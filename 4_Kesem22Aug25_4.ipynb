{"cells":[{"cell_type":"markdown","metadata":{"id":"l2o6Ou8N_my-"},"source":["# Text To Speech Model"]},{"cell_type":"markdown","metadata":{"id":"8NETblXi_pCu"},"source":["## Google Colab Integration"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wzLS2lDb_fFh","outputId":"9999028c-8396-4cca-9892-7b942228df11"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"xVEJaRsC_fFj"},"source":["## Installations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kIdQWWwYHxy-","outputId":"cf3ff873-1ee5-4a73-b40d-85b5401146f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","sox is already the newest version (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 74 not upgraded.\n","Get:1 https://cli.github.com/packages stable InRelease [3,917 B]\n","Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Fetched 3,917 B in 1s (3,190 B/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","espeak is already the newest version (1.48.15+dfsg-3).\n","0 upgraded, 0 newly installed, 0 to remove and 74 not upgraded.\n","Requirement already satisfied: unidecode in /usr/local/lib/python3.12/dist-packages (1.4.0)\n","Requirement already satisfied: inflect in /usr/local/lib/python3.12/dist-packages (7.5.0)\n","Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.12/dist-packages (from inflect) (10.7.0)\n","Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from inflect) (4.4.4)\n","Requirement already satisfied: typing_extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from typeguard>=4.0.1->inflect) (4.14.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n","Requirement already satisfied: whisperx in /usr/local/lib/python3.12/dist-packages (3.4.2)\n","Requirement already satisfied: ctranslate2<4.5.0 in /usr/local/lib/python3.12/dist-packages (from whisperx) (4.4.0)\n","Requirement already satisfied: faster-whisper>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from whisperx) (1.2.0)\n","Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from whisperx) (3.9.1)\n","Collecting numpy>=2.0.2 (from whisperx)\n","  Downloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: onnxruntime>=1.19 in /usr/local/lib/python3.12/dist-packages (from whisperx) (1.22.1)\n","Requirement already satisfied: pandas>=2.2.3 in /usr/local/lib/python3.12/dist-packages (from whisperx) (2.3.2)\n","Requirement already satisfied: pyannote-audio>=3.3.2 in /usr/local/lib/python3.12/dist-packages (from whisperx) (3.3.2)\n","Requirement already satisfied: torch>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from whisperx) (2.8.0+cu126)\n","Requirement already satisfied: torchaudio>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from whisperx) (2.8.0+cu126)\n","Requirement already satisfied: transformers>=4.48.0 in /usr/local/lib/python3.12/dist-packages (from whisperx) (4.51.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from ctranslate2<4.5.0->whisperx) (75.2.0)\n","Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.12/dist-packages (from ctranslate2<4.5.0->whisperx) (6.0.2)\n","Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper>=1.1.1->whisperx) (0.34.4)\n","Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.12/dist-packages (from faster-whisper>=1.1.1->whisperx) (0.21.4)\n","Requirement already satisfied: av>=11 in /usr/local/lib/python3.12/dist-packages (from faster-whisper>=1.1.1->whisperx) (15.0.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from faster-whisper>=1.1.1->whisperx) (4.67.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9.1->whisperx) (8.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9.1->whisperx) (1.5.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9.1->whisperx) (2024.11.6)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.19->whisperx) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.19->whisperx) (25.2.10)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.19->whisperx) (24.2)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.19->whisperx) (5.29.5)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.19->whisperx) (1.13.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->whisperx) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->whisperx) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.3->whisperx) (2025.2)\n","Requirement already satisfied: asteroid-filterbanks>=0.4 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (0.4.0)\n","Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (0.8.1)\n","Requirement already satisfied: lightning>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (2.4.0)\n","Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (2.3.0)\n","Requirement already satisfied: pyannote.core>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (5.0.0)\n","Requirement already satisfied: pyannote.database>=5.0.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (5.1.3)\n","Requirement already satisfied: pyannote.metrics>=3.2 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (3.2.1)\n","Requirement already satisfied: pyannote.pipeline>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (3.0.1)\n","Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (2.9.0)\n","Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (13.9.4)\n","Requirement already satisfied: semver>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (3.0.4)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (0.13.1)\n","Requirement already satisfied: speechbrain>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (1.0.3)\n","Requirement already satisfied: tensorboardX>=2.6 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (2.6.4)\n","Requirement already satisfied: torch-audiomentations>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (0.12.0)\n","Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from pyannote-audio>=3.3.2->whisperx) (1.8.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (2024.12.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.1->whisperx) (3.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.48.0->whisperx) (2.32.4)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.48.0->whisperx) (0.6.2)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.13->faster-whisper>=1.1.1->whisperx) (1.1.7)\n","Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (0.15.2)\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (2.5.3)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf<3.0,>=2.1->pyannote-audio>=3.3.2->whisperx) (4.9.3)\n","Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from pyannote.core>=5.0.0->pyannote-audio>=3.3.2->whisperx) (2.4.0)\n","Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.core>=5.0.0->pyannote-audio>=3.3.2->whisperx) (1.16.1)\n","Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.database>=5.0.1->pyannote-audio>=3.3.2->whisperx) (0.16.0)\n","Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (1.6.1)\n","Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.12/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (0.6.2)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.12/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (0.9.0)\n","Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (3.10.0)\n","Requirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx) (4.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2.3->whisperx) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->pyannote-audio>=3.3.2->whisperx) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.0.0->pyannote-audio>=3.3.2->whisperx) (2.19.2)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->pyannote-audio>=3.3.2->whisperx) (1.17.1)\n","Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.12/dist-packages (from speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx) (1.2.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx) (0.2.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.19->whisperx) (1.3.0)\n","Requirement already satisfied: julius<0.3,>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from torch-audiomentations>=0.11.0->pyannote-audio>=3.3.2->whisperx) (0.2.7)\n","Requirement already satisfied: torch-pitch-shift>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from torch-audiomentations>=0.11.0->pyannote-audio>=3.3.2->whisperx) (1.2.5)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.19->whisperx) (10.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.5.1->whisperx) (3.0.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.48.0->whisperx) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.48.0->whisperx) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.48.0->whisperx) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.48.0->whisperx) (2025.8.3)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote-audio>=3.3.2->whisperx) (2.22)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (3.12.15)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote-audio>=3.3.2->whisperx) (0.1.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (4.59.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (3.2.3)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx) (1.16.4)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx) (6.9.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx) (2.0.43)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote-audio>=3.3.2->whisperx) (3.6.0)\n","Requirement already satisfied: primePy>=1.3 in /usr/local/lib/python3.12/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote-audio>=3.3.2->whisperx) (1.3)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote-audio>=3.3.2->whisperx) (1.5.4)\n","Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.12/dist-packages (from hyperpyyaml->speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx) (0.18.15)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning>=2.0.1->pyannote-audio>=3.3.2->whisperx) (1.20.1)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx) (1.1.3)\n","Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=1.0.0->pyannote-audio>=3.3.2->whisperx) (0.2.12)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote-audio>=3.3.2->whisperx) (3.2.4)\n","Downloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n","tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.2 which is incompatible.\n","cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n","cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.2 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\n","dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-2.3.2\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"d6201a47c535421c9752452afff359e3","pip_warning":{"packages":["numpy"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from torchaudio) (2.8.0+cu126)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (4.14.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (2024.12.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchaudio) (3.4.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0->torchaudio) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0->torchaudio) (3.0.2)\n","Requirement already satisfied: phonemizer in /usr/local/lib/python3.12/dist-packages (3.3.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from phonemizer) (1.5.1)\n","Requirement already satisfied: segments in /usr/local/lib/python3.12/dist-packages (from phonemizer) (2.3.0)\n","Requirement already satisfied: attrs>=18.1 in /usr/local/lib/python3.12/dist-packages (from phonemizer) (25.3.0)\n","Requirement already satisfied: dlinfo in /usr/local/lib/python3.12/dist-packages (from phonemizer) (2.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from phonemizer) (4.14.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from segments->phonemizer) (2024.11.6)\n","Requirement already satisfied: csvw>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from segments->phonemizer) (3.5.1)\n","Requirement already satisfied: isodate in /usr/local/lib/python3.12/dist-packages (from csvw>=1.5.6->segments->phonemizer) (0.7.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.9.0.post0)\n","Requirement already satisfied: rfc3986<2 in /usr/local/lib/python3.12/dist-packages (from csvw>=1.5.6->segments->phonemizer) (1.5.0)\n","Requirement already satisfied: uritemplate>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.2.0)\n","Requirement already satisfied: babel in /usr/local/lib/python3.12/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.17.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from csvw>=1.5.6->segments->phonemizer) (2.32.4)\n","Requirement already satisfied: language-tags in /usr/local/lib/python3.12/dist-packages (from csvw>=1.5.6->segments->phonemizer) (1.2.0)\n","Requirement already satisfied: rdflib in /usr/local/lib/python3.12/dist-packages (from csvw>=1.5.6->segments->phonemizer) (7.1.4)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from csvw>=1.5.6->segments->phonemizer) (0.4.6)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from csvw>=1.5.6->segments->phonemizer) (4.25.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer) (0.27.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->csvw>=1.5.6->segments->phonemizer) (1.17.0)\n","Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from rdflib->csvw>=1.5.6->segments->phonemizer) (3.2.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer) (2025.8.3)\n","Requirement already satisfied: nemo_toolkit[tts] in /usr/local/lib/python3.12/dist-packages (2.4.0)\n","Requirement already satisfied: fsspec==2024.12.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (2024.12.0)\n","Requirement already satisfied: huggingface_hub>=0.24 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.34.4)\n","Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.60.0)\n","Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (2.3.2)\n","Requirement already satisfied: onnx>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (1.18.0)\n","Requirement already satisfied: protobuf~=5.29.5 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (5.29.5)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (2.9.0.post0)\n","Requirement already satisfied: ruamel.yaml in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.18.15)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (1.6.1)\n","Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (75.2.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (2.19.0)\n","Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (1.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (2.8.0+cu126)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (4.67.1)\n","Requirement already satisfied: wget in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (3.2)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (1.17.3)\n","Requirement already satisfied: attrdict in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (2.0.1)\n","Requirement already satisfied: cdifflib==1.2.6 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (1.2.6)\n","Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.8.1)\n","Requirement already satisfied: janome in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.5.0)\n","Requirement already satisfied: jieba in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.42.1)\n","Requirement already satisfied: kornia in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.8.1)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.11.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (3.10.0)\n","Requirement already satisfied: nemo_text_processing in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (1.1.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (3.9.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (2.3.2)\n","Requirement already satisfied: pypinyin in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.55.0)\n","Requirement already satisfied: pypinyin-dict in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.9.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.13.2)\n","Requirement already satisfied: braceexpand in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.1.7)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.8.1)\n","Requirement already satisfied: jiwer<4.0.0,>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (3.1.0)\n","Requirement already satisfied: kaldi-python-io in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (1.2.2)\n","Requirement already satisfied: lhotse!=1.31.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (1.30.3)\n","Requirement already satisfied: marshmallow in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (4.0.0)\n","Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (4.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (24.2)\n","Requirement already satisfied: pyannote.core in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (5.0.0)\n","Requirement already satisfied: pyannote.metrics in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (3.2.1)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.25.1)\n","Requirement already satisfied: pyloudnorm in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.1.1)\n","Requirement already satisfied: resampy in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.4.3)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (1.16.1)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.13.1)\n","Requirement already satisfied: sox<=1.5.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (1.5.0)\n","Requirement already satisfied: texterrors<1.0.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.5.1)\n","Requirement already satisfied: whisper_normalizer in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.1.12)\n","Requirement already satisfied: num2words in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.5.14)\n","Collecting numpy>=1.22 (from nemo_toolkit[tts])\n","  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (4.0.0)\n","Requirement already satisfied: inflect in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (7.5.0)\n","Requirement already satisfied: mediapy==1.1.6 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (1.1.6)\n","Requirement already satisfied: sacremoses>=0.0.43 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.1.1)\n","Requirement already satisfied: sentencepiece<1.0.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.2.1)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (3.1.1)\n","Requirement already satisfied: fiddle in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.3.0)\n","Requirement already satisfied: hydra-core<=1.3.2,>1.3 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (1.3.2)\n","Requirement already satisfied: lightning<=2.4.0,>2.2.1 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (2.4.0)\n","Requirement already satisfied: omegaconf<=2.3 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (2.3.0)\n","Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.17.0)\n","Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (1.8.1)\n","Requirement already satisfied: transformers<=4.52.0,>=4.51.0 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (4.51.3)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.21.1)\n","Requirement already satisfied: webdataset>=0.2.86 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (1.0.2)\n","Requirement already satisfied: bitsandbytes==0.45.5 in /usr/local/lib/python3.12/dist-packages (from nemo_toolkit[tts]) (0.45.5)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from mediapy==1.1.6->nemo_toolkit[tts]) (7.34.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from mediapy==1.1.6->nemo_toolkit[tts]) (11.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[tts]) (3.19.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[tts]) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[tts]) (2.32.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[tts]) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.24->nemo_toolkit[tts]) (1.1.7)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core<=1.3.2,>1.3->nemo_toolkit[tts]) (4.9.3)\n","Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer<4.0.0,>=3.1.0->nemo_toolkit[tts]) (8.2.1)\n","Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.12/dist-packages (from jiwer<4.0.0,>=3.1.0->nemo_toolkit[tts]) (3.13.0)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from lhotse!=1.31.0->nemo_toolkit[tts]) (3.0.1)\n","Requirement already satisfied: cytoolz>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from lhotse!=1.31.0->nemo_toolkit[tts]) (1.0.1)\n","Requirement already satisfied: intervaltree>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from lhotse!=1.31.0->nemo_toolkit[tts]) (3.1.0)\n","Requirement already satisfied: tabulate>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from lhotse!=1.31.0->nemo_toolkit[tts]) (0.9.0)\n","Requirement already satisfied: lilcom>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from lhotse!=1.31.0->nemo_toolkit[tts]) (1.8.1)\n","Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->nemo_toolkit[tts]) (1.5.1)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa->nemo_toolkit[tts]) (4.4.2)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa->nemo_toolkit[tts]) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa->nemo_toolkit[tts]) (0.5.0.post1)\n","Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa->nemo_toolkit[tts]) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->nemo_toolkit[tts]) (1.1.1)\n","Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lightning<=2.4.0,>2.2.1->nemo_toolkit[tts]) (0.15.2)\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from lightning<=2.4.0,>2.2.1->nemo_toolkit[tts]) (2.5.3)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->nemo_toolkit[tts]) (0.43.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacremoses>=0.0.43->nemo_toolkit[tts]) (2024.11.6)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->nemo_toolkit[tts]) (3.6.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile->nemo_toolkit[tts]) (1.17.1)\n","Requirement already satisfied: pybind11 in /usr/local/lib/python3.12/dist-packages (from texterrors<1.0.0->nemo_toolkit[tts]) (3.0.0)\n","Requirement already satisfied: plac in /usr/local/lib/python3.12/dist-packages (from texterrors<1.0.0->nemo_toolkit[tts]) (1.4.5)\n","Requirement already satisfied: loguru in /usr/local/lib/python3.12/dist-packages (from texterrors<1.0.0->nemo_toolkit[tts]) (0.7.3)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from texterrors<1.0.0->nemo_toolkit[tts]) (3.1.0)\n","Requirement already satisfied: Levenshtein in /usr/local/lib/python3.12/dist-packages (from texterrors<1.0.0->nemo_toolkit[tts]) (0.27.1)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->nemo_toolkit[tts]) (3.4.0)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.52.0,>=4.51.0->nemo_toolkit[tts]) (0.21.4)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.52.0,>=4.51.0->nemo_toolkit[tts]) (0.6.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from attrdict->nemo_toolkit[tts]) (1.17.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->nemo_toolkit[tts]) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->nemo_toolkit[tts]) (0.3.8)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->nemo_toolkit[tts]) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->nemo_toolkit[tts]) (0.70.16)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from fiddle->nemo_toolkit[tts]) (1.4.0)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from fiddle->nemo_toolkit[tts]) (0.21)\n","Requirement already satisfied: libcst in /usr/local/lib/python3.12/dist-packages (from fiddle->nemo_toolkit[tts]) (1.8.2)\n","Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.12/dist-packages (from inflect->nemo_toolkit[tts]) (10.7.0)\n","Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from inflect->nemo_toolkit[tts]) (4.4.4)\n","Requirement already satisfied: kornia_rs>=0.1.9 in /usr/local/lib/python3.12/dist-packages (from kornia->nemo_toolkit[tts]) (0.1.9)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->nemo_toolkit[tts]) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->nemo_toolkit[tts]) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->nemo_toolkit[tts]) (4.59.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->nemo_toolkit[tts]) (1.4.9)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->nemo_toolkit[tts]) (3.2.3)\n","Requirement already satisfied: pynini==2.1.6.post1 in /usr/local/lib/python3.12/dist-packages (from nemo_text_processing->nemo_toolkit[tts]) (2.1.6.post1)\n","Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.12/dist-packages (from num2words->nemo_toolkit[tts]) (0.6.2)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna->nemo_toolkit[tts]) (1.16.4)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna->nemo_toolkit[tts]) (6.9.0)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna->nemo_toolkit[tts]) (2.0.43)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->nemo_toolkit[tts]) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->nemo_toolkit[tts]) (2025.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft->nemo_toolkit[tts]) (5.9.5)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft->nemo_toolkit[tts]) (1.10.0)\n","Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from pyannote.core->nemo_toolkit[tts]) (2.4.0)\n","Requirement already satisfied: pyannote.database>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.metrics->nemo_toolkit[tts]) (5.1.3)\n","Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from pyloudnorm->nemo_toolkit[tts]) (1.0.0)\n","Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from ruamel.yaml->nemo_toolkit[tts]) (0.2.12)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo_toolkit[tts]) (1.74.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo_toolkit[tts]) (3.8.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo_toolkit[tts]) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->nemo_toolkit[tts]) (3.1.3)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->nemo_toolkit[tts]) (3.1.45)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->nemo_toolkit[tts]) (4.3.8)\n","Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb->nemo_toolkit[tts]) (2.11.7)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->nemo_toolkit[tts]) (2.35.0)\n","Requirement already satisfied: indic-numtowords in /usr/local/lib/python3.12/dist-packages (from whisper_normalizer->nemo_toolkit[tts]) (1.1.0)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->nemo_toolkit[tts]) (1.1.3)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile->nemo_toolkit[tts]) (2.22)\n","Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from cytoolz>=0.10.1->lhotse!=1.31.0->nemo_toolkit[tts]) (0.12.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[tts]) (3.12.15)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[tts]) (4.0.12)\n","Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[tts]) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->nemo_toolkit[tts]) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->nemo_toolkit[tts]) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb->nemo_toolkit[tts]) (0.4.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[tts]) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[tts]) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[tts]) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.24->nemo_toolkit[tts]) (2025.8.3)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna->nemo_toolkit[tts]) (3.2.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->nemo_toolkit[tts]) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->nemo_toolkit[tts]) (3.0.2)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[tts]) (0.19.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[tts]) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[tts]) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[tts]) (3.0.51)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[tts]) (2.19.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[tts]) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[tts]) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->mediapy==1.1.6->nemo_toolkit[tts]) (4.9.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[tts]) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[tts]) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[tts]) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[tts]) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[tts]) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[tts]) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<=2.4.0,>2.2.1->nemo_toolkit[tts]) (1.20.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[tts]) (5.0.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->mediapy==1.1.6->nemo_toolkit[tts]) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->mediapy==1.1.6->nemo_toolkit[tts]) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->mediapy==1.1.6->nemo_toolkit[tts]) (0.2.13)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[tts]) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[tts]) (13.9.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[tts]) (4.0.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[tts]) (0.1.2)\n","Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.3.2\n","    Uninstalling numpy-2.3.2:\n","      Successfully uninstalled numpy-2.3.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","whisperx 3.4.2 requires numpy>=2.0.2, but you have numpy 1.26.4 which is incompatible.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.2 which is incompatible.\n","cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.2 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.4\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"c9c766d9af3d43e8892fc9c677ff8af7","pip_warning":{"packages":["numpy"]}}},"metadata":{},"output_type":"display_data"}],"source":["!apt-get install sox\n","!apt-get update\n","!apt-get install espeak\n","!pip install unidecode\n","!pip install inflect\n","!pip install nltk\n","!pip install whisperx\n","!pip install torchaudio\n","!pip install phonemizer\n","!pip install nemo_toolkit[tts]"]},{"cell_type":"markdown","metadata":{"id":"cfBvYq31_fFl"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aznEOCsZ_fFm","outputId":"bc7b3424-4044-4215-c62a-36d99dd9217d"},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow: 2.19.0\n","NumPy: 1.26.4\n","GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}],"source":["import os\n","import subprocess\n","import librosa\n","import numpy as np\n","import soundfile as sf\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from typing import List, Dict\n","import pickle\n","import gc\n","import torch\n","import torchaudio\n","from transformers import Wav2Vec2Model, Wav2Vec2Processor\n","from phonemizer import phonemize\n","from phonemizer.backend import EspeakBackend\n","from nemo.collections.tts.models import HifiGanModel\n","import random\n","\n","print(\"TensorFlow:\", tf.__version__)\n","print(\"NumPy:\", np.__version__)\n","print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n"]},{"cell_type":"markdown","metadata":{"id":"MeFjPLt-_fFm"},"source":["## Download Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OFuLew0z_fFm"},"outputs":[],"source":["# Define paths\n","dataset_path = \"/content/drive/MyDrive/final_project/Dataset_3\"\n","# dataset_path = \"/content/drive/MyDrive/final_project/Dataset_1\"\n","wav_folder = os.path.join(dataset_path, \"wav\")\n","stm_folder = os.path.join(dataset_path, \"data/stm\")\n","sph_folder = os.path.join(dataset_path, \"data/sph\")\n","clips_folder = os.path.join(dataset_path, \"clips\")\n","audio_outputs_folder = os.path.join(dataset_path, \"audio_outputs\")\n","\n","\n","# Create necessary directories\n","os.makedirs(wav_folder, exist_ok=True)\n","os.makedirs(clips_folder, exist_ok=True)\n","os.makedirs(audio_outputs_folder, exist_ok=True)\n"]},{"cell_type":"markdown","metadata":{"id":"oAjb0idQ_fFn"},"source":["## Pre-Processing"]},{"cell_type":"markdown","metadata":{"id":"vhtHjS19_fFn"},"source":["### Convert .sph to .wav"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8_UYEkOs_fFn"},"outputs":[],"source":["def convert_sph_to_wav(sph_folder, wav_folder, max_files=None):\n","    os.makedirs(wav_folder, exist_ok=True)\n","    sph_files = glob.glob(os.path.join(sph_folder, \"*.sph\"))\n","    if max_files is not None:\n","        sph_files = sph_files[:max_files]\n","        print(f\"Processing {max_files} files out of {len(sph_files)} total files\")\n","    for sph_file in tqdm(sph_files, desc=\"Converting .sph to .wav\"):\n","        basename = os.path.splitext(os.path.basename(sph_file))[0]\n","        wav_path = os.path.join(wav_folder, f\"{basename}.wav\")\n","        if not os.path.exists(wav_path):\n","            subprocess.run([\"sox\", sph_file, wav_path])"]},{"cell_type":"markdown","metadata":{"id":"P6fN89ui_fFo"},"source":["### Parse .stm files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"df8S7sNh_fFo"},"outputs":[],"source":["def parse_stm_file(stm_path):\n","    segments = []\n","    segments_dict = {}\n","    with open(stm_path, 'r') as f:\n","        for line in f:\n","            parts = line.strip().split(' ')\n","            talk_id, speaker, start, end = parts[0], parts[1], float(parts[3]), float(parts[4])\n","            text = ' '.join(parts[6:])\n","            segments.append((talk_id, speaker, start, end, text))\n","            if talk_id not in segments_dict:\n","                segments_dict[talk_id] = dict()\n","            segments_dict[talk_id][f'{start:.2f}_{end:.2f}'] = text\n","\n","    return segments, segments_dict\n"]},{"cell_type":"markdown","metadata":{"id":"HU7JU3_M_fFo"},"source":["### Split wavs to small clips"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kPQFonxR_fFo"},"outputs":[],"source":["def extract_audio_segments(wav_folder, segments, output_folder):\n","    os.makedirs(output_folder, exist_ok=True)\n","    for (talk_id, speaker, start, end, text) in tqdm(segments, desc=\"Segmenting audio\"):\n","        wav_path = os.path.join(wav_folder, f\"{talk_id}.wav\")\n","        if not os.path.exists(wav_path):\n","            print(f\"Skipping {wav_path} because it does not exist\")\n","            continue\n","        y, sr = librosa.load(wav_path, sr=None)\n","        start_sample = int(start * sr)\n","        end_sample = int(end * sr)\n","        segment = y[start_sample:end_sample]\n","        output_path = os.path.join(output_folder, f\"{talk_id}_{start:.2f}_{end:.2f}.wav\")\n","        sf.write(output_path, segment, sr)\n"]},{"cell_type":"markdown","metadata":{"id":"aDhBblA7_fFp"},"source":["### Convert wav to mel spectrograms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_3j5fvZC-m9p"},"outputs":[],"source":["# 1) Redefine wav_to_mel to produce dB-scaled mel (power=2.0 -> dB)\n","def wav_to_mel(wav_path, sr=22050, n_fft=1024, hop_length=256, win_length=1024, n_mels=80, fmin=0, fmax=8000):\n","    y, _ = librosa.load(wav_path, sr=sr, mono=True)\n","    S_power = librosa.feature.melspectrogram(\n","        y=y,\n","        sr=sr,\n","        n_fft=n_fft,\n","        hop_length=hop_length,\n","        win_length=win_length,\n","        n_mels=n_mels,\n","        fmin=fmin,\n","        fmax=fmax,\n","        power=2.0,\n","    )\n","    mel_db = librosa.power_to_db(S_power, ref=1.0)  # dB, typically in [-80, 0]\n","    return mel_db.astype(np.float32)  # [80, T]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M8CwCYopanWE","outputId":"528dd248-ff97-4f61-bee7-d114d1d1d954"},"outputs":[{"name":"stderr","output_type":"stream","text":[" NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n","INFO:NeMo-text-processing:Creating ClassifyFst grammars.\n","[NeMo W 2025-08-21 18:00:36 nemo_logging:405] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n","[NeMo W 2025-08-21 18:00:36 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    dataset:\n","      _target_: nemo.collections.tts.torch.data.TTSDataset\n","      manifest_filepath: /ws/LJSpeech/nvidia_ljspeech_train_clean_ngc.json\n","      sample_rate: 22050\n","      sup_data_path: /raid/LJSpeech/supplementary\n","      sup_data_types:\n","      - align_prior_matrix\n","      - pitch\n","      n_fft: 1024\n","      win_length: 1024\n","      hop_length: 256\n","      window: hann\n","      n_mels: 80\n","      lowfreq: 0\n","      highfreq: 8000\n","      max_duration: null\n","      min_duration: 0.1\n","      ignore_file: null\n","      trim: false\n","      pitch_fmin: 65.40639132514966\n","      pitch_fmax: 2093.004522404789\n","      pitch_norm: true\n","      pitch_mean: 212.35873413085938\n","      pitch_std: 68.52806091308594\n","      use_beta_binomial_interpolator: true\n","    dataloader_params:\n","      drop_last: false\n","      shuffle: true\n","      batch_size: 24\n","      num_workers: 0\n","    \n","[NeMo W 2025-08-21 18:00:36 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    dataset:\n","      _target_: nemo.collections.tts.torch.data.TTSDataset\n","      manifest_filepath: /ws/LJSpeech/nvidia_ljspeech_val_clean_ngc.json\n","      sample_rate: 22050\n","      sup_data_path: /raid/LJSpeech/supplementary\n","      sup_data_types:\n","      - align_prior_matrix\n","      - pitch\n","      n_fft: 1024\n","      win_length: 1024\n","      hop_length: 256\n","      window: hann\n","      n_mels: 80\n","      lowfreq: 0\n","      highfreq: 8000\n","      max_duration: null\n","      min_duration: null\n","      ignore_file: null\n","      trim: false\n","      pitch_fmin: 65.40639132514966\n","      pitch_fmax: 2093.004522404789\n","      pitch_norm: true\n","      pitch_mean: 212.35873413085938\n","      pitch_std: 68.52806091308594\n","      use_beta_binomial_interpolator: true\n","    dataloader_params:\n","      drop_last: false\n","      shuffle: false\n","      batch_size: 24\n","      num_workers: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2025-08-21 18:00:36 nemo_logging:393] PADDING: 1\n","[NeMo I 2025-08-21 18:00:37 nemo_logging:393] Model FastPitchModel was successfully restored from /root/.cache/huggingface/hub/models--nvidia--tts_en_fastpitch/snapshots/2c8305b7b41b33fd6367f0635796dc3a7a33cbf9/tts_en_fastpitch.nemo.\n"]}],"source":["from nemo.collections.tts.models import FastPitchModel\n","spec_generator = FastPitchModel.from_pretrained(\"nvidia/tts_en_fastpitch\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UZ-6w2jmb58i"},"outputs":[],"source":["def text_to_mel(text):\n","    parsed = spec_generator.parse(text)\n","    mel_spectrogram = spec_generator.generate_spectrogram(tokens=parsed)\n","    return mel_spectrogram"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oDssL_Sye4RT","outputId":"7f0c3b87-9c83-485e-d1ce-c78e7fe5276e"},"outputs":[{"name":"stderr","output_type":"stream","text":[" NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n","INFO:NeMo-text-processing:Creating ClassifyFst grammars.\n","[NeMo W 2025-08-21 18:01:15 nemo_logging:405] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n","[NeMo W 2025-08-21 18:01:15 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    dataset:\n","      _target_: nemo.collections.tts.torch.data.TTSDataset\n","      manifest_filepath: /ws/LJSpeech/nvidia_ljspeech_train_clean_ngc.json\n","      sample_rate: 22050\n","      sup_data_path: /raid/LJSpeech/supplementary\n","      sup_data_types:\n","      - align_prior_matrix\n","      - pitch\n","      n_fft: 1024\n","      win_length: 1024\n","      hop_length: 256\n","      window: hann\n","      n_mels: 80\n","      lowfreq: 0\n","      highfreq: 8000\n","      max_duration: null\n","      min_duration: 0.1\n","      ignore_file: null\n","      trim: false\n","      pitch_fmin: 65.40639132514966\n","      pitch_fmax: 2093.004522404789\n","      pitch_norm: true\n","      pitch_mean: 212.35873413085938\n","      pitch_std: 68.52806091308594\n","      use_beta_binomial_interpolator: true\n","    dataloader_params:\n","      drop_last: false\n","      shuffle: true\n","      batch_size: 24\n","      num_workers: 0\n","    \n","[NeMo W 2025-08-21 18:01:15 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    dataset:\n","      _target_: nemo.collections.tts.torch.data.TTSDataset\n","      manifest_filepath: /ws/LJSpeech/nvidia_ljspeech_val_clean_ngc.json\n","      sample_rate: 22050\n","      sup_data_path: /raid/LJSpeech/supplementary\n","      sup_data_types:\n","      - align_prior_matrix\n","      - pitch\n","      n_fft: 1024\n","      win_length: 1024\n","      hop_length: 256\n","      window: hann\n","      n_mels: 80\n","      lowfreq: 0\n","      highfreq: 8000\n","      max_duration: null\n","      min_duration: null\n","      ignore_file: null\n","      trim: false\n","      pitch_fmin: 65.40639132514966\n","      pitch_fmax: 2093.004522404789\n","      pitch_norm: true\n","      pitch_mean: 212.35873413085938\n","      pitch_std: 68.52806091308594\n","      use_beta_binomial_interpolator: true\n","    dataloader_params:\n","      drop_last: false\n","      shuffle: false\n","      batch_size: 24\n","      num_workers: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2025-08-21 18:01:15 nemo_logging:393] PADDING: 1\n","[NeMo I 2025-08-21 18:01:16 nemo_logging:393] Model FastPitchModel was successfully restored from /root/.cache/huggingface/hub/models--nvidia--tts_en_fastpitch/snapshots/2c8305b7b41b33fd6367f0635796dc3a7a33cbf9/tts_en_fastpitch.nemo.\n"]}],"source":["import numpy as np\n","import torch\n","from nemo.collections.tts.models import FastPitchModel\n","\n","spec_generator = FastPitchModel.from_pretrained(\"nvidia/tts_en_fastpitch\")\n","spec_generator.eval()\n","\n","@torch.no_grad()\n","def text_to_mel(text):\n","    # Parse text -> token ids (shape [B, T_text])\n","    tokens = spec_generator.parse(text)\n","\n","    # Generate mel (usually returns [B, n_mels(=80), T_frames])\n","    mel = spec_generator.generate_spectrogram(tokens=tokens)\n","\n","    # Squeeze batch dim -> [80, T]\n","    if mel.dim() == 3:\n","        mel = mel[0]\n","\n","    # Ensure mel-first layout [80, T]\n","    if mel.shape[0] != 80 and mel.shape[1] == 80:\n","        mel = mel.transpose(0, 1)\n","\n","    # Convert to numpy float32 like wav_to_mel\n","    mel_np = mel.detach().cpu().numpy().astype(np.float32)  # [80, T]\n","    return mel_np\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mIu2ci7Vg2gx"},"outputs":[],"source":["import torch\n","@torch.no_grad()\n","def text_to_mel(text):\n","    spec_generator.eval()\n","    tokens = spec_generator.parse(text)                         # [B, T_text]\n","    mel = spec_generator.generate_spectrogram(tokens=tokens)    # [B, 80, T]\n","    if mel.dim() == 3:\n","        mel = mel[0]                                           # [80, T]\n","    mel = mel.transpose(0, 1).contiguous()                      # -> [T, 80]\n","    return mel.float()                                          # torch.FloatTensor [T, 80]\n"]},{"cell_type":"markdown","metadata":{"id":"t0e-tbsO_fFp"},"source":["### Convert all wav files in folder to mel spectograms"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vejgEhpH_fFp"},"outputs":[],"source":["def create_full_talks_mel(wav_folder):\n","    full_talks_mel = {}\n","    talks_paths = glob.glob(os.path.join(wav_folder, \"*.wav\"))\n","    print(talks_paths)\n","    for talk_path in tqdm(talks_paths, desc=\"Creating full talks mel\"):\n","        mel = wav_to_mel(talk_path)\n","        talk_id = os.path.basename(talk_path).split(\".\")[0]\n","        full_talks_mel[talk_id] = mel\n","    return full_talks_mel\n"]},{"cell_type":"markdown","metadata":{"id":"lfKCDEDa_fFp"},"source":["### Dataset Creation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wwL972Pf_fFp"},"outputs":[],"source":["def preprocess_tedlium(base_path, target_size=10000, max_files=None, output_path='custom_data_phoneme', _convert_sph_to_wav=True):\n","    sph_folder = os.path.join(base_path, \"data/sph\")\n","    stm_folder = os.path.join(base_path, \"data/stm\")\n","    custom_wav_folder = f\"{output_path}/wavs\"\n","    custom_clip_folder = f\"{output_path}/clips\"\n","\n","    os.makedirs(custom_wav_folder, exist_ok=True)\n","    os.makedirs(custom_clip_folder, exist_ok=True)\n","\n","    # Convert SPH to WAV\n","    if _convert_sph_to_wav:\n","        convert_sph_to_wav(sph_folder, custom_wav_folder, max_files=max_files)\n","\n","    # Parse STM files\n","    stm_files = glob.glob(os.path.join(stm_folder, \"*.stm\"))\n","    custom_clips = glob.glob(os.path.join(custom_wav_folder, \"*.wav\"))\n","    custom_clips = [clip.split(\"/\")[-1].replace(\".wav\", \"\") for clip in custom_clips]\n","\n","    stm_files = [stm_file for stm_file in stm_files if stm_file.split(\"/\")[-1].replace(\".stm\", \"\") in custom_clips]\n","\n","\n","    all_segments = []\n","    all_segments_dict = {}\n","\n","    for stm_path in stm_files:\n","        segments, segments_dict = parse_stm_file(stm_path)\n","        all_segments.extend(segments)\n","        all_segments_dict.update(segments_dict)\n","\n","    # Create full talks mel\n","    full_talks_mel = create_full_talks_mel(custom_wav_folder)\n","\n","    # Limit dataset size\n","    all_segments = all_segments[:target_size]\n","\n","    # Extract audio clips\n","    extract_audio_segments(custom_wav_folder, all_segments, custom_clip_folder)\n","\n","    print(f\"Preprocessing done. {len(all_segments)} clips created.\")\n","\n","    return custom_clip_folder, all_segments_dict, full_talks_mel\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGTlViZi_fFp"},"outputs":[],"source":["def create_dataset(clips_folder, all_segments, full_talks_mel: Dict[str, np.ndarray], full_talks_folder: str, processor: Wav2Vec2Processor, specific_clips: List[str]=None, shuffle=False):\n","    dataset = []\n","\n","    clip_paths = glob.glob(os.path.join(clips_folder, \"*.wav\"))\n","    if specific_clips:\n","        clip_paths = [clip_path for clip_path in clip_paths if '_'.join(os.path.basename(clip_path).split(\"_\")[:-2]) in specific_clips]\n","\n","    for clip_path in tqdm(clip_paths, desc=\"Creating dataset\"):\n","        mel = wav_to_mel(clip_path)\n","        basename = os.path.basename(clip_path).split(\"_\")\n","        talk_id = '_'.join(basename[:-2])\n","        start = float(basename[-2])\n","        end = float(basename[-1].replace(\".wav\", \"\"))\n","        time_range = f'{start:.2f}_{end:.2f}'\n","        text = all_segments[talk_id][time_range]\n","        tokenized = processor.tokenizer(text, return_tensors=\"pt\").input_ids.squeeze(0).numpy()\n","\n","        full_talk_wav_path = os.path.join(full_talks_folder, f\"{talk_id}.wav\")\n","        dataset.append((full_talk_wav_path, clip_path, mel, tokenized))\n","\n","    if shuffle:\n","        random.shuffle(dataset)\n","\n","    return dataset\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"__UxOCCm2St3"},"source":["### Make a word-based dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-QV170OR2aZi"},"outputs":[],"source":["import os, glob, json, re, csv, math\n","import soundfile as sf\n","import numpy as np\n","import torch\n","import torchaudio\n","from phonemizer import phonemize\n","from phonemizer.backend import EspeakBackend\n","\n","# ---------- helpers ----------\n","\n","_word_re = re.compile(r\"[a-zA-Z']+\")\n","\n","def normalize_text_for_alignment(text: str) -> str:\n","    # Simple normalization; adjust to your preference\n","    text = text.strip().lower()\n","    # keep apostrophes in contractions; drop other punctuation\n","    text = re.sub(r\"[^a-z0-9' ]+\", \" \", text)\n","    text = re.sub(r\"\\s+\", \" \", text)\n","    return text.strip()\n","\n","def slice_audio(audio, sr, t0, t1, pad=0.0):\n","    start = max(0, int((t0 - pad) * sr))\n","    end   = min(len(audio), int((t1 + pad) * sr))\n","    return audio[start:end]\n","\n","def maybe_phonemes(word: str) -> str:\n","    # ARPAbet/IPA; here we use IPA with espeak (en-us)\n","    # For ARPAbet consider g2p-en or phonemizer with 'espeak-mbrola-...'\n","    try:\n","        return phonemize(word, backend=EspeakBackend(language='en-us'), strip=True, njobs=1)\n","    except Exception:\n","        return \"\"\n","\n","# ---------- WhisperX alignment ----------\n","\n","class WhisperXAligner:\n","    def __init__(self, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", compute_type=\"float16\"):\n","        import whisperx\n","        self.device = device\n","        self.model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type)\n","        self.alignment_model, self.metadata = whisperx.load_align_model(language_code=\"en\", device=device)\n","\n","    def align_sentence(self, wav_path: str, sentence_text: str):\n","        \"\"\"\n","        Returns list of dicts: [{\"word\": str, \"start\": float, \"end\": float}, ...]\n","        Uses *given* sentence text to constrain ASR then align to words.\n","        \"\"\"\n","        import whisperx\n","\n","        audio = whisperx.load_audio(wav_path)\n","        # Do constrained decoding by injecting reference text into WhisperX pipeline.\n","        # Practical trick: transcribe then replace segments' text with our gold sentence, then align.\n","        # We create a \"fake\" segment covering full utterance.\n","        duration = len(audio) / 16000.0\n","        norm_text = normalize_text_for_alignment(sentence_text)\n","\n","        # Build pseudo-segments using gold text\n","        segments = [{\"start\": 0.0, \"end\": duration, \"text\": norm_text}]\n","        result = {\"segments\": segments}\n","\n","        # Align with CTC model for word times\n","        aligned = whisperx.align(result[\"segments\"], self.alignment_model, self.metadata, audio, self.device)\n","\n","        words = []\n","        for seg in aligned[\"segments\"]:\n","            for w in seg.get(\"words\", []):\n","                # Filter tokens that aren't real words\n","                token = w.get(\"word\", \"\").strip()\n","                if _word_re.fullmatch(token):\n","                    words.append({\"word\": token, \"start\": w[\"start\"], \"end\": w[\"end\"]})\n","        return words\n","\n","# ---------- main word dataset builder ----------\n","\n","def build_word_dataset_from_sentence_clips(\n","    clips_folder: str,\n","    segments_dict: dict,\n","    out_folder: str = f\"{dataset_path}/custom_data/words\",\n","    pad_seconds: float = 0.0,\n","    min_word_dur: float = 0.05,\n","    max_word_dur: float = 1.5,\n","    skip_short_tokens=False\n","):\n","    \"\"\"\n","    clips_folder: your sentence-level clips (wav) created by extract_audio_segments(...)\n","    segments_dict: from your parse_stm_file, maps clip_id -> {\"text\": ..., \"talk_id\": ..., \"speaker\": ...}\n","    \"\"\"\n","    os.makedirs(out_folder, exist_ok=True)\n","    word_wavs = os.path.join(out_folder, \"wavs\")\n","    os.makedirs(word_wavs, exist_ok=True)\n","\n","    aligner = WhisperXAligner()\n","\n","    metadata_csv = os.path.join(out_folder, \"metadata_words.csv\")\n","    with open(metadata_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n","        writer = csv.writer(f, delimiter=\"|\")\n","        writer.writerow([\"path\", \"word\", \"phonemes\", \"speaker\", \"talk_id\", \"sentence_id\", \"start\", \"end\", \"dur\"])\n","\n","        clip_paths = sorted(glob.glob(os.path.join(clips_folder, \"*.wav\")))\n","        for i, clip_path in enumerate(clip_paths):\n","            # BEFORE\n","            # clip_id = os.path.splitext(os.path.basename(clip_path))[0]\n","            # meta = segments_dict.get(clip_id, {})\n","            # text = meta.get(\"text\", \"\")\n","            # if not text:\n","            #     continue\n","\n","            # AFTER\n","            base = os.path.splitext(os.path.basename(clip_path))[0]\n","            parts = base.split(\"_\")\n","            if len(parts) < 3:\n","                print(f\"[skip] bad filename: {base}\")\n","                continue\n","\n","            start = float(parts[-2])\n","            end = float(parts[-1])\n","            talk_id = \"_\".join(parts[:-2])\n","            time_range = f\"{start:.2f}_{end:.2f}\"   # <-- match your save format exactly\n","\n","            text_entry = segments_dict.get(talk_id, {}).get(time_range)\n","            if isinstance(text_entry, dict):\n","                text = text_entry.get(\"text\") or text_entry.get(\"sentence\") or text_entry.get(\"transcript\") or \"\"\n","            else:\n","                text = text_entry or \"\"\n","\n","            if not text:\n","                print(f\"[skip] no text for talk_id={talk_id} time={time_range}\")\n","                continue\n","\n","            # use 'base' as a stable sentence_id in your CSV, if you want:\n","            sentence_id = base\n","\n","\n","            # Align\n","            try:\n","                words = aligner.align_sentence(clip_path, text)\n","            except Exception as e:\n","                print(f\"[align-error] {sentence_id}: {e}\")\n","                continue\n","\n","            # Load audio once\n","            audio, sr = sf.read(clip_path)\n","            if audio.ndim > 1:\n","                audio = np.mean(audio, axis=1)\n","\n","            for j, w in enumerate(words):\n","                t0, t1 = w.get(\"start\"), w.get(\"end\")\n","                if t0 is None or t1 is None:\n","                    continue\n","                dur = float(t1 - t0)\n","                if skip_short_tokens and (dur < min_word_dur or dur > max_word_dur):\n","                    continue\n","\n","                word_audio = slice_audio(audio, sr, t0, t1, pad=pad_seconds)\n","                if len(word_audio) < int(0.002 * sr):  # robust min length\n","                    continue\n","\n","                token = w[\"word\"]\n","                phone = maybe_phonemes(token)\n","\n","                # Use talk_id + time_range for stable naming (not clip_id/meta)\n","                out_name = f\"{talk_id}_{time_range}__{j:03d}_{token}.wav\"\n","                out_path = os.path.join(word_wavs, out_name)\n","                sf.write(out_path, word_audio, sr)\n","\n","                writer.writerow([\n","                    os.path.relpath(out_path, out_folder),  # path\n","                    token,                                  # word\n","                    phone,                                  # phonemes\n","                    \"\",                                     # speaker (fill if you have it)\n","                    talk_id,                                # talk_id\n","                    sentence_id,                            # sentence_id == \"<talk_id>_<start>_<end>\"\n","                    f\"{t0:.3f}\", f\"{t1:.3f}\", f\"{dur:.3f}\",\n","                ])\n","    print(f\"Done. Wrote single-word clips + {metadata_csv}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"YcGQ50L3Rybt"},"source":["### Dataset Convertor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Go7hMvWR03s"},"outputs":[],"source":["# Simplified TextMelDataset (same interface, minimal logic)\n","import os\n","import csv\n","import random\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset\n","\n","\n","class TextMelDataset(Dataset):\n","    def __init__(\n","        self,\n","        words_folder: str,\n","        metadata_csv: str,\n","        specific_items=None,  # list of talk_id or sentence_id strings\n","        shuffle: bool = False,\n","        use_phonemes: bool = True,\n","    ):\n","        self.mel_dim = 80\n","        self.words_folder = words_folder\n","        self.use_phonemes = use_phonemes\n","\n","        # Load all rows once\n","        if not os.path.exists(metadata_csv):\n","            raise FileNotFoundError(f\"metadata csv not found: {metadata_csv}\")\n","        with open(metadata_csv, \"r\", encoding=\"utf-8\") as f:\n","            reader = csv.DictReader(f, delimiter=\"|\")\n","            rows = list(reader)\n","\n","        # Optional filter by talk_id or sentence_id\n","        if specific_items:\n","            keep = set(specific_items)\n","            filt = []\n","            for r in rows:\n","                if (r.get(\"talk_id\") in keep) or (r.get(\"sentence_id\") in keep):\n","                    filt.append(r)\n","            rows = filt\n","\n","        self.rows = rows\n","\n","        # Build index order\n","        self.indices = list(range(len(self.rows)))\n","        if shuffle:\n","            random.seed(1234)\n","            random.shuffle(self.indices)\n","\n","    def __len__(self):\n","        return len(self.rows)\n","\n","    def _load_mel(self, wav_path: str) -> torch.Tensor:\n","        \"\"\"Create [T, mel_dim] FloatTensor using the global wav_to_mel.\"\"\"\n","        mel = wav_to_mel(wav_path)         # [80, T] np.float32 (dB)\n","        mel = torch.from_numpy(mel.T).float()  # [T, 80]\n","        if mel.size(1) != self.mel_dim:\n","            raise RuntimeError(f\"Mel dim mismatch: {mel.size(1)} != {self.mel_dim}\")\n","        return mel\n","\n","    def _get_text(self, row) -> torch.Tensor:\n","        word = (row.get(\"word\") or \"\").strip()\n","        phon = (row.get(\"phonemes\") or \"\").strip()\n","        text = phon if (self.use_phonemes and phon) else word\n","        if not text:\n","            text = word or phon or \"\"\n","        ids = text_to_sequence(text)\n","        return torch.IntTensor(ids)\n","\n","    def __getitem__(self, index):\n","        row = self.rows[self.indices[index]]\n","        rel_path = (row.get(\"path\") or \"\").strip()\n","        wav_path = os.path.join(self.words_folder, rel_path)\n","        if not os.path.exists(wav_path):\n","            raise FileNotFoundError(f\"Missing wav: {wav_path}\")\n","        # mel = self._load_mel(wav_path)\n","        word = (row.get(\"word\") or \"\").strip()\n","        mel = text_to_mel(word)\n","        text_ids = self._get_text(row)\n","        return text_ids, mel\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cjlxazJ9Sfq_"},"outputs":[],"source":["class TextMelCollate():\n","    \"\"\" Zero-pads model inputs and targets based on number of frames per step\n","    \"\"\"\n","    def __init__(self, r):\n","        self.r = r\n","\n","    def __call__(self, batch):\n","        \"\"\"Collate's training batch from normalized text and mel-spectrogram\n","        PARAMS\n","        ------\n","        batch: [text_normalized, mel_normalized]\n","        \"\"\"\n","        # Right zero-pad all one-hot text sequences to max input length\n","        input_lengths, ids_sorted_decreasing = torch.sort(\n","            torch.LongTensor([len(x[0]) for x in batch]),\n","            dim=0, descending=True)\n","        max_input_len = input_lengths[0]\n","\n","        text_padded = torch.LongTensor(len(batch), max_input_len)\n","        text_padded.zero_()\n","        for i in range(len(ids_sorted_decreasing)):\n","            text = batch[ids_sorted_decreasing[i]][0]\n","            text_padded[i, :text.size(0)] = text\n","\n","        # Right zero-pad mel-spec\n","        num_mels = batch[0][1].size(1)\n","        max_target_len = max([x[1].size(0) for x in batch])\n","        if max_target_len % self.r != 0:\n","            max_target_len += self.r - max_target_len % self.r\n","            assert max_target_len % self.r == 0\n","\n","        # include mel padded and gate padded\n","        mel_padded = torch.FloatTensor(len(batch), max_target_len, num_mels)\n","        mel_padded.zero_()\n","        gate_padded = torch.FloatTensor(len(batch), max_target_len)\n","        gate_padded.zero_()\n","        output_lengths = torch.LongTensor(len(batch))\n","        for i in range(len(ids_sorted_decreasing)):\n","            mel = batch[ids_sorted_decreasing[i]][1]\n","            mel_padded[i, :mel.size(0), :] = mel\n","            gate_padded[i, mel.size(0)-1:] = 1\n","            output_lengths[i] = mel.size(0)\n","\n","        return text_padded, input_lengths, mel_padded, gate_padded, output_lengths\n"]},{"cell_type":"markdown","metadata":{"id":"dRLiJLNE_fFq"},"source":["### Mel Spectogran Figure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"THJfcjZveS7e"},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3sftXQyX_fFq"},"outputs":[],"source":["def show_or_save_mel_spectrogram(mel, title=\"Mel Spectrogram\", save_path=None, cmap=\"magma\"):\n","    \"\"\"\n","    Display or save a Mel spectrogram (NumPy array) as an image.\n","\n","    Args:\n","        mel (np.ndarray): 2D or 3D Mel spectrogram. Shape should be (time, mel) or (1, time, mel).\n","        title (str): Title of the plot.\n","        save_path (str): If provided, saves the image to this path.\n","        cmap (str): Colormap for visualization (e.g., \"magma\", \"inferno\", \"viridis\").\n","    \"\"\"\n","    if mel.ndim == 3:\n","        mel = mel[0]  # Remove batch dimension if present\n","\n","    plt.figure(figsize=(10, 4))\n","    plt.imshow(mel.T, aspect='auto', origin='lower', cmap=cmap)\n","    plt.title(title)\n","    plt.xlabel(\"Time\")\n","    plt.ylabel(\"Mel Frequency Channels\")\n","    plt.colorbar(format='%+2.0f dB')\n","\n","    if save_path:\n","        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n","        plt.savefig(save_path)\n","        print(f\"Saved mel spectrogram to {save_path}\")\n","        plt.close()\n","    else:\n","        plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"DBDQ8koyOBRf"},"source":["## Model Architecture"]},{"cell_type":"markdown","metadata":{"id":"KHilLOV3OBRf"},"source":["### Set Logger"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WOhSSGakeJ_p"},"outputs":[],"source":["import copy\n","\n","DEFAULT_T2_CFG = {\n","    \"encoder\": {\n","        \"num_convs\": 3,\n","        \"conv_channels\": 512,\n","        \"conv_kernel_size\": 5,\n","        \"conv_dropout\": 0.5,\n","        \"blstm_units\": 512,\n","    },\n","    \"decoder\": {\n","        \"prenet_dims\": [256, 256],\n","        \"prenet_dropout\": 0.5,\n","        \"attention_dim\": 128,\n","        \"attention_rnn_units\": 1024,\n","        \"attention_dropout\": 0.1,\n","        \"attention_location_filters\": 32,\n","        \"attention_location_kernel_size\": 31,\n","        \"decoder_rnn_units\": 1024,\n","        \"decoder_rnn_layers\": 2,\n","        \"decoder_dropout\": 0.1,\n","    },\n","    \"postnet\": {\n","        \"num_convs\": 5,\n","        \"conv_channels\": 512,\n","        \"conv_kernel_size\": 5,\n","        \"conv_dropout\": 0.5,\n","    },\n","}\n","\n","\n","def create_model():\n","    \"\"\"\n","    Create TextToMelSpectrogramModel model.\n","    \"\"\"\n","    model_cfg = copy.deepcopy(DEFAULT_T2_CFG)\n","\n","    model = TextToMelSpectrogramModel(\n","        model_cfg=model_cfg,\n","        embed_dim=512,\n","        mel_dim=80,\n","        max_decoder_steps=1000,\n","        stop_threshold=0.5,\n","        r=3,\n","    )\n","\n","    criterion = TextToMelSpectrogramLoss()\n","    return model, criterion\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aK06htwHeKWy"},"outputs":[],"source":["import re\n","from typing import List\n","\n","_pad = \"_\"\n","_eos = \"~\"\n","_ascii_chars = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz!'\\\"(),-.:;? %/\"\n","_digits = \"0123456789\"\n","\n","EN_SYMBOLS: List[str] = [_pad, _eos] + list(_ascii_chars) + list(_digits)\n","_symbol_to_id = {s: i for i, s in enumerate(EN_SYMBOLS)}\n","_id_to_symbol = {i: s for i, s in enumerate(EN_SYMBOLS)}\n","\n","_whitespace_re = re.compile(r\"\\s+\")\n","\n","def basic_cleaners(text: str) -> str:\n","    text = text.lower()\n","    text = _whitespace_re.sub(\" \", text)\n","    return text.strip()\n","\n","\n","def symbols(lang: str = \"en\") -> List[str]:\n","    return EN_SYMBOLS\n","\n","\n","def _symbols_to_sequence(chars: List[str]) -> List[int]:\n","    return [_symbol_to_id[c] for c in chars if c in _symbol_to_id]\n","\n","\n","def text_to_sequence(text: str) -> List[int]:\n","    text = basic_cleaners(text)\n","    seq = _symbols_to_sequence(list(text))\n","    seq.append(_symbol_to_id[_eos])\n","    return seq\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DXOtmsgXhvcF"},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","\n","class TextToMelSpectrogramLogger(SummaryWriter):\n","    def __init__(self, logdir: str):\n","        super().__init__(logdir)\n","\n","    def log_training(self, loss, grad_norm, learning_rate, duration, iteration: int):\n","        self.add_scalar(\"training.loss\", float(loss), iteration)\n","        self.add_scalar(\"grad.norm\", float(grad_norm), iteration)\n","        self.add_scalar(\"learning.rate\", float(learning_rate), iteration)\n","        self.add_scalar(\"duration\", float(duration), iteration)\n","\n","    def log_validation(self, loss, model, targets, predicts, iteration: int):\n","        self.add_scalar(\"validation.loss\", float(loss), iteration)\n","        return"]},{"cell_type":"markdown","metadata":{"id":"Md_9eZkrOBRg"},"source":["### Create TextToMelSpectrogram Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_pLfF0qVg-pE"},"outputs":[],"source":["from math import sqrt\n","import torch\n","from torch import nn\n","\n","\n","class BahdanauAttention(nn.Module):\n","    \"\"\"Additive attention that produces alignment over encoder memory.\"\"\"\n","    def __init__(self, query_dim: int, attn_dim: int, score_mask_value: float = -float(\"inf\")):\n","        super().__init__()\n","        self.query_layer = nn.Linear(query_dim, attn_dim, bias=False)\n","        self.tanh = nn.Tanh()\n","        self.v = nn.Linear(attn_dim, 1, bias=False)\n","        self.score_mask_value = score_mask_value\n","\n","    def forward(self, query, processed_memory, mask=None):\n","        if query.dim() == 2:\n","            query = query.unsqueeze(1)\n","        energies = self.get_energies(query, processed_memory)\n","        if mask is not None:\n","            energies.data.masked_fill_(mask.view(query.size(0), -1), self.score_mask_value)\n","        return self.get_probabilities(energies)\n","\n","    def init_attention(self, processed_memory):\n","        return\n","\n","    def get_energies(self, query, processed_memory):\n","        processed_query = self.query_layer(query)\n","        alignment = self.v(self.tanh(processed_query + processed_memory))\n","        return alignment.squeeze(-1)\n","\n","    def get_probabilities(self, energies):\n","        return nn.Softmax(dim=1)(energies)\n","\n","\n","class LocationSensitiveAttention(BahdanauAttention):\n","    \"\"\"Location-sensitive attention that incorporates cumulative alignment history.\"\"\"\n","    def __init__(self, query_dim, attn_dim, filters=32, kernel_size=31, score_mask_value=-float(\"inf\")):\n","        super().__init__(query_dim, attn_dim, score_mask_value)\n","        self.conv = nn.Conv1d(1, filters, kernel_size=kernel_size, padding=(kernel_size - 1) // 2, bias=True)\n","        self.L = nn.Linear(filters, attn_dim, bias=False)\n","        self.cumulative = None\n","\n","    def init_attention(self, processed_memory):\n","        b, t, _ = processed_memory.size()\n","        self.cumulative = processed_memory.data.new(b, t).zero_()\n","\n","    def get_energies(self, query, processed_memory):\n","        processed_query = self.query_layer(query)\n","        processed_loc = self.L(self.conv(self.cumulative.unsqueeze(1)).transpose(1, 2))\n","        alignment = self.v(self.tanh(processed_query + processed_memory + processed_loc))\n","        return alignment.squeeze(-1)\n","\n","    def get_probabilities(self, energies):\n","        alignment = nn.Softmax(dim=1)(energies)\n","        self.cumulative = self.cumulative + alignment\n","        return alignment\n","\n","\n","def get_mask_from_lengths(memory, memory_lengths):\n","    mask = memory.data.new(memory.size(0), memory.size(1)).byte().zero_()\n","    for idx, l in enumerate(memory_lengths):\n","        mask[idx][:l] = 1\n","    return mask == 0\n","\n","\n","class AttentionWrapper(nn.Module):\n","    \"\"\"Wraps an RNN cell with attention over encoder memory.\"\"\"\n","    def __init__(self, rnn_cell, attention_mechanism):\n","        super().__init__()\n","        self.rnn_cell = rnn_cell\n","        self.attention_mechanism = attention_mechanism\n","\n","    def forward(self, query, attention, cell_state, memory, processed_memory=None, mask=None, memory_lengths=None):\n","        if processed_memory is None:\n","            processed_memory = memory\n","        if memory_lengths is not None and mask is None:\n","            mask = get_mask_from_lengths(memory, memory_lengths)\n","\n","        cell_input = torch.cat((query, attention), -1)\n","        cell_output = self.rnn_cell(cell_input, cell_state)\n","        query = cell_output[0] if isinstance(self.rnn_cell, nn.LSTMCell) else cell_output\n","\n","        alignment = self.attention_mechanism(query, processed_memory, mask)\n","        attention = torch.bmm(alignment.unsqueeze(1), memory).squeeze(1)\n","        return cell_output, attention, alignment\n","\n","\n","class Prenet(nn.Module):\n","    def __init__(self, in_dim, sizes=[256, 128], dropout=0.5):\n","        super().__init__()\n","        in_sizes = [in_dim] + sizes[:-1]\n","        self.layers = nn.ModuleList([nn.Linear(i, o) for i, o in zip(in_sizes, sizes)])\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        for linear in self.layers:\n","            x = self.dropout(self.relu(linear(x)))\n","        return x\n","\n","\n","class BatchNormConv1d(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, activation=None):\n","        super().__init__()\n","        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n","        self.bn = nn.BatchNorm1d(out_channels)\n","        self.activation = activation\n","\n","    def forward(self, x):\n","        x = self.conv1d(x)\n","        if self.activation is not None:\n","            x = self.activation(x)\n","        return self.bn(x)\n","\n","\n","class BatchNormConv1dStack(nn.Module):\n","    def __init__(self, in_channel, out_channels=[512, 512, 512], kernel_size=3, stride=1, padding=1, activations=None, dropout=0.5):\n","        super().__init__()\n","        if activations is None:\n","            activations = [None] * len(out_channels)\n","        in_sizes = [in_channel] + out_channels[:-1]\n","        self.convs = nn.ModuleList([\n","            BatchNormConv1d(i, o, kernel_size=kernel_size, stride=stride, padding=padding, activation=ac)\n","            for i, o, ac in zip(in_sizes, out_channels, activations)\n","        ])\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        for conv in self.convs:\n","            x = self.dropout(conv(x))\n","        return x\n","\n","\n","class Postnet(nn.Module):\n","    def __init__(self, mel_dim, num_convs=5, conv_channels=512, conv_kernel_size=5, conv_dropout=0.5):\n","        super().__init__()\n","        activations = [torch.tanh] * (num_convs - 1) + [None]\n","        channels = [conv_channels] * (num_convs - 1) + [mel_dim]\n","        self.convs = BatchNormConv1dStack(\n","            mel_dim,\n","            channels,\n","            kernel_size=conv_kernel_size,\n","            stride=1,\n","            padding=(conv_kernel_size - 1) // 2,\n","            activations=activations,\n","            dropout=conv_dropout,\n","        )\n","\n","    def forward(self, x):\n","        return self.convs(x.transpose(1, 2)).transpose(1, 2)\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, embed_dim, num_convs=3, conv_channels=512, conv_kernel_size=5, conv_dropout=0.5, blstm_units=512):\n","        super().__init__()\n","        activations = [nn.ReLU()] * num_convs\n","        channels = [conv_channels] * num_convs\n","        self.convs = BatchNormConv1dStack(\n","            embed_dim,\n","            channels,\n","            kernel_size=conv_kernel_size,\n","            stride=1,\n","            padding=(conv_kernel_size - 1) // 2,\n","            activations=activations,\n","            dropout=conv_dropout,\n","        )\n","        self.lstm = nn.LSTM(conv_channels, blstm_units // 2, 1, batch_first=True, bidirectional=True)\n","\n","    def forward(self, x):\n","        x = self.convs(x.transpose(1, 2)).transpose(1, 2)\n","        self.lstm.flatten_parameters()\n","        outputs, _ = self.lstm(x)\n","        return outputs\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, mel_dim, r, encoder_output_dim, prenet_dims=[256, 256], prenet_dropout=0.5, attention_dim=128, attention_rnn_units=1024, attention_dropout=0.1, attention_location_filters=32, attention_location_kernel_size=31, decoder_rnn_units=1024, decoder_rnn_layers=2, decoder_dropout=0.1, max_decoder_steps=1000, stop_threshold=0.5):\n","        super().__init__()\n","        self.mel_dim = mel_dim\n","        self.r = r\n","        self.attention_context_dim = encoder_output_dim\n","        self.attention_rnn_units = attention_rnn_units\n","        self.decoder_rnn_units = decoder_rnn_units\n","        self.max_decoder_steps = max_decoder_steps\n","        self.stop_threshold = stop_threshold\n","\n","        self.prenet = Prenet(mel_dim, prenet_dims, prenet_dropout)\n","        self.attention_rnn = AttentionWrapper(\n","            nn.LSTMCell(prenet_dims[-1] + encoder_output_dim, attention_rnn_units),\n","            LocationSensitiveAttention(attention_rnn_units, attention_dim, filters=attention_location_filters, kernel_size=attention_location_kernel_size),\n","        )\n","        self.attention_dropout = nn.Dropout(attention_dropout)\n","        self.memory_layer = nn.Linear(encoder_output_dim, attention_dim, bias=False)\n","\n","        self.decoder_rnn = nn.LSTMCell(attention_rnn_units + encoder_output_dim, decoder_rnn_units)\n","        self.decoder_dropout = nn.Dropout(decoder_dropout)\n","\n","        self.mel_proj = nn.Linear(decoder_rnn_units + encoder_output_dim, mel_dim * self.r)\n","        self.stop_proj = nn.Linear(decoder_rnn_units + encoder_output_dim, 1)\n","\n","    def forward(self, encoder_outputs, inputs=None, memory_lengths=None):\n","        bsz = encoder_outputs.size(0)\n","        processed_memory = self.memory_layer(encoder_outputs)\n","        mask = get_mask_from_lengths(processed_memory, memory_lengths) if memory_lengths is not None else None\n","        greedy = inputs is None\n","        if inputs is not None:\n","            inputs = inputs.transpose(0, 1)\n","            T_decoder = inputs.size(0)\n","\n","        go_frame = encoder_outputs.data.new(bsz, self.mel_dim).zero_()\n","        self.attention_rnn.attention_mechanism.init_attention(processed_memory)\n","        attn_h = encoder_outputs.data.new(bsz, self.attention_rnn_units).zero_()\n","        attn_c = encoder_outputs.data.new(bsz, self.attention_rnn_units).zero_()\n","        dec_h = encoder_outputs.data.new(bsz, self.decoder_rnn_units).zero_()\n","        dec_c = encoder_outputs.data.new(bsz, self.decoder_rnn_units).zero_()\n","        attn_ctx = encoder_outputs.data.new(bsz, self.attention_context_dim).zero_()\n","\n","        mel_outputs, attn_scores, stop_tokens = [], [], []\n","        t = 0\n","        current = go_frame\n","        while True:\n","            if t > 0:\n","                current = mel_outputs[-1][:, -1, :] if greedy else inputs[t - 1]\n","            t += self.r\n","\n","            current = self.prenet(current)\n","            (attn_h, attn_c), attn_ctx, attn_score = self.attention_rnn(\n","                current, attn_ctx, (attn_h, attn_c), encoder_outputs, processed_memory=processed_memory, mask=mask\n","            )\n","            attn_h = self.attention_dropout(attn_h)\n","\n","            dec_input = torch.cat((attn_h, attn_ctx), -1)\n","            dec_h, dec_c = self.decoder_rnn(dec_input, (dec_h, dec_c))\n","            dec_h = self.decoder_dropout(dec_h)\n","\n","            proj_in = torch.cat((dec_h, attn_ctx), -1)\n","            out = self.mel_proj(proj_in).view(bsz, -1, self.mel_dim)\n","            stop = torch.sigmoid(self.stop_proj(proj_in))\n","\n","            mel_outputs.append(out)\n","            attn_scores.append(attn_score.unsqueeze(1))\n","            stop_tokens.extend([stop] * self.r)\n","\n","            if greedy:\n","                if stop > self.stop_threshold or t > self.max_decoder_steps:\n","                    break\n","            else:\n","                if t >= T_decoder:\n","                    break\n","\n","        mel_outputs = torch.cat(mel_outputs, dim=1)\n","        attn_scores = torch.cat(attn_scores, dim=1)\n","        stop_tokens = torch.cat(stop_tokens, dim=1)\n","        assert greedy or mel_outputs.size(1) == T_decoder\n","        return mel_outputs, stop_tokens, attn_scores\n","\n","\n","class TextToMelSpectrogramModel(nn.Module):\n","    def __init__(self, model_cfg, embed_dim=512, mel_dim=80, max_decoder_steps=1000, stop_threshold=0.5, r=3):\n","        super().__init__()\n","        self.mel_dim = mel_dim\n","        self.embedding = nn.Embedding(1, embed_dim)\n","        std = sqrt(2.0 / (1 + embed_dim))\n","        val = sqrt(3.0) * std\n","        self.embedding.weight.data.uniform_(-val, val)\n","\n","        enc_cfg = model_cfg[\"encoder\"]\n","        self.encoder = Encoder(embed_dim, **enc_cfg)\n","        encoder_out_dim = enc_cfg[\"blstm_units\"]\n","\n","        dec_cfg = model_cfg[\"decoder\"]\n","        self.decoder = Decoder(mel_dim, r, encoder_out_dim, **dec_cfg, max_decoder_steps=max_decoder_steps, stop_threshold=stop_threshold)\n","\n","        self.postnet = Postnet(mel_dim, **model_cfg[\"postnet\"])\n","\n","    def parse_data_batch(self, batch):\n","        device = next(self.parameters()).device\n","        text, text_length, mel, stop, _ = batch\n","        return (text.to(device).long(), text_length.to(device).long(), mel.to(device).float()), (mel.to(device).float(), stop.to(device).float())\n","\n","    def forward(self, inputs):\n","        inputs, input_lengths, mels = inputs\n","        x = self.embedding(inputs)\n","        enc_out = self.encoder(x)\n","        mel_out, stop_tokens, alignments = self.decoder(enc_out, mels, memory_lengths=input_lengths)\n","        mel_post = self.postnet(mel_out)\n","        mel_post = mel_out + mel_post\n","        return mel_out, mel_post, stop_tokens, alignments\n","\n","    def inference(self, inputs):\n","        return self.forward((inputs, None, None))\n","\n","\n","class TextToMelSpectrogramLoss(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, predicts, targets):\n","        mel_target, stop_target = targets\n","        mel_target.requires_grad = False\n","        stop_target.requires_grad = False\n","        mel_pred, mel_post_pred, stop_pred, _ = predicts\n","        mel_loss = nn.MSELoss()(mel_pred, mel_target)\n","        post_loss = nn.MSELoss()(mel_post_pred, mel_target)\n","        stop_loss = nn.BCELoss()(stop_pred, stop_target)\n","        return mel_loss + post_loss + stop_loss\n"]},{"cell_type":"markdown","metadata":{"id":"bN_BZpZ8OBRg"},"source":["### Build Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r93ZMX2lOBRh","outputId":"fe88e5de-6d2c-44a2-cb55-232066bfcd83"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n","\n","Initialising Tacotron Model...\n","\n"]}],"source":["torch.manual_seed(1234)\n","torch.cuda.manual_seed(1234)\n","\n","# Prepare device\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")\n","print(\"Using device:\", device)\n","\n","\n","# Instantiate TextToMelSpectrogram Model\n","print(\"\\nInitialising TextToMelSpectrogram Model...\\n\")\n","model, criterion = create_model()\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gT-2RO39OBRh"},"outputs":[],"source":["# Initialize the optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3PpS7bgFOBRh"},"outputs":[],"source":["# Prepare directory and logger\n","output_dir = ''\n","log_dir = os.path.join(audio_outputs_folder, \"logs\")\n","\n","os.makedirs(audio_outputs_folder, exist_ok=True)\n","logger = TextToMelSpectrogramLogger(log_dir)\n"]},{"cell_type":"markdown","metadata":{"id":"aH9qGPwVOBRh"},"source":["### Speaker Embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PymVbbESOBRh"},"outputs":[],"source":["MAX_CHUNKS = 5\n","CHUNK_DURATION_SEC = 5\n","CHUNK_LEN = 16000 * CHUNK_DURATION_SEC\n","HIDDEN_DIM = 1024  # from Wav2Vec2\n","\n","def extract_wav2vec_features_fixed(audio_path, processor, model):\n","    waveform, sr = torchaudio.load(audio_path)\n","    if sr != 16000:\n","        waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n","\n","    total_len = waveform.shape[1]\n","    embeddings = []\n","\n","    for i in range(MAX_CHUNKS):\n","        start = i * CHUNK_LEN\n","        end = start + CHUNK_LEN\n","\n","        if start >= total_len:\n","            break  # no more data\n","\n","        chunk = waveform[:, start:end]\n","        if chunk.shape[1] < CHUNK_LEN:\n","            # Pad short chunk with zeros\n","            pad = torch.zeros((1, CHUNK_LEN - chunk.shape[1]))\n","            chunk = torch.cat((chunk, pad), dim=1)\n","\n","        inputs = processor(chunk.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\").input_values.to(DEVICE)\n","        with torch.no_grad():\n","            outputs = model(inputs)\n","        emb = outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # shape: (1, HIDDEN_DIM)\n","        embeddings.append(emb)\n","\n","        del inputs, outputs\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","    # Pad with zero-vectors if we didn't get enough chunks\n","    while len(embeddings) < MAX_CHUNKS:\n","        embeddings.append(np.zeros((1, HIDDEN_DIM)))\n","\n","    final_embedding = np.concatenate(embeddings, axis=1)  # shape: (1, MAX_CHUNKS * HIDDEN_DIM)\n","    return final_embedding\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mwsQig7SOBRh"},"outputs":[],"source":["def create_speaker_embeddings(dataset, wav2vec_processor, wav2vec_model):\n","    processor = wav2vec_processor\n","    model = wav2vec_model\n","\n","    speaker_embeddings = dict()\n","\n","    for i, (full_talk_wav_path, _, _, _) in enumerate(tqdm(dataset, desc=\"Generating speaker embeddings\")):\n","      if full_talk_wav_path not in speaker_embeddings:\n","        speaker_embedding = extract_wav2vec_features_fixed(full_talk_wav_path, processor, model)  # shape (1, hidden_dim)\n","        speaker_embeddings[full_talk_wav_path] = speaker_embedding\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return speaker_embeddings\n"]},{"cell_type":"markdown","metadata":{"id":"mbowSHavOBRh"},"source":["### Build Models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AU6GcjZoOBRh","outputId":"97a82e66-f922-4a66-aa55-61516dc50eb2"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['masked_spec_embed']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[NeMo W 2025-08-21 18:02:11 nemo_logging:405] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    dataset:\n","      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n","      manifest_filepath: /home/fkreuk/data/train_finetune.txt\n","      min_duration: 0.75\n","      n_segments: 8192\n","    dataloader_params:\n","      drop_last: false\n","      shuffle: true\n","      batch_size: 64\n","      num_workers: 4\n","    \n","[NeMo W 2025-08-21 18:02:11 nemo_logging:405] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    dataset:\n","      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n","      manifest_filepath: /home/fkreuk/data/val_finetune.txt\n","      min_duration: 3\n","      n_segments: 66150\n","    dataloader_params:\n","      drop_last: false\n","      shuffle: false\n","      batch_size: 5\n","      num_workers: 4\n","    \n","[NeMo W 2025-08-21 18:02:11 nemo_logging:405] Using torch_stft is deprecated and has been removed. The values have been forcibly set to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2025-08-21 18:02:11 nemo_logging:393] PADDING: 0\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2025-08-21 18:02:11 nemo_logging:405] Using torch_stft is deprecated and has been removed. The values have been forcibly set to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2025-08-21 18:02:11 nemo_logging:393] PADDING: 0\n","[NeMo I 2025-08-21 18:02:12 nemo_logging:393] Model HifiGanModel was successfully restored from /root/.cache/huggingface/hub/models--nvidia--tts_hifigan/snapshots/3ba1fed954276287015654bf4c78060ffc9a4772/tts_hifigan.nemo.\n"]}],"source":["DEVICE = 'cuda'\n","wav2vec_processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n","wav2vec_model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-large-960h\", use_safetensors=True).to(DEVICE)\n","hifigan_model = HifiGanModel.from_pretrained(model_name=\"nvidia/tts_hifigan\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LaAArX3e_fFr"},"source":["## Create Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"xn5EsXDk_fFr","outputId":"88304a65-57e0-4395-b683-6a13a6f92f3f"},"outputs":[{"name":"stdout","output_type":"stream","text":["['/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AbeDavis_2015.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AdamOckelford_2013X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AdamDavidson_2012S.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AJJacobs_2014A.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AJJacobs_2014A (1).wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AdamdelaZerda_2016X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlanSmith_2016X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AdamGrant_2016S.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AditiGupta_2015X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AdamFoss_2016.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlejandroAravena_2014G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AimeeMullins_2009U.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlessandraOrofino_2014G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AditiShankardass_2009I.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AdamSpencer_2013.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlastairParvin_2013.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlanRussell_2006.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlaindeBotton_2011G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlaindeBotton_2009G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlexTabarrok_2009.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlexKipman_2016.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlexWissnerGross_2013X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlexSteffen_2011G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlexanderTsiaras_2010P.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlexLaskey_2013.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlexanderBetts_2016T.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlexisOhanian_2009I.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlanSiegel_2010.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlanKay_2007.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AllanAdams_2016.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlisonGopnik_2011G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlexSteffen_2005G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlGore_2006.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlGore_2016.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlwarBalasubramaniam_2009I.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlexanderBetts_2016.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlisonKilling_2014X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmyWebb_2013S.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlisaMiller_2008.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmyLockwood_2011G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlisonKilling_2014U.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmiKlin_2011X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlGore_2008.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmandaBurden_2014.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndrewConnolly_2014.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AliceGoffman_2015.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndrewBastawrous_2014U.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndreasSchleicher_2012G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AliceBowsLarkin_2015G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AliCarrChellman_2010X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndersFjellberg_2015G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AliceRawsthorn_2016.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlVernacchio_2012.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AllanAdams_2014.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnilAnanthaswamy_2010P.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AllisonHunt_2007.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndrewMwenda_2007G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AliceDreger_2011X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlisonJackson_2005G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndrewMcAfee_2013.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AliciaGarzaandPatrisseCullorsandOpalTometi_2016W.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AshadeVos_2014U.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmandaBennett_2013P.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/ArthurGanson_2004.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AllanJones_2011G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AparnaRao_2013U.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlSeckel_2004.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnupamMishra_2009I.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlyssaMonks_2015X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnnCooper_2007P.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlixGenerous_2015W.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmeeraHarouda_2016.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AudreyChoi_2015S.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmberCase_2010W.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmitSood_2011.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AstroTeller_2016.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AllanSavory_2013.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AshleyJudd_2016W.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AlysonMcGregor_2014X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AshBeckham_2014X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmoryLovins_2012S.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmoryLovins_2005.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmyAdeleHasinoff_2016X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmitSood_2016.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AzizAbuSarah_2014U.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmeenahGuribFakim_2014G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmandaPalmer_2013.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AyahBdeir_2012U.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AviRubin_2011X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmosWinter_2012X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnandGiridharadas_2015.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnandGiridharadas_2016T.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnandaShankar_2009I.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmySmith_2006.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmyGreen_2017S.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmyPurdy_2011X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnandVarma_2015.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnandAgarawala_2007.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnastasiaTaylorLind_2014U.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmyTan_2008.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AmyCuddy_2012G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnantAgarwal_2013G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnasAremeyawAnas_2013.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndreasRaptopoulos_2013G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndreasEkstrom_2015X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndrasForgacs_2013G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndersYnnerman_2010X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndresRuzo_2014G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndreaGhez_2009G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndresLozano_2013X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndrewFitzgerald_2013S.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndrewBlum_2012G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndrewPelling_2016U.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndyHobsbawm_2008.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndrewSolomon_2014.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndrewBird_2010.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndrewMcAfee_2012X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndrewYoun_2016.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndrewSolomon_2013X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndrewSolomon_2013P.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AngelaPatton_2012X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndyPuddicombe_2012S.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AniLiu_2016X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AngeloVermeulen_2014U.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AngelaDuckworth_2013S.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AndyYen_2014G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnjaliTripathi_2015X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AngelicaDass_2016.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AngelaBelcher_2011X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnnieLennox_2010G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnnaMracekDietrich_2011G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnnMarieThomas_2011.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnilGupta_2009I.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnneLamott_2017.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnneMilgram_2013S.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnnetteHeuser_2013G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnneMarieSlaughter_2013G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnneCurzan_2014X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnnieMurphyPaul_2011G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnthonyGoldbloom_2016U.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnnaDeavereSmith_2005.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AntonyGormley_2012G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnthonyDRomero_2017.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnnMorgan_2015G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AomawaShields_2015U.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AntonioDamasio_2011.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnthonyAtala_2009P.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnthonyAtala_2011.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AriannaHuffington_2010W.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AnoteTong_2015Z.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AntonioGuterres_2015G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/ArisVenetikidis_2012X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/ArthurBenjamin_2005.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/ArielGarten_2011X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/ArthurBrooks_2016.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AriWallach_2016X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AparnaRao_2011G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/ApolloRobbins_2013G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/ArthurBenjamin_2013G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/ArthurBenjamin_2009.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/ArunachalamMuruganantham_2012S.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AshBeckham_2013X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/ArthurPottsDawson_2010G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AshtonCofer_2016Y.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AsherHasan_2009I.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AtulGawande_2012.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AshrafGhani_2005G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/ArvindGupta_2010P.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AspenBaker_2015W.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AzizaChaouni_2014U.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AubreydeGrey_2005G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AuretvanHeerden_2010G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AukeIjspeert_2015G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AviReichental_2014.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/911Mothers_2010W.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AaronHuey_2010X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AalaElKhani_2016X.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AbhaDawesar_2013G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AaronOConnell_2011.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AaronKoblin_2011.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AchenyoIdachaba_2015W.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AbrahamVerghese_2011G.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AbigailWashburn_2012U.wav', '/content/drive/MyDrive/final_project/Dataset_3/custom_data/wavs/AbigailMarsh_2016T.wav']\n"]},{"name":"stderr","output_type":"stream","text":["Creating full talks mel: 100%|██████████| 184/184 [05:07<00:00,  1.67s/it]\n","Segmenting audio: 100%|██████████| 10000/10000 [1:25:09<00:00,  1.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Preprocessing done. 10000 clips created.\n"]}],"source":["import_from_local = False\n","all_segments_dict = []\n","if import_from_local:\n","    clips_folder = f'{dataset_path}/custom_data/clips'\n","    # clips_folder = f'{dataset_path}/custom_data_phoneme/clips'\n","    print(clips_folder)\n","    with open(f\"{dataset_path}/all_segments_dict.pkl\", \"rb\") as f:\n","        all_segments_dict = pickle.load(f)\n","    with open(f\"{dataset_path}/full_talks_mel.pkl\", \"rb\") as f:\n","        full_talks_mel = pickle.load(f)\n","\n","else:\n","    target_dataset_size = 10000\n","    clips_folder, all_segments_dict, full_talks_mel = preprocess_tedlium(dataset_path, target_dataset_size, max_files=100000, output_path=f'{dataset_path}/custom_data', _convert_sph_to_wav=False)\n","    with open(f\"{dataset_path}/all_segments_dict.pkl\", \"wb\") as f:\n","        pickle.dump(all_segments_dict, f)\n","\n","    with open(f\"{dataset_path}/full_talks_mel.pkl\", \"wb\") as f:\n","        pickle.dump(full_talks_mel, f)\n"]},{"cell_type":"markdown","metadata":{"id":"MfuvAVHN2zon"},"source":["### One-word based dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"referenced_widgets":["f2a264fbbed14343870cf2638991ffb5","3bd7aa5987a54ca184f22f7c06fec0b1","fcb4343b49b04478919b3d33bd30d1d1","0756e620499c40dfb28b4ba454f833a1"]},"id":"1zRi56YV22xH","outputId":"83a7f186-8737-4472-a47b-c6ef872f2e92"},"outputs":[{"name":"stderr","output_type":"stream","text":["DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _speechbrain_save\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _speechbrain_load\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for save\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for load\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint save hook for _save\n","DEBUG:speechbrain.utils.checkpoints:Registered checkpoint load hook for _recover\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f2a264fbbed14343870cf2638991ffb5","version_major":2,"version_minor":0},"text/plain":["config.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3bd7aa5987a54ca184f22f7c06fec0b1","version_major":2,"version_minor":0},"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fcb4343b49b04478919b3d33bd30d1d1","version_major":2,"version_minor":0},"text/plain":["model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0756e620499c40dfb28b4ba454f833a1","version_major":2,"version_minor":0},"text/plain":["vocabulary.txt: 0.00B [00:01, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../usr/local/lib/python3.12/dist-packages/whisperx/assets/pytorch_model.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n",">>Performing voice activity detection using Pyannote...\n","Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.8.0+cu126. Bad things might happen unless you revert torch to 1.x.\n","Downloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_fairseq_base_ls960_asr_ls960.pth\" to /root/.cache/torch/hub/checkpoints/wav2vec2_fairseq_base_ls960_asr_ls960.pth\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 360M/360M [00:00<00:00, 587MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["[align-error] AalaElKhani_2016X_308.92_322.19: CUDA out of memory. Tried to allocate 84.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.52 GiB is free. Process 19480 has 7.03 GiB memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 470.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AalaElKhani_2016X_368.76_379.70: CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.52 GiB is free. Process 19480 has 7.03 GiB memory in use. Of the allocated memory 3.11 GiB is allocated by PyTorch, and 484.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AaronKoblin_2011_1025.00_1054.94: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 468.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AaronKoblin_2011_304.84_319.94: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 562.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AaronKoblin_2011_625.00_654.82: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 469.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AdamOckelford_2013X_1100.00_1129.94: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 468.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AdamOckelford_2013X_500.00_515.42: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 560.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=100.46_106.86\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=106.46_111.50\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=111.28_116.55\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=116.54_122.13\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=12.43_15.62\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=121.79_125.40\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=126.62_129.85\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=130.11_132.52\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=132.12_140.92\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=141.57_150.01\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=15.62_23.16\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=150.01_153.37\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=153.06_154.58\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=155.14_159.89\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=159.66_166.76\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=166.30_174.62\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=174.13_179.97\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=179.96_188.88\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=188.54_191.73\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=191.72_200.41\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=205.05_206.10\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=206.01_213.70\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=213.54_220.01\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=219.78_225.05\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=22.95_29.58\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=226.45_232.76\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=232.33_242.84\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=242.68_249.92\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=249.73_254.94\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=255.14_262.32\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=262.12_265.29\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=265.28_274.87\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=276.33_278.77\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=279.09_282.59\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=282.59_293.17\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=292.80_300.17\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=300.82_302.21\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=302.47_304.82\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=304.99_315.50\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=31.19_34.70\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=315.50_318.98\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=318.76_324.60\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=325.46_331.17\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=331.10_338.02\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=337.63_348.87\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=34.54_44.88\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=348.44_350.73\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=350.27_354.97\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=354.96_361.21\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=360.93_370.36\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=370.14_372.64\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=378.13_384.68\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=385.24_394.05\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=394.05_397.53\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=397.34_402.44\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=402.43_404.97\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=404.99_411.33\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=410.84_424.35\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=424.22_428.86\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=430.05_434.09\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=436.59_438.46\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=438.00_441.79\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=44.87_48.33\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=441.57_449.99\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=458.50_468.21\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=468.21_471.65\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=47.87_54.97\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=472.00_476.60\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=476.17_479.97\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=480.23_483.46\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=483.46_491.55\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=491.06_493.68\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=493.34_501.52\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=501.33_504.76\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=504.72_514.06\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=513.57_518.11\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=518.11_525.01\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=524.61_526.88\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=526.64_529.16\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=530.14_536.22\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=536.22_543.02\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=54.99_59.21\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=542.68_547.58\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=547.12_554.37\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=555.41_563.04\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=562.61_565.86\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=565.70_571.21\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=571.21_579.94\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=579.90_589.15\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=588.90_598.30\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=59.21_67.94\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=598.23_603.08\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=604.93_612.48\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=612.48_617.54\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=618.82_624.26\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=623.83_629.85\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=629.89_644.34\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=644.34_649.81\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=651.57_663.70\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=663.70_673.93\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=67.71_70.87\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=673.92_679.97\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=680.22_681.84\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=682.95_684.89\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=684.89_693.60\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=695.41_704.88\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=70.68_74.54\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=704.84_706.44\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=706.07_717.87\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=718.16_724.99\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=725.88_732.67\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=732.48_735.79\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=735.79_743.20\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=742.77_744.52\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=744.39_752.93\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=75.79_84.71\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=84.58_87.78\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=87.59_96.29\n","[skip] no text for talk_id=AlejandroAlvarado_2016X time=96.07_100.23\n","[align-error] AlexSteffen_2011G_264.29_279.40: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 562.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AlexanderTsiaras_2010P_125.00_154.94: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 468.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AlexanderTsiaras_2010P_150.00_179.94: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 468.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AlexanderTsiaras_2010P_175.00_194.80: CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.17 GiB is allocated by PyTorch, and 533.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AlexanderTsiaras_2010P_200.00_229.94: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 468.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AlexanderTsiaras_2010P_225.00_253.08: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.22 GiB is allocated by PyTorch, and 480.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AlexanderTsiaras_2010P_275.00_304.94: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 468.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AlexanderTsiaras_2010P_300.00_329.94: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 468.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AlexanderTsiaras_2010P_325.00_353.38: CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.22 GiB is allocated by PyTorch, and 478.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AmyGreen_2017S_225.00_250.17: CUDA out of memory. Tried to allocate 158.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.20 GiB is allocated by PyTorch, and 499.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AnandaShankar_2009I_550.00_579.94: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 468.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AnandaShankar_2009I_600.00_629.94: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 468.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AnandaShankar_2009I_625.00_654.94: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 468.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AnandaShankar_2009I_650.00_679.79: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 469.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AnandaShankar_2009I_675.00_704.88: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 469.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AnandaShankar_2009I_700.00_729.91: CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 469.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AnandaShankar_2009I_750.00_779.76: CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.23 GiB is allocated by PyTorch, and 470.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AnandaShankar_2009I_775.00_802.66: CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.22 GiB is allocated by PyTorch, and 483.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","[align-error] AshBeckham_2014X_654.96_670.09: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 39.56 GiB of which 32.42 GiB is free. Process 19480 has 7.13 GiB memory in use. Of the allocated memory 3.14 GiB is allocated by PyTorch, and 562.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n","Done. Wrote single-word clips + /content/drive/MyDrive/final_project/Dataset_3/custom_data/words/metadata_words.csv\n"]}],"source":["import_from_local = False\n","\n","# NEW: build word dataset\n","# Step 2: Create Dataset\n","clips_folder = f'{dataset_path}/custom_data/clips'\n","full_talks_folder = f'{dataset_path}/custom_data/wavs'\n","\n","output_words_path = f\"{dataset_path}/custom_data/words\"\n","\n","if not import_from_local:\n","    build_word_dataset_from_sentence_clips(\n","        clips_folder=clips_folder,\n","        segments_dict=all_segments_dict,\n","        out_folder=output_words_path,\n","        pad_seconds=0.05\n","    )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zHr6u92ydtiI"},"outputs":[],"source":["words_folder = os.path.join(output_words_path, \"wavs\")\n","words_folder = output_words_path\n","metadata_csv = os.path.join(output_words_path, \"metadata_words.csv\")\n","\n","dataset = TextMelDataset(\n","    words_folder=words_folder,\n","    metadata_csv=metadata_csv,\n","    specific_items=None,   # or a list of sentence_ids / talk_ids to keep\n","    shuffle=False,\n","    use_phonemes=True      # switch to False to train on plain words\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wXtmw2lhxuMP","outputId":"fb901513-dcc5-4a80-e6f9-194fc5c8e5f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["274669\n"]}],"source":["print(len(dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HGCsSubGh2DY"},"outputs":[],"source":["from torch.utils.data import DataLoader, random_split\n","import torch\n","\n","# Split\n","val_ratio = 0.1\n","dataset_size = len(dataset)\n","val_size = max(1, int(val_ratio * dataset_size))\n","train_size = dataset_size - val_size\n","trainset, valset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n","\n","collate_fn = TextMelCollate(r=3)\n","\n","# Train loader\n","train_loader = DataLoader(\n","    trainset,\n","    batch_size=32,\n","    shuffle=True,                 # shuffle the training set\n","    num_workers=0,                # start with 0 to avoid RAM spikes\n","    pin_memory=False,             # enable later if using GPU + enough RAM\n","    drop_last=True,\n","    collate_fn=collate_fn,\n","    prefetch_factor=None,         # IMPORTANT: None when num_workers=0\n","    persistent_workers=False\n",")\n","\n","# Val loader\n","val_loader = DataLoader(\n","    valset,\n","    batch_size=32,\n","    shuffle=False,\n","    num_workers=0,\n","    pin_memory=False,\n","    drop_last=False,\n","    collate_fn=collate_fn,\n","    prefetch_factor=None,\n","    persistent_workers=False\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"Eoc8cuQVN1aQ"},"source":["## TextToMelSpectrogram Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PzffGa4BmRPX"},"outputs":[],"source":["import os\n","import time\n","import torch\n","\n","\n","def validate(model, criterion, iteration, device, valset, batch_size, collate_fn, logger):\n","    \"\"\"Simple validation loop that returns/prints average loss and logs scalar.\"\"\"\n","    model.eval()\n","    avg_loss = 0.0\n","    last_targets, last_predicts = None, None\n","    with torch.no_grad():\n","        val_loader = torch.utils.data.DataLoader(\n","            valset, shuffle=False, batch_size=batch_size, num_workers=0,\n","            pin_memory=False, collate_fn=collate_fn\n","        )\n","        for i, batch in enumerate(val_loader):\n","            inputs, targets = model.parse_data_batch(batch)\n","            predicts = model(inputs)\n","            loss = criterion(predicts, targets)\n","            avg_loss += float(loss)\n","            last_targets, last_predicts = targets, predicts\n","    avg_loss /= max(1, i + 1)\n","    model.train()\n","    print(f\"Validation loss {iteration}: {avg_loss:.6f}\")\n","    if logger is not None:\n","        logger.log_validation(avg_loss, model, last_targets, last_predicts, iteration)\n","    return avg_loss\n","\n","\n","def train(model, logger, learning_rate, optimizer, train_loader, collate_fn, valset, epochs=10):\n","    \"\"\"Training loop with periodic validation and checkpointing.\n","    Signature and external semantics preserved; parallel_run is ignored for simplicity.\n","    \"\"\"\n","    # Optional checkpoint restore\n","    iteration = -1\n","    epoch_offset = 0\n","\n","    model.train()\n","    for epoch in range(epoch_offset, epochs):\n","        print(f\"Epoch: {epoch}\")\n","        for batch in train_loader:\n","            start = time.perf_counter()\n","            iteration += 1\n","\n","            # Update LR each step (keeps existing behavior)\n","            for group in optimizer.param_groups:\n","                group['lr'] = learning_rate\n","\n","            # Forward + loss\n","            inputs, targets = model.parse_data_batch(batch)\n","            predicts = model(inputs)\n","            loss = criterion(predicts, targets)\n","\n","            # Backward\n","            optimizer.zero_grad()\n","            loss.backward()\n","            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","\n","            # Logs\n","            duration = time.perf_counter() - start\n","            print(f\"Train loss {iteration} {float(loss):.6f} Grad Norm {float(grad_norm):.6f} {duration:.2f}s/it\")\n","            if logger is not None:\n","                logger.log_training(float(loss), float(grad_norm), float(learning_rate), float(duration), iteration)\n","\n","            # Periodic validation\n","            if iteration % 1000 == 0:\n","                validate(model, criterion, iteration, None, valset, 32, collate_fn, logger)\n"]},{"cell_type":"markdown","metadata":{"id":"8cnwSCjOmOhs"},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TX7hehVkN1aQ","outputId":"eb04ca27-7ed0-495d-d736-f20bc90ee848"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Train loss 22010 0.452703 Grad Norm 1.043250 0.15s/it\n","Train loss 22011 0.708000 Grad Norm 2.547370 0.13s/it\n","Train loss 22012 0.903015 Grad Norm 3.468312 0.11s/it\n","Train loss 22013 0.600642 Grad Norm 1.005891 0.13s/it\n","Train loss 22014 0.650044 Grad Norm 2.080561 0.12s/it\n","Train loss 22015 0.713655 Grad Norm 1.287138 0.11s/it\n","Train loss 22016 0.634973 Grad Norm 1.103881 0.13s/it\n","Train loss 22017 0.422491 Grad Norm 0.799460 0.16s/it\n","Train loss 22018 0.667909 Grad Norm 1.564371 0.15s/it\n","Train loss 22019 0.376232 Grad Norm 1.849930 0.13s/it\n","Train loss 22020 0.600515 Grad Norm 2.138355 0.11s/it\n","Train loss 22021 0.462078 Grad Norm 0.707953 0.14s/it\n","Train loss 22022 0.589383 Grad Norm 1.415639 0.12s/it\n","Train loss 22023 0.521892 Grad Norm 1.561337 0.11s/it\n","Train loss 22024 0.700345 Grad Norm 1.488307 0.13s/it\n","Train loss 22025 0.591218 Grad Norm 4.123748 0.11s/it\n","Train loss 22026 0.574837 Grad Norm 0.979283 0.14s/it\n","Train loss 22027 0.499891 Grad Norm 1.334120 0.10s/it\n","Train loss 22028 0.404371 Grad Norm 0.956079 0.11s/it\n","Train loss 22029 0.564115 Grad Norm 2.246536 0.13s/it\n","Train loss 22030 0.626537 Grad Norm 1.978573 0.12s/it\n","Train loss 22031 0.354384 Grad Norm 1.455818 0.13s/it\n","Train loss 22032 0.543879 Grad Norm 0.790720 0.13s/it\n","Train loss 22033 0.586105 Grad Norm 3.506579 0.12s/it\n","Train loss 22034 0.590811 Grad Norm 0.793293 0.14s/it\n","Train loss 22035 0.549667 Grad Norm 4.263355 0.14s/it\n","Train loss 22036 0.468610 Grad Norm 2.409796 0.12s/it\n","Train loss 22037 0.563227 Grad Norm 1.576859 0.12s/it\n","Train loss 22038 1.018070 Grad Norm 3.727082 0.11s/it\n","Train loss 22039 0.602839 Grad Norm 1.035183 0.13s/it\n","Train loss 22040 0.841983 Grad Norm 3.312119 0.13s/it\n","Train loss 22041 0.466154 Grad Norm 0.689457 0.12s/it\n","Train loss 22042 0.632815 Grad Norm 1.697700 0.11s/it\n","Train loss 22043 0.401319 Grad Norm 0.388648 0.12s/it\n","Train loss 22044 0.516379 Grad Norm 2.698123 0.11s/it\n","Train loss 22045 0.778374 Grad Norm 4.318097 0.11s/it\n","Train loss 22046 0.659340 Grad Norm 2.047521 0.09s/it\n","Train loss 22047 0.665237 Grad Norm 3.250783 0.11s/it\n","Train loss 22048 0.760774 Grad Norm 2.151398 0.12s/it\n","Train loss 22049 0.415496 Grad Norm 1.609821 0.13s/it\n","Train loss 22050 0.440754 Grad Norm 1.213996 0.11s/it\n","Train loss 22051 0.655769 Grad Norm 0.768370 0.11s/it\n","Train loss 22052 0.637464 Grad Norm 0.982515 0.12s/it\n","Train loss 22053 0.557984 Grad Norm 1.185514 0.13s/it\n","Train loss 22054 0.520985 Grad Norm 0.992143 0.12s/it\n","Train loss 22055 0.576157 Grad Norm 2.945697 0.15s/it\n","Train loss 22056 0.415685 Grad Norm 0.967839 0.12s/it\n","Train loss 22057 0.444336 Grad Norm 0.924596 0.11s/it\n","Train loss 22058 0.434537 Grad Norm 1.437346 0.13s/it\n","Train loss 22059 0.384420 Grad Norm 0.802017 0.15s/it\n","Train loss 22060 0.829854 Grad Norm 3.053792 0.14s/it\n","Train loss 22061 0.551911 Grad Norm 1.368986 0.13s/it\n","Train loss 22062 0.566421 Grad Norm 1.315545 0.13s/it\n","Train loss 22063 0.927125 Grad Norm 1.851438 0.11s/it\n","Train loss 22064 0.767279 Grad Norm 2.112585 0.11s/it\n","Train loss 22065 0.545574 Grad Norm 1.509830 0.12s/it\n","Train loss 22066 0.724229 Grad Norm 2.058768 0.13s/it\n","Train loss 22067 0.584387 Grad Norm 2.051221 0.11s/it\n","Train loss 22068 0.520968 Grad Norm 0.827695 0.13s/it\n","Train loss 22069 0.540242 Grad Norm 1.154025 0.11s/it\n","Train loss 22070 0.460128 Grad Norm 0.725074 0.15s/it\n","Train loss 22071 0.347085 Grad Norm 0.898331 0.12s/it\n","Train loss 22072 0.362025 Grad Norm 0.585861 0.11s/it\n","Train loss 22073 0.527640 Grad Norm 1.470974 0.14s/it\n","Train loss 22074 0.351856 Grad Norm 1.484728 0.14s/it\n","Train loss 22075 0.397894 Grad Norm 1.330583 0.11s/it\n","Train loss 22076 0.817970 Grad Norm 3.776100 0.11s/it\n","Train loss 22077 0.566001 Grad Norm 2.094585 0.12s/it\n","Train loss 22078 0.532532 Grad Norm 1.418628 0.14s/it\n","Train loss 22079 0.714222 Grad Norm 2.150432 0.12s/it\n","Train loss 22080 0.725690 Grad Norm 2.222311 0.11s/it\n","Train loss 22081 0.723571 Grad Norm 1.651090 0.12s/it\n","Train loss 22082 0.534533 Grad Norm 2.066500 0.14s/it\n","Train loss 22083 0.560465 Grad Norm 3.427796 0.10s/it\n","Train loss 22084 0.570209 Grad Norm 2.050860 0.11s/it\n","Train loss 22085 0.770648 Grad Norm 2.046599 0.10s/it\n","Train loss 22086 0.696557 Grad Norm 1.769058 0.10s/it\n","Train loss 22087 0.607767 Grad Norm 1.276685 0.13s/it\n","Train loss 22088 0.438335 Grad Norm 0.891744 0.12s/it\n","Train loss 22089 0.550606 Grad Norm 2.650737 0.17s/it\n","Train loss 22090 0.373624 Grad Norm 0.917295 0.11s/it\n","Train loss 22091 1.049274 Grad Norm 2.098783 0.13s/it\n","Train loss 22092 0.522152 Grad Norm 0.917095 0.13s/it\n","Train loss 22093 0.481015 Grad Norm 1.997197 0.12s/it\n","Train loss 22094 0.401231 Grad Norm 1.347560 0.14s/it\n","Train loss 22095 0.335176 Grad Norm 0.685119 0.15s/it\n","Train loss 22096 0.582663 Grad Norm 3.648271 0.14s/it\n","Train loss 22097 0.606128 Grad Norm 1.285433 0.11s/it\n","Train loss 22098 0.786408 Grad Norm 1.850986 0.11s/it\n","Train loss 22099 0.663846 Grad Norm 1.942009 0.14s/it\n","Train loss 22100 0.338852 Grad Norm 0.516957 0.11s/it\n","Train loss 22101 0.672776 Grad Norm 1.172575 0.12s/it\n","Train loss 22102 0.854190 Grad Norm 4.025859 0.12s/it\n","Train loss 22103 0.472350 Grad Norm 3.239063 0.11s/it\n","Train loss 22104 0.490462 Grad Norm 1.044261 0.13s/it\n","Train loss 22105 0.751155 Grad Norm 2.189960 0.13s/it\n","Train loss 22106 0.769617 Grad Norm 2.022979 0.14s/it\n","Train loss 22107 0.517222 Grad Norm 1.532086 0.11s/it\n","Train loss 22108 0.706205 Grad Norm 2.218796 0.12s/it\n","Train loss 22109 0.522029 Grad Norm 1.192572 0.15s/it\n","Train loss 22110 0.494808 Grad Norm 0.763214 0.11s/it\n","Train loss 22111 0.405190 Grad Norm 1.555049 0.11s/it\n","Train loss 22112 0.736817 Grad Norm 2.423963 0.13s/it\n","Train loss 22113 0.335063 Grad Norm 0.733588 0.14s/it\n","Train loss 22114 0.783828 Grad Norm 1.838221 0.12s/it\n","Train loss 22115 0.614211 Grad Norm 1.474973 0.13s/it\n","Train loss 22116 0.370626 Grad Norm 0.571423 0.15s/it\n","Train loss 22117 0.481663 Grad Norm 2.680724 0.13s/it\n","Train loss 22118 0.627176 Grad Norm 1.564297 0.12s/it\n","Train loss 22119 0.699453 Grad Norm 1.096875 0.13s/it\n","Train loss 22120 0.515148 Grad Norm 0.627369 0.13s/it\n","Train loss 22121 0.549852 Grad Norm 0.927912 0.10s/it\n","Train loss 22122 0.815838 Grad Norm 5.960526 0.12s/it\n","Train loss 22123 0.530500 Grad Norm 1.083937 0.12s/it\n","Train loss 22124 0.711859 Grad Norm 1.022696 0.11s/it\n","Train loss 22125 0.461136 Grad Norm 1.165112 0.14s/it\n","Train loss 22126 0.408925 Grad Norm 1.383463 0.15s/it\n","Train loss 22127 0.376890 Grad Norm 0.688496 0.14s/it\n","Train loss 22128 0.564037 Grad Norm 0.994304 0.13s/it\n","Train loss 22129 0.624195 Grad Norm 1.486939 0.15s/it\n","Train loss 22130 0.566769 Grad Norm 2.864658 0.10s/it\n","Train loss 22131 0.517836 Grad Norm 0.853094 0.14s/it\n","Train loss 22132 0.402496 Grad Norm 0.672431 0.12s/it\n","Train loss 22133 0.655888 Grad Norm 1.944682 0.11s/it\n","Train loss 22134 0.663228 Grad Norm 1.037677 0.12s/it\n","Train loss 22135 0.532697 Grad Norm 2.414586 0.14s/it\n","Train loss 22136 0.780870 Grad Norm 1.867058 0.11s/it\n","Train loss 22137 0.666913 Grad Norm 2.113501 0.13s/it\n","Train loss 22138 0.857307 Grad Norm 1.740172 0.11s/it\n","Train loss 22139 0.824940 Grad Norm 7.273401 0.11s/it\n","Train loss 22140 0.622249 Grad Norm 1.430453 0.12s/it\n","Train loss 22141 0.315650 Grad Norm 0.935372 0.10s/it\n","Train loss 22142 0.536626 Grad Norm 1.288555 0.11s/it\n","Train loss 22143 0.620340 Grad Norm 1.082360 0.14s/it\n","Train loss 22144 0.723590 Grad Norm 1.518180 0.11s/it\n","Train loss 22145 0.616523 Grad Norm 2.443706 0.11s/it\n","Train loss 22146 0.631441 Grad Norm 1.081191 0.15s/it\n","Train loss 22147 0.750864 Grad Norm 1.292087 0.13s/it\n","Train loss 22148 0.373253 Grad Norm 0.926401 0.15s/it\n","Train loss 22149 0.434208 Grad Norm 0.901078 0.13s/it\n","Train loss 22150 0.598286 Grad Norm 1.204813 0.13s/it\n","Train loss 22151 0.526135 Grad Norm 2.285595 0.11s/it\n","Train loss 22152 0.650942 Grad Norm 1.942295 0.13s/it\n","Train loss 22153 0.491184 Grad Norm 1.241823 0.14s/it\n","Train loss 22154 0.481542 Grad Norm 1.220889 0.14s/it\n","Train loss 22155 0.490692 Grad Norm 1.285231 0.11s/it\n","Train loss 22156 0.651294 Grad Norm 1.264832 0.12s/it\n","Train loss 22157 0.822512 Grad Norm 1.682307 0.11s/it\n","Train loss 22158 0.530280 Grad Norm 0.921261 0.14s/it\n","Train loss 22159 0.954081 Grad Norm 2.023736 0.11s/it\n","Train loss 22160 0.550686 Grad Norm 1.455591 0.10s/it\n","Train loss 22161 0.567287 Grad Norm 1.018663 0.13s/it\n","Train loss 22162 0.485710 Grad Norm 1.033185 0.14s/it\n","Train loss 22163 0.740291 Grad Norm 3.338422 0.13s/it\n","Train loss 22164 0.437276 Grad Norm 0.677642 0.14s/it\n","Train loss 22165 0.485764 Grad Norm 0.722488 0.12s/it\n","Train loss 22166 0.548504 Grad Norm 1.458521 0.09s/it\n","Train loss 22167 0.576826 Grad Norm 1.606632 0.14s/it\n","Train loss 22168 0.487818 Grad Norm 1.604163 0.13s/it\n","Train loss 22169 0.574421 Grad Norm 1.262557 0.12s/it\n","Train loss 22170 0.295843 Grad Norm 0.710318 0.10s/it\n","Train loss 22171 0.336476 Grad Norm 0.644306 0.12s/it\n","Train loss 22172 0.475401 Grad Norm 1.010293 0.15s/it\n","Train loss 22173 0.457191 Grad Norm 0.553077 0.13s/it\n","Train loss 22174 0.599365 Grad Norm 2.213846 0.11s/it\n","Train loss 22175 0.817645 Grad Norm 1.548188 0.13s/it\n","Train loss 22176 0.505692 Grad Norm 1.096888 0.12s/it\n","Train loss 22177 0.614116 Grad Norm 1.563033 0.13s/it\n","Train loss 22178 0.557845 Grad Norm 1.773368 0.14s/it\n","Train loss 22179 0.708838 Grad Norm 1.662943 0.13s/it\n","Train loss 22180 0.603364 Grad Norm 2.306231 0.12s/it\n","Train loss 22181 0.575975 Grad Norm 2.764129 0.14s/it\n","Train loss 22182 0.603619 Grad Norm 1.565684 0.12s/it\n","Train loss 22183 0.576109 Grad Norm 0.872745 0.15s/it\n","Train loss 22184 0.367166 Grad Norm 0.959871 0.16s/it\n","Train loss 22185 0.353221 Grad Norm 0.944409 0.15s/it\n","Train loss 22186 0.394875 Grad Norm 1.497323 0.14s/it\n","Train loss 22187 0.682339 Grad Norm 1.397621 0.12s/it\n","Train loss 22188 0.518874 Grad Norm 1.594433 0.11s/it\n","Train loss 22189 0.367630 Grad Norm 0.713067 0.14s/it\n","Train loss 22190 0.570349 Grad Norm 3.312401 0.10s/it\n","Train loss 22191 0.578492 Grad Norm 3.042077 0.11s/it\n","Train loss 22192 0.504171 Grad Norm 3.139822 0.12s/it\n","Train loss 22193 0.376827 Grad Norm 0.688655 0.14s/it\n","Train loss 22194 0.503616 Grad Norm 0.797229 0.11s/it\n","Train loss 22195 0.586873 Grad Norm 1.783438 0.12s/it\n","Train loss 22196 0.524753 Grad Norm 1.000668 0.10s/it\n","Train loss 22197 0.822677 Grad Norm 1.643583 0.11s/it\n","Train loss 22198 0.703860 Grad Norm 1.901462 0.12s/it\n","Train loss 22199 0.635771 Grad Norm 2.778963 0.11s/it\n","Train loss 22200 0.476820 Grad Norm 1.331624 0.11s/it\n","Train loss 22201 0.773461 Grad Norm 2.375543 0.12s/it\n","Train loss 22202 0.271365 Grad Norm 0.430532 0.13s/it\n","Train loss 22203 0.479157 Grad Norm 1.229006 0.11s/it\n","Train loss 22204 0.856518 Grad Norm 2.380979 0.11s/it\n","Train loss 22205 0.491831 Grad Norm 1.539593 0.09s/it\n","Train loss 22206 0.710861 Grad Norm 1.645620 0.12s/it\n","Train loss 22207 0.677229 Grad Norm 2.157348 0.16s/it\n","Train loss 22208 0.518391 Grad Norm 1.224003 0.10s/it\n","Train loss 22209 0.495343 Grad Norm 2.182217 0.11s/it\n","Train loss 22210 0.689135 Grad Norm 1.855026 0.13s/it\n","Train loss 22211 0.413627 Grad Norm 2.170247 0.10s/it\n","Train loss 22212 0.519386 Grad Norm 1.676012 0.14s/it\n","Train loss 22213 0.715890 Grad Norm 1.000615 0.12s/it\n","Train loss 22214 0.493870 Grad Norm 1.695520 0.14s/it\n","Train loss 22215 0.744989 Grad Norm 2.244481 0.11s/it\n","Train loss 22216 0.407519 Grad Norm 1.139392 0.13s/it\n","Train loss 22217 0.438784 Grad Norm 1.126809 0.17s/it\n","Train loss 22218 0.536001 Grad Norm 1.357619 0.13s/it\n","Train loss 22219 0.560377 Grad Norm 1.304627 0.12s/it\n","Train loss 22220 0.604255 Grad Norm 2.690936 0.12s/it\n","Train loss 22221 0.475119 Grad Norm 3.599284 0.13s/it\n","Train loss 22222 0.574071 Grad Norm 1.674279 0.13s/it\n","Train loss 22223 0.614217 Grad Norm 1.070770 0.13s/it\n","Train loss 22224 0.375937 Grad Norm 0.685253 0.14s/it\n","Train loss 22225 0.495878 Grad Norm 0.633666 0.13s/it\n","Train loss 22226 0.488912 Grad Norm 0.613858 0.15s/it\n","Train loss 22227 0.382089 Grad Norm 0.408243 0.11s/it\n","Train loss 22228 0.782977 Grad Norm 1.831435 0.13s/it\n","Train loss 22229 0.539008 Grad Norm 1.108877 0.15s/it\n","Train loss 22230 0.584158 Grad Norm 1.120140 0.12s/it\n","Train loss 22231 0.447166 Grad Norm 1.146816 0.10s/it\n","Train loss 22232 0.590036 Grad Norm 2.790324 0.10s/it\n","Train loss 22233 0.539967 Grad Norm 0.961537 0.15s/it\n","Train loss 22234 0.492097 Grad Norm 2.349663 0.11s/it\n","Train loss 22235 0.699944 Grad Norm 1.602575 0.12s/it\n","Train loss 22236 0.465996 Grad Norm 1.227947 0.10s/it\n","Train loss 22237 0.524138 Grad Norm 1.247488 0.11s/it\n","Train loss 22238 0.584536 Grad Norm 1.091486 0.10s/it\n","Train loss 22239 0.564723 Grad Norm 1.353606 0.11s/it\n","Train loss 22240 0.549666 Grad Norm 1.888308 0.11s/it\n","Train loss 22241 0.297654 Grad Norm 1.180211 0.13s/it\n","Train loss 22242 0.656580 Grad Norm 1.494227 0.12s/it\n","Train loss 22243 0.620803 Grad Norm 1.214567 0.12s/it\n","Train loss 22244 0.731615 Grad Norm 1.148974 0.12s/it\n","Train loss 22245 0.465806 Grad Norm 1.452128 0.09s/it\n","Train loss 22246 0.360724 Grad Norm 1.227199 0.13s/it\n","Train loss 22247 0.774626 Grad Norm 1.620683 0.11s/it\n","Train loss 22248 0.344430 Grad Norm 0.792928 0.15s/it\n","Train loss 22249 0.546073 Grad Norm 1.304293 0.13s/it\n","Train loss 22250 0.313025 Grad Norm 1.458912 0.14s/it\n","Train loss 22251 0.777693 Grad Norm 1.347288 0.11s/it\n","Train loss 22252 0.584569 Grad Norm 0.888201 0.14s/it\n","Train loss 22253 0.471027 Grad Norm 0.651252 0.12s/it\n","Train loss 22254 0.632149 Grad Norm 2.717868 0.11s/it\n","Train loss 22255 0.652901 Grad Norm 1.515009 0.11s/it\n","Train loss 22256 0.550642 Grad Norm 0.877461 0.15s/it\n","Train loss 22257 0.717797 Grad Norm 2.546122 0.12s/it\n","Train loss 22258 0.376488 Grad Norm 0.678095 0.13s/it\n","Train loss 22259 0.340145 Grad Norm 1.360472 0.16s/it\n","Train loss 22260 0.627959 Grad Norm 2.351045 0.14s/it\n","Train loss 22261 0.603659 Grad Norm 1.289190 0.13s/it\n","Train loss 22262 0.437882 Grad Norm 0.740898 0.12s/it\n","Train loss 22263 0.772448 Grad Norm 2.738967 0.11s/it\n","Train loss 22264 0.501724 Grad Norm 0.945164 0.12s/it\n","Train loss 22265 0.504800 Grad Norm 0.897867 0.11s/it\n","Train loss 22266 0.516900 Grad Norm 1.342093 0.10s/it\n","Train loss 22267 0.593485 Grad Norm 3.656044 0.12s/it\n","Train loss 22268 0.560435 Grad Norm 1.094376 0.13s/it\n","Train loss 22269 0.734903 Grad Norm 2.627534 0.15s/it\n","Train loss 22270 0.701051 Grad Norm 3.569413 0.12s/it\n","Train loss 22271 0.302269 Grad Norm 0.655190 0.13s/it\n","Train loss 22272 0.427122 Grad Norm 1.528222 0.11s/it\n","Train loss 22273 0.441609 Grad Norm 0.970775 0.13s/it\n","Train loss 22274 0.594563 Grad Norm 1.179045 0.13s/it\n","Train loss 22275 0.776234 Grad Norm 2.425281 0.11s/it\n","Train loss 22276 0.840333 Grad Norm 2.727582 0.11s/it\n","Train loss 22277 0.431398 Grad Norm 1.210919 0.10s/it\n","Train loss 22278 0.459434 Grad Norm 1.413422 0.12s/it\n","Train loss 22279 0.421242 Grad Norm 1.070230 0.11s/it\n","Train loss 22280 0.399546 Grad Norm 0.597232 0.13s/it\n","Train loss 22281 0.406871 Grad Norm 0.652337 0.10s/it\n","Train loss 22282 0.488263 Grad Norm 0.906605 0.15s/it\n","Train loss 22283 0.752131 Grad Norm 2.278411 0.15s/it\n","Train loss 22284 0.538021 Grad Norm 1.306498 0.13s/it\n","Train loss 22285 0.358117 Grad Norm 2.192148 0.13s/it\n","Train loss 22286 0.604515 Grad Norm 1.384596 0.11s/it\n","Train loss 22287 0.806811 Grad Norm 2.006238 0.11s/it\n","Train loss 22288 0.551697 Grad Norm 1.249579 0.12s/it\n","Train loss 22289 0.698692 Grad Norm 1.538421 0.13s/it\n","Train loss 22290 0.552976 Grad Norm 3.567145 0.10s/it\n","Train loss 22291 0.549520 Grad Norm 2.190225 0.09s/it\n","Train loss 22292 0.770518 Grad Norm 2.151027 0.12s/it\n","Train loss 22293 0.430452 Grad Norm 0.548167 0.18s/it\n","Train loss 22294 0.454558 Grad Norm 0.927019 0.12s/it\n","Train loss 22295 0.513097 Grad Norm 0.928786 0.11s/it\n","Train loss 22296 0.662030 Grad Norm 3.067535 0.11s/it\n","Train loss 22297 0.561589 Grad Norm 1.737308 0.11s/it\n","Train loss 22298 0.526951 Grad Norm 2.683350 0.13s/it\n","Train loss 22299 0.998102 Grad Norm 2.191743 0.11s/it\n","Train loss 22300 0.634158 Grad Norm 1.801591 0.10s/it\n","Train loss 22301 0.604215 Grad Norm 0.980987 0.11s/it\n","Train loss 22302 0.609137 Grad Norm 1.213406 0.11s/it\n","Train loss 22303 0.712589 Grad Norm 1.361170 0.12s/it\n","Train loss 22304 0.409438 Grad Norm 0.682671 0.11s/it\n","Train loss 22305 0.384497 Grad Norm 0.524449 0.11s/it\n","Train loss 22306 0.437879 Grad Norm 1.362779 0.16s/it\n","Train loss 22307 0.508289 Grad Norm 1.574581 0.12s/it\n","Train loss 22308 0.671640 Grad Norm 2.288562 0.12s/it\n","Train loss 22309 0.612795 Grad Norm 2.643314 0.12s/it\n","Train loss 22310 0.521669 Grad Norm 0.967052 0.13s/it\n","Train loss 22311 0.549332 Grad Norm 2.316470 0.14s/it\n","Train loss 22312 0.537855 Grad Norm 2.111774 0.11s/it\n","Train loss 22313 0.633590 Grad Norm 1.128433 0.14s/it\n","Train loss 22314 0.767623 Grad Norm 2.146543 0.12s/it\n","Train loss 22315 0.490719 Grad Norm 3.236100 0.11s/it\n","Train loss 22316 0.420220 Grad Norm 0.729514 0.14s/it\n","Train loss 22317 0.536983 Grad Norm 1.658738 0.11s/it\n","Train loss 22318 0.663956 Grad Norm 2.140885 0.11s/it\n","Train loss 22319 0.333077 Grad Norm 0.733822 0.16s/it\n","Train loss 22320 0.493486 Grad Norm 3.791361 0.11s/it\n","Train loss 22321 0.477968 Grad Norm 0.860371 0.12s/it\n","Train loss 22322 0.474661 Grad Norm 1.131038 0.11s/it\n","Train loss 22323 0.613131 Grad Norm 2.916106 0.13s/it\n","Train loss 22324 0.497875 Grad Norm 0.713917 0.12s/it\n","Train loss 22325 0.748737 Grad Norm 1.636103 0.14s/it\n","Train loss 22326 0.463538 Grad Norm 0.952780 0.11s/it\n","Train loss 22327 0.719454 Grad Norm 1.499751 0.14s/it\n","Train loss 22328 0.662198 Grad Norm 0.865945 0.15s/it\n","Train loss 22329 0.526243 Grad Norm 1.383324 0.13s/it\n","Train loss 22330 0.704004 Grad Norm 0.756042 0.11s/it\n","Train loss 22331 0.763215 Grad Norm 1.830990 0.11s/it\n","Train loss 22332 0.525951 Grad Norm 0.903248 0.13s/it\n","Train loss 22333 0.409419 Grad Norm 2.225713 0.15s/it\n","Train loss 22334 0.911275 Grad Norm 2.026501 0.14s/it\n","Train loss 22335 0.422276 Grad Norm 2.849982 0.15s/it\n","Train loss 22336 0.676195 Grad Norm 3.420506 0.12s/it\n","Train loss 22337 0.487398 Grad Norm 1.106690 0.15s/it\n","Train loss 22338 0.652120 Grad Norm 0.942779 0.14s/it\n","Train loss 22339 0.623495 Grad Norm 1.532478 0.13s/it\n","Train loss 22340 0.695849 Grad Norm 1.583833 0.10s/it\n","Train loss 22341 0.717100 Grad Norm 0.945023 0.12s/it\n","Train loss 22342 0.645727 Grad Norm 1.240857 0.16s/it\n","Train loss 22343 0.843055 Grad Norm 1.315607 0.11s/it\n","Train loss 22344 0.504585 Grad Norm 0.728132 0.14s/it\n","Train loss 22345 0.614912 Grad Norm 1.385853 0.14s/it\n","Train loss 22346 0.519897 Grad Norm 0.805214 0.13s/it\n","Train loss 22347 0.669800 Grad Norm 0.926524 0.10s/it\n","Train loss 22348 0.570071 Grad Norm 1.285797 0.13s/it\n","Train loss 22349 0.335541 Grad Norm 0.522254 0.12s/it\n","Train loss 22350 0.645475 Grad Norm 1.010965 0.11s/it\n","Train loss 22351 0.415144 Grad Norm 1.072944 0.15s/it\n","Train loss 22352 0.664007 Grad Norm 1.185725 0.12s/it\n","Train loss 22353 0.786920 Grad Norm 2.586883 0.11s/it\n","Train loss 22354 0.466259 Grad Norm 0.703210 0.13s/it\n","Train loss 22355 0.687228 Grad Norm 2.200318 0.12s/it\n","Train loss 22356 0.504575 Grad Norm 2.135485 0.14s/it\n","Train loss 22357 0.427352 Grad Norm 1.382998 0.11s/it\n","Train loss 22358 0.490372 Grad Norm 1.235735 0.12s/it\n","Train loss 22359 0.510681 Grad Norm 1.517098 0.19s/it\n","Train loss 22360 0.476794 Grad Norm 0.991639 0.12s/it\n","Train loss 22361 0.588684 Grad Norm 4.739776 0.13s/it\n","Train loss 22362 0.540467 Grad Norm 1.094661 0.13s/it\n","Train loss 22363 0.784780 Grad Norm 1.406300 0.12s/it\n","Train loss 22364 0.505162 Grad Norm 1.881699 0.15s/it\n","Train loss 22365 0.539227 Grad Norm 1.549115 0.10s/it\n","Train loss 22366 0.278779 Grad Norm 0.345287 0.14s/it\n","Train loss 22367 0.506603 Grad Norm 0.933181 0.10s/it\n","Train loss 22368 0.555487 Grad Norm 1.286860 0.10s/it\n","Train loss 22369 0.751728 Grad Norm 2.150256 0.14s/it\n","Train loss 22370 0.482946 Grad Norm 0.841127 0.12s/it\n","Train loss 22371 0.568028 Grad Norm 1.044912 0.13s/it\n","Train loss 22372 0.539076 Grad Norm 1.483947 0.11s/it\n","Train loss 22373 0.543643 Grad Norm 0.919325 0.15s/it\n","Train loss 22374 0.504445 Grad Norm 1.256488 0.11s/it\n","Train loss 22375 0.793043 Grad Norm 2.362154 0.12s/it\n","Train loss 22376 0.788434 Grad Norm 2.166598 0.13s/it\n","Train loss 22377 0.700322 Grad Norm 3.573092 0.12s/it\n","Train loss 22378 0.493961 Grad Norm 0.984263 0.10s/it\n","Train loss 22379 0.574466 Grad Norm 1.421005 0.15s/it\n","Train loss 22380 0.555320 Grad Norm 0.775100 0.12s/it\n","Train loss 22381 0.926707 Grad Norm 1.592024 0.11s/it\n","Train loss 22382 0.680264 Grad Norm 1.711317 0.11s/it\n","Train loss 22383 0.782454 Grad Norm 2.621112 0.12s/it\n","Train loss 22384 0.408595 Grad Norm 1.170094 0.13s/it\n","Train loss 22385 0.514331 Grad Norm 1.366676 0.14s/it\n","Train loss 22386 0.672240 Grad Norm 1.264314 0.13s/it\n","Train loss 22387 0.703632 Grad Norm 2.483769 0.12s/it\n","Train loss 22388 0.691064 Grad Norm 1.946010 0.11s/it\n","Train loss 22389 0.493970 Grad Norm 1.200272 0.13s/it\n","Train loss 22390 0.484308 Grad Norm 0.658249 0.14s/it\n","Train loss 22391 0.647532 Grad Norm 1.979367 0.13s/it\n","Train loss 22392 0.591581 Grad Norm 1.329226 0.12s/it\n","Train loss 22393 0.382570 Grad Norm 0.816709 0.15s/it\n","Train loss 22394 0.605597 Grad Norm 1.307192 0.10s/it\n","Train loss 22395 0.497787 Grad Norm 1.095242 0.11s/it\n","Train loss 22396 0.589496 Grad Norm 2.038574 0.14s/it\n","Train loss 22397 0.824980 Grad Norm 1.360480 0.12s/it\n","Train loss 22398 0.637601 Grad Norm 2.029345 0.11s/it\n","Train loss 22399 0.738439 Grad Norm 2.005780 0.13s/it\n","Train loss 22400 0.359569 Grad Norm 0.967506 0.11s/it\n","Train loss 22401 0.601705 Grad Norm 1.839026 0.12s/it\n","Train loss 22402 0.553810 Grad Norm 1.945421 0.13s/it\n","Train loss 22403 0.635412 Grad Norm 3.580424 0.11s/it\n","Train loss 22404 0.453331 Grad Norm 1.312231 0.11s/it\n","Train loss 22405 0.373912 Grad Norm 1.450020 0.13s/it\n","Train loss 22406 0.488691 Grad Norm 1.613602 0.13s/it\n","Train loss 22407 0.574473 Grad Norm 1.769973 0.12s/it\n","Train loss 22408 0.477791 Grad Norm 0.872550 0.17s/it\n","Train loss 22409 0.716003 Grad Norm 1.654014 0.11s/it\n","Train loss 22410 0.487782 Grad Norm 1.461158 0.13s/it\n","Train loss 22411 0.701343 Grad Norm 2.749887 0.13s/it\n","Train loss 22412 0.323965 Grad Norm 0.791320 0.15s/it\n","Train loss 22413 0.310027 Grad Norm 0.958416 0.14s/it\n","Train loss 22414 0.649728 Grad Norm 1.438688 0.11s/it\n","Train loss 22415 0.506632 Grad Norm 1.510361 0.12s/it\n","Train loss 22416 0.444931 Grad Norm 0.985965 0.15s/it\n","Train loss 22417 0.469166 Grad Norm 1.479954 0.15s/it\n","Train loss 22418 0.783608 Grad Norm 1.775412 0.11s/it\n","Train loss 22419 0.470906 Grad Norm 1.575749 0.12s/it\n","Train loss 22420 0.578352 Grad Norm 1.483325 0.11s/it\n","Train loss 22421 0.506629 Grad Norm 1.011357 0.12s/it\n","Train loss 22422 0.465384 Grad Norm 2.267111 0.14s/it\n","Train loss 22423 0.680972 Grad Norm 1.658814 0.11s/it\n","Train loss 22424 0.523908 Grad Norm 1.822895 0.12s/it\n","Train loss 22425 0.635528 Grad Norm 2.417638 0.11s/it\n","Train loss 22426 0.581558 Grad Norm 1.129174 0.12s/it\n","Train loss 22427 0.470206 Grad Norm 1.193495 0.14s/it\n","Train loss 22428 0.433388 Grad Norm 0.737949 0.13s/it\n","Train loss 22429 0.471767 Grad Norm 1.904010 0.11s/it\n","Train loss 22430 0.532594 Grad Norm 1.365842 0.12s/it\n","Train loss 22431 0.755476 Grad Norm 2.425911 0.13s/it\n","Train loss 22432 0.395695 Grad Norm 1.023730 0.11s/it\n","Train loss 22433 0.382015 Grad Norm 1.190573 0.16s/it\n","Train loss 22434 0.489693 Grad Norm 1.416297 0.11s/it\n","Train loss 22435 0.607571 Grad Norm 2.748567 0.12s/it\n","Train loss 22436 0.673247 Grad Norm 1.538910 0.14s/it\n","Train loss 22437 0.603749 Grad Norm 1.246526 0.14s/it\n","Train loss 22438 0.513425 Grad Norm 3.202192 0.14s/it\n","Train loss 22439 0.606759 Grad Norm 1.107410 0.14s/it\n","Train loss 22440 0.576115 Grad Norm 2.088917 0.15s/it\n","Train loss 22441 0.329483 Grad Norm 0.995893 0.16s/it\n","Train loss 22442 0.540190 Grad Norm 1.949354 0.12s/it\n","Train loss 22443 0.516257 Grad Norm 3.294635 0.12s/it\n","Train loss 22444 0.922747 Grad Norm 2.072971 0.13s/it\n","Train loss 22445 0.736367 Grad Norm 2.981704 0.13s/it\n","Train loss 22446 0.586379 Grad Norm 0.943833 0.13s/it\n","Train loss 22447 0.485144 Grad Norm 0.783447 0.12s/it\n","Train loss 22448 0.462709 Grad Norm 1.029534 0.11s/it\n","Train loss 22449 0.473402 Grad Norm 1.079353 0.11s/it\n","Train loss 22450 0.511665 Grad Norm 1.643307 0.13s/it\n","Train loss 22451 0.551585 Grad Norm 1.189658 0.14s/it\n","Train loss 22452 0.487112 Grad Norm 1.158449 0.11s/it\n","Train loss 22453 0.668934 Grad Norm 1.396624 0.12s/it\n","Train loss 22454 0.628991 Grad Norm 2.267829 0.14s/it\n","Train loss 22455 0.416162 Grad Norm 0.735320 0.14s/it\n","Train loss 22456 0.500345 Grad Norm 1.276753 0.14s/it\n","Train loss 22457 0.806632 Grad Norm 3.550386 0.11s/it\n","Train loss 22458 0.473944 Grad Norm 2.594693 0.11s/it\n","Train loss 22459 0.455295 Grad Norm 1.228776 0.13s/it\n","Train loss 22460 0.661638 Grad Norm 2.428051 0.12s/it\n","Train loss 22461 0.514587 Grad Norm 2.069830 0.15s/it\n","Train loss 22462 0.451360 Grad Norm 1.419797 0.13s/it\n","Train loss 22463 0.672931 Grad Norm 1.532393 0.11s/it\n","Train loss 22464 0.484755 Grad Norm 1.112264 0.12s/it\n","Train loss 22465 0.419060 Grad Norm 3.241346 0.13s/it\n","Train loss 22466 0.404429 Grad Norm 1.040051 0.13s/it\n","Train loss 22467 0.878735 Grad Norm 1.730611 0.12s/it\n","Train loss 22468 0.674866 Grad Norm 3.100077 0.12s/it\n","Train loss 22469 0.414087 Grad Norm 1.884857 0.12s/it\n","Train loss 22470 0.580443 Grad Norm 1.152586 0.12s/it\n","Train loss 22471 0.970089 Grad Norm 3.051436 0.14s/it\n","Train loss 22472 0.626454 Grad Norm 1.441930 0.12s/it\n","Train loss 22473 0.498757 Grad Norm 1.316599 0.13s/it\n","Train loss 22474 0.727676 Grad Norm 1.946193 0.12s/it\n","Train loss 22475 0.663839 Grad Norm 2.535642 0.15s/it\n","Train loss 22476 0.597522 Grad Norm 1.174153 0.15s/it\n","Train loss 22477 0.466399 Grad Norm 1.264760 0.12s/it\n","Train loss 22478 0.488239 Grad Norm 1.052795 0.13s/it\n","Train loss 22479 0.585368 Grad Norm 1.558805 0.11s/it\n","Train loss 22480 0.433170 Grad Norm 1.274675 0.12s/it\n","Train loss 22481 0.614211 Grad Norm 1.648396 0.09s/it\n","Train loss 22482 0.683959 Grad Norm 1.741472 0.12s/it\n","Train loss 22483 0.540922 Grad Norm 3.177922 0.12s/it\n","Train loss 22484 0.469007 Grad Norm 1.239208 0.15s/it\n","Train loss 22485 0.754513 Grad Norm 1.878248 0.15s/it\n","Train loss 22486 0.541961 Grad Norm 0.880651 0.13s/it\n","Train loss 22487 0.439326 Grad Norm 1.332813 0.16s/it\n","Train loss 22488 0.650358 Grad Norm 1.623110 0.13s/it\n","Train loss 22489 0.689324 Grad Norm 2.535766 0.11s/it\n","Train loss 22490 0.601321 Grad Norm 1.518600 0.15s/it\n","Train loss 22491 0.717123 Grad Norm 2.008758 0.11s/it\n","Train loss 22492 0.449853 Grad Norm 1.495285 0.14s/it\n","Train loss 22493 0.658935 Grad Norm 1.883608 0.14s/it\n","Train loss 22494 0.383447 Grad Norm 1.357951 0.14s/it\n","Train loss 22495 0.363406 Grad Norm 0.551922 0.10s/it\n","Train loss 22496 0.538081 Grad Norm 2.137613 0.12s/it\n","Train loss 22497 0.492316 Grad Norm 0.797337 0.14s/it\n","Train loss 22498 0.624900 Grad Norm 2.801032 0.12s/it\n","Train loss 22499 0.643577 Grad Norm 2.297264 0.13s/it\n","Train loss 22500 0.399502 Grad Norm 0.919374 0.13s/it\n","Train loss 22501 0.702008 Grad Norm 2.624443 0.13s/it\n","Train loss 22502 0.348615 Grad Norm 0.603741 0.14s/it\n","Train loss 22503 0.613339 Grad Norm 1.437047 0.13s/it\n","Train loss 22504 0.759804 Grad Norm 2.374213 0.11s/it\n","Train loss 22505 0.603974 Grad Norm 1.650258 0.10s/it\n","Train loss 22506 0.918421 Grad Norm 5.784043 0.12s/it\n","Train loss 22507 0.488772 Grad Norm 1.982978 0.10s/it\n","Train loss 22508 0.583476 Grad Norm 2.037364 0.12s/it\n","Train loss 22509 0.640902 Grad Norm 1.396132 0.15s/it\n","Train loss 22510 0.761392 Grad Norm 1.217235 0.12s/it\n","Train loss 22511 0.377796 Grad Norm 0.954122 0.12s/it\n","Train loss 22512 0.493556 Grad Norm 0.743799 0.16s/it\n","Train loss 22513 0.601701 Grad Norm 2.326584 0.13s/it\n","Train loss 22514 0.670901 Grad Norm 2.250730 0.14s/it\n","Train loss 22515 0.520957 Grad Norm 1.034523 0.12s/it\n","Train loss 22516 0.500660 Grad Norm 2.974395 0.11s/it\n","Train loss 22517 0.611669 Grad Norm 1.218930 0.12s/it\n","Train loss 22518 0.758000 Grad Norm 2.473224 0.11s/it\n","Train loss 22519 0.633082 Grad Norm 1.578939 0.12s/it\n","Train loss 22520 0.448541 Grad Norm 1.271976 0.13s/it\n","Train loss 22521 0.501990 Grad Norm 0.871238 0.13s/it\n","Train loss 22522 0.554396 Grad Norm 1.263239 0.12s/it\n","Train loss 22523 0.577693 Grad Norm 1.281720 0.10s/it\n","Train loss 22524 0.479135 Grad Norm 0.584557 0.12s/it\n","Train loss 22525 0.438875 Grad Norm 0.940291 0.11s/it\n","Train loss 22526 0.515706 Grad Norm 1.449790 0.14s/it\n","Train loss 22527 0.858665 Grad Norm 3.174978 0.13s/it\n","Train loss 22528 0.424728 Grad Norm 0.966080 0.10s/it\n","Train loss 22529 0.615345 Grad Norm 0.879721 0.12s/it\n","Train loss 22530 0.457354 Grad Norm 0.896655 0.12s/it\n","Train loss 22531 0.672535 Grad Norm 2.082015 0.12s/it\n","Train loss 22532 0.585158 Grad Norm 2.527130 0.11s/it\n","Train loss 22533 0.716358 Grad Norm 1.402865 0.11s/it\n","Train loss 22534 0.552730 Grad Norm 1.377598 0.11s/it\n","Train loss 22535 0.641262 Grad Norm 1.532676 0.13s/it\n","Train loss 22536 0.527502 Grad Norm 1.277239 0.10s/it\n","Train loss 22537 0.641353 Grad Norm 2.337026 0.12s/it\n","Train loss 22538 0.670516 Grad Norm 2.117490 0.14s/it\n","Train loss 22539 0.482612 Grad Norm 2.619116 0.10s/it\n","Train loss 22540 0.368757 Grad Norm 0.963849 0.16s/it\n","Train loss 22541 0.305348 Grad Norm 0.644907 0.14s/it\n","Train loss 22542 0.526139 Grad Norm 1.523418 0.13s/it\n","Train loss 22543 0.429006 Grad Norm 1.624325 0.15s/it\n","Train loss 22544 0.636465 Grad Norm 1.422067 0.13s/it\n","Train loss 22545 0.297765 Grad Norm 0.342083 0.14s/it\n","Train loss 22546 0.644487 Grad Norm 2.509669 0.13s/it\n","Train loss 22547 0.559681 Grad Norm 1.048510 0.15s/it\n","Train loss 22548 0.365969 Grad Norm 0.744536 0.15s/it\n","Train loss 22549 0.561382 Grad Norm 1.732789 0.13s/it\n","Train loss 22550 0.595488 Grad Norm 0.652172 0.12s/it\n","Train loss 22551 0.539569 Grad Norm 1.312024 0.11s/it\n","Train loss 22552 0.511471 Grad Norm 1.092272 0.15s/it\n","Train loss 22553 0.405086 Grad Norm 0.607590 0.15s/it\n","Train loss 22554 0.528982 Grad Norm 0.946067 0.14s/it\n","Train loss 22555 0.437112 Grad Norm 0.846448 0.12s/it\n","Train loss 22556 0.662546 Grad Norm 2.518141 0.12s/it\n","Train loss 22557 0.418287 Grad Norm 1.238166 0.13s/it\n","Train loss 22558 0.735159 Grad Norm 1.762466 0.12s/it\n","Train loss 22559 0.440385 Grad Norm 0.997220 0.13s/it\n","Train loss 22560 0.616060 Grad Norm 3.112911 0.15s/it\n","Train loss 22561 0.650055 Grad Norm 3.590737 0.12s/it\n","Train loss 22562 0.716585 Grad Norm 1.757367 0.11s/it\n","Train loss 22563 0.483837 Grad Norm 0.744618 0.15s/it\n","Train loss 22564 0.615655 Grad Norm 2.437717 0.13s/it\n","Train loss 22565 0.626077 Grad Norm 2.132229 0.12s/it\n","Train loss 22566 0.703098 Grad Norm 1.557133 0.12s/it\n","Train loss 22567 0.554859 Grad Norm 2.901227 0.15s/it\n","Train loss 22568 0.746748 Grad Norm 1.010132 0.13s/it\n","Train loss 22569 0.407339 Grad Norm 1.161519 0.11s/it\n","Train loss 22570 0.527006 Grad Norm 0.975103 0.11s/it\n","Train loss 22571 0.568743 Grad Norm 2.319131 0.11s/it\n","Train loss 22572 0.705201 Grad Norm 1.741992 0.14s/it\n","Train loss 22573 0.364970 Grad Norm 0.779916 0.14s/it\n","Train loss 22574 0.482632 Grad Norm 0.728648 0.14s/it\n","Train loss 22575 0.641755 Grad Norm 1.585117 0.14s/it\n","Train loss 22576 0.723025 Grad Norm 1.365379 0.13s/it\n","Train loss 22577 0.782317 Grad Norm 2.173066 0.13s/it\n","Train loss 22578 0.689378 Grad Norm 1.797465 0.10s/it\n","Train loss 22579 0.514207 Grad Norm 1.446214 0.12s/it\n","Train loss 22580 0.648649 Grad Norm 1.111202 0.14s/it\n","Train loss 22581 0.757369 Grad Norm 2.638068 0.12s/it\n","Train loss 22582 0.929490 Grad Norm 2.015507 0.13s/it\n","Train loss 22583 0.517161 Grad Norm 1.877118 0.14s/it\n","Train loss 22584 0.653196 Grad Norm 1.913200 0.16s/it\n","Train loss 22585 0.397507 Grad Norm 1.500127 0.11s/it\n","Train loss 22586 0.551483 Grad Norm 0.957866 0.13s/it\n","Train loss 22587 0.544527 Grad Norm 1.186601 0.14s/it\n","Train loss 22588 0.604233 Grad Norm 1.348014 0.14s/it\n","Train loss 22589 0.533627 Grad Norm 1.899266 0.11s/it\n","Train loss 22590 0.468359 Grad Norm 1.016347 0.10s/it\n","Train loss 22591 0.290188 Grad Norm 0.383566 0.10s/it\n","Train loss 22592 0.541103 Grad Norm 1.232506 0.11s/it\n","Train loss 22593 0.650881 Grad Norm 1.634775 0.13s/it\n","Train loss 22594 0.471808 Grad Norm 0.677975 0.14s/it\n","Train loss 22595 0.328241 Grad Norm 0.671343 0.12s/it\n","Train loss 22596 0.553608 Grad Norm 1.084638 0.12s/it\n","Train loss 22597 0.411957 Grad Norm 2.494780 0.13s/it\n","Train loss 22598 0.667142 Grad Norm 2.668357 0.12s/it\n","Train loss 22599 0.553245 Grad Norm 1.805973 0.11s/it\n","Train loss 22600 0.885916 Grad Norm 2.774987 0.12s/it\n","Train loss 22601 0.545287 Grad Norm 0.664700 0.13s/it\n","Train loss 22602 0.275149 Grad Norm 0.358381 0.13s/it\n","Train loss 22603 0.565769 Grad Norm 2.551695 0.11s/it\n","Train loss 22604 0.320251 Grad Norm 0.785449 0.14s/it\n","Train loss 22605 0.695103 Grad Norm 1.015057 0.14s/it\n","Train loss 22606 0.429719 Grad Norm 0.804029 0.16s/it\n","Train loss 22607 0.562197 Grad Norm 1.064210 0.15s/it\n","Train loss 22608 0.672243 Grad Norm 3.158660 0.12s/it\n","Train loss 22609 0.393524 Grad Norm 0.658897 0.13s/it\n","Train loss 22610 0.441983 Grad Norm 1.365009 0.10s/it\n","Train loss 22611 0.428529 Grad Norm 0.922355 0.12s/it\n","Train loss 22612 0.495948 Grad Norm 1.853416 0.17s/it\n","Train loss 22613 0.656108 Grad Norm 1.498546 0.12s/it\n","Train loss 22614 0.487999 Grad Norm 0.861026 0.15s/it\n","Train loss 22615 0.636828 Grad Norm 1.601612 0.14s/it\n","Train loss 22616 0.644929 Grad Norm 2.817930 0.10s/it\n","Train loss 22617 0.564676 Grad Norm 0.994580 0.11s/it\n","Train loss 22618 0.363740 Grad Norm 0.518258 0.15s/it\n","Train loss 22619 0.344762 Grad Norm 1.658939 0.11s/it\n","Train loss 22620 0.636243 Grad Norm 2.156593 0.12s/it\n","Train loss 22621 0.698745 Grad Norm 1.250954 0.11s/it\n","Train loss 22622 0.738188 Grad Norm 1.048290 0.11s/it\n","Train loss 22623 0.470259 Grad Norm 1.199254 0.13s/it\n","Train loss 22624 0.369530 Grad Norm 1.041821 0.11s/it\n","Train loss 22625 0.656993 Grad Norm 1.527680 0.13s/it\n","Train loss 22626 0.601433 Grad Norm 1.025332 0.12s/it\n","Train loss 22627 0.279559 Grad Norm 0.724950 0.15s/it\n","Train loss 22628 0.608151 Grad Norm 0.785578 0.11s/it\n","Train loss 22629 0.332329 Grad Norm 1.036826 0.13s/it\n","Train loss 22630 0.450324 Grad Norm 1.251187 0.13s/it\n","Train loss 22631 0.513640 Grad Norm 0.701773 0.11s/it\n","Train loss 22632 0.609280 Grad Norm 1.022984 0.12s/it\n","Train loss 22633 0.629627 Grad Norm 1.824608 0.16s/it\n","Train loss 22634 0.462656 Grad Norm 0.647221 0.13s/it\n","Train loss 22635 0.550042 Grad Norm 1.286934 0.11s/it\n","Train loss 22636 0.557516 Grad Norm 1.634109 0.10s/it\n","Train loss 22637 0.593954 Grad Norm 2.724856 0.11s/it\n","Train loss 22638 0.394468 Grad Norm 0.896115 0.13s/it\n","Train loss 22639 0.604475 Grad Norm 0.838373 0.15s/it\n","Train loss 22640 0.607407 Grad Norm 1.186985 0.11s/it\n","Train loss 22641 1.006469 Grad Norm 3.663568 0.12s/it\n","Train loss 22642 0.384910 Grad Norm 0.522882 0.16s/it\n","Train loss 22643 0.493498 Grad Norm 1.914702 0.13s/it\n","Train loss 22644 0.673990 Grad Norm 1.317233 0.13s/it\n","Train loss 22645 0.479378 Grad Norm 0.939403 0.13s/it\n","Train loss 22646 0.554888 Grad Norm 2.554448 0.13s/it\n","Train loss 22647 0.421954 Grad Norm 0.903025 0.12s/it\n","Train loss 22648 0.834535 Grad Norm 1.770007 0.13s/it\n","Train loss 22649 0.576474 Grad Norm 1.210320 0.11s/it\n","Train loss 22650 0.576467 Grad Norm 0.738079 0.13s/it\n","Train loss 22651 0.779236 Grad Norm 2.702926 0.11s/it\n","Train loss 22652 0.484925 Grad Norm 1.392316 0.13s/it\n","Train loss 22653 0.630972 Grad Norm 1.043443 0.14s/it\n","Train loss 22654 0.283936 Grad Norm 0.537114 0.12s/it\n","Train loss 22655 0.535196 Grad Norm 0.987702 0.11s/it\n","Train loss 22656 0.528077 Grad Norm 1.330706 0.12s/it\n","Train loss 22657 0.563827 Grad Norm 0.882841 0.14s/it\n","Train loss 22658 0.421395 Grad Norm 1.244996 0.13s/it\n","Train loss 22659 0.662856 Grad Norm 1.197926 0.13s/it\n","Train loss 22660 0.661233 Grad Norm 0.963029 0.10s/it\n","Train loss 22661 0.671397 Grad Norm 1.367314 0.13s/it\n","Train loss 22662 0.681460 Grad Norm 1.551402 0.11s/it\n","Train loss 22663 0.552014 Grad Norm 1.122113 0.12s/it\n","Train loss 22664 0.400754 Grad Norm 1.330639 0.13s/it\n","Train loss 22665 0.643881 Grad Norm 1.530004 0.11s/it\n","Train loss 22666 0.453506 Grad Norm 2.092846 0.11s/it\n","Train loss 22667 0.630185 Grad Norm 0.903610 0.13s/it\n","Train loss 22668 0.409053 Grad Norm 1.962728 0.13s/it\n","Train loss 22669 0.441415 Grad Norm 0.656785 0.11s/it\n","Train loss 22670 0.352588 Grad Norm 1.144258 0.13s/it\n","Train loss 22671 0.629187 Grad Norm 2.716350 0.13s/it\n","Train loss 22672 0.453316 Grad Norm 1.278169 0.11s/it\n","Train loss 22673 0.484943 Grad Norm 1.672833 0.12s/it\n","Train loss 22674 0.613723 Grad Norm 4.194452 0.10s/it\n","Train loss 22675 0.608473 Grad Norm 2.191566 0.12s/it\n","Train loss 22676 0.502354 Grad Norm 7.819797 0.16s/it\n","Train loss 22677 0.791057 Grad Norm 2.068645 0.11s/it\n","Train loss 22678 0.555352 Grad Norm 0.751435 0.13s/it\n","Train loss 22679 0.838753 Grad Norm 2.468084 0.12s/it\n","Train loss 22680 0.612157 Grad Norm 3.939671 0.10s/it\n","Train loss 22681 0.441241 Grad Norm 1.314493 0.12s/it\n","Train loss 22682 0.656992 Grad Norm 2.132529 0.11s/it\n","Train loss 22683 0.699788 Grad Norm 1.637299 0.12s/it\n","Train loss 22684 0.558837 Grad Norm 0.751351 0.13s/it\n","Train loss 22685 0.772606 Grad Norm 1.371132 0.15s/it\n","Train loss 22686 0.721956 Grad Norm 1.566180 0.13s/it\n","Train loss 22687 0.615548 Grad Norm 1.309485 0.11s/it\n","Train loss 22688 0.617877 Grad Norm 2.370075 0.13s/it\n","Train loss 22689 0.480501 Grad Norm 1.691156 0.13s/it\n","Train loss 22690 0.567005 Grad Norm 1.522940 0.13s/it\n","Train loss 22691 0.439849 Grad Norm 0.722859 0.11s/it\n","Train loss 22692 0.874314 Grad Norm 2.920058 0.13s/it\n","Train loss 22693 0.642512 Grad Norm 1.123542 0.12s/it\n","Train loss 22694 0.492765 Grad Norm 1.287961 0.14s/it\n","Train loss 22695 0.327942 Grad Norm 0.764660 0.13s/it\n","Train loss 22696 0.533731 Grad Norm 2.093684 0.13s/it\n","Train loss 22697 0.639313 Grad Norm 1.771717 0.15s/it\n","Train loss 22698 0.477249 Grad Norm 2.158148 0.14s/it\n","Train loss 22699 0.461867 Grad Norm 1.619969 0.10s/it\n","Train loss 22700 0.409282 Grad Norm 1.224286 0.16s/it\n","Train loss 22701 0.462782 Grad Norm 1.142147 0.14s/it\n","Train loss 22702 0.686408 Grad Norm 1.411142 0.12s/it\n","Train loss 22703 0.401637 Grad Norm 0.820938 0.16s/it\n","Train loss 22704 0.556273 Grad Norm 1.456242 0.11s/it\n","Train loss 22705 0.774451 Grad Norm 3.180395 0.15s/it\n","Train loss 22706 0.814141 Grad Norm 1.455810 0.13s/it\n","Train loss 22707 0.396938 Grad Norm 0.959670 0.14s/it\n","Train loss 22708 0.529349 Grad Norm 2.375641 0.11s/it\n","Train loss 22709 0.574931 Grad Norm 1.716771 0.12s/it\n","Train loss 22710 0.415110 Grad Norm 0.709801 0.13s/it\n","Train loss 22711 0.620898 Grad Norm 0.825859 0.13s/it\n","Train loss 22712 0.704971 Grad Norm 1.336204 0.13s/it\n","Train loss 22713 0.538650 Grad Norm 1.891182 0.14s/it\n","Train loss 22714 0.826226 Grad Norm 0.983291 0.12s/it\n","Train loss 22715 0.502244 Grad Norm 3.299673 0.12s/it\n","Train loss 22716 0.798298 Grad Norm 1.507667 0.11s/it\n","Train loss 22717 0.437239 Grad Norm 1.100662 0.13s/it\n","Train loss 22718 0.573781 Grad Norm 1.732049 0.13s/it\n","Train loss 22719 0.421686 Grad Norm 1.082607 0.11s/it\n","Train loss 22720 0.629971 Grad Norm 3.033755 0.11s/it\n","Train loss 22721 0.530451 Grad Norm 1.397686 0.13s/it\n","Train loss 22722 0.576214 Grad Norm 1.334190 0.13s/it\n","Train loss 22723 0.541097 Grad Norm 1.312646 0.13s/it\n","Train loss 22724 0.643769 Grad Norm 1.948453 0.11s/it\n","Train loss 22725 0.543637 Grad Norm 0.836044 0.12s/it\n","Train loss 22726 0.639138 Grad Norm 2.072501 0.15s/it\n","Train loss 22727 0.651913 Grad Norm 3.378057 0.10s/it\n","Train loss 22728 0.775581 Grad Norm 4.361528 0.11s/it\n","Train loss 22729 0.440705 Grad Norm 1.128945 0.15s/it\n","Train loss 22730 0.615622 Grad Norm 4.325649 0.12s/it\n","Train loss 22731 0.542022 Grad Norm 1.361313 0.12s/it\n","Train loss 22732 0.560924 Grad Norm 3.046739 0.14s/it\n","Train loss 22733 0.436394 Grad Norm 1.421356 0.11s/it\n","Train loss 22734 0.442294 Grad Norm 1.090997 0.12s/it\n","Train loss 22735 0.535207 Grad Norm 0.992992 0.15s/it\n","Train loss 22736 0.580748 Grad Norm 1.311869 0.11s/it\n","Train loss 22737 0.659941 Grad Norm 1.937132 0.11s/it\n","Train loss 22738 0.255616 Grad Norm 0.443516 0.12s/it\n","Train loss 22739 0.833168 Grad Norm 3.616755 0.12s/it\n","Train loss 22740 0.623299 Grad Norm 1.481388 0.14s/it\n","Train loss 22741 0.797851 Grad Norm 2.161826 0.12s/it\n","Train loss 22742 0.760604 Grad Norm 4.721388 0.17s/it\n","Train loss 22743 0.569408 Grad Norm 1.220310 0.12s/it\n","Train loss 22744 0.649319 Grad Norm 2.173369 0.11s/it\n","Train loss 22745 0.379276 Grad Norm 2.029569 0.11s/it\n","Train loss 22746 0.629284 Grad Norm 1.831253 0.13s/it\n","Train loss 22747 0.534610 Grad Norm 1.006807 0.14s/it\n","Train loss 22748 0.876730 Grad Norm 2.843941 0.12s/it\n","Train loss 22749 0.622098 Grad Norm 4.925059 0.11s/it\n","Train loss 22750 0.512500 Grad Norm 2.093992 0.11s/it\n","Train loss 22751 0.423956 Grad Norm 0.829958 0.15s/it\n","Train loss 22752 0.708814 Grad Norm 3.571011 0.12s/it\n","Train loss 22753 0.788454 Grad Norm 2.161468 0.12s/it\n","Train loss 22754 0.738923 Grad Norm 1.164310 0.13s/it\n","Train loss 22755 0.756842 Grad Norm 1.531507 0.11s/it\n","Train loss 22756 0.593676 Grad Norm 1.918766 0.13s/it\n","Train loss 22757 0.414045 Grad Norm 0.545382 0.14s/it\n","Train loss 22758 0.505044 Grad Norm 0.873516 0.11s/it\n","Train loss 22759 0.656581 Grad Norm 2.193640 0.11s/it\n","Train loss 22760 0.488096 Grad Norm 1.020740 0.10s/it\n","Train loss 22761 0.610410 Grad Norm 1.871924 0.11s/it\n","Train loss 22762 0.395931 Grad Norm 1.148894 0.12s/it\n","Train loss 22763 0.472886 Grad Norm 1.123248 0.11s/it\n","Train loss 22764 0.870898 Grad Norm 5.086224 0.15s/it\n","Train loss 22765 0.479404 Grad Norm 1.388572 0.15s/it\n","Train loss 22766 0.771130 Grad Norm 2.887795 0.12s/it\n","Train loss 22767 0.657090 Grad Norm 1.255312 0.15s/it\n","Train loss 22768 0.388561 Grad Norm 0.798078 0.18s/it\n","Train loss 22769 0.547198 Grad Norm 2.105908 0.14s/it\n","Train loss 22770 0.608231 Grad Norm 1.693912 0.12s/it\n","Train loss 22771 0.510088 Grad Norm 1.384774 0.13s/it\n","Train loss 22772 0.639650 Grad Norm 1.089345 0.12s/it\n","Train loss 22773 0.515484 Grad Norm 2.135477 0.14s/it\n","Train loss 22774 0.574306 Grad Norm 1.409991 0.13s/it\n","Train loss 22775 0.481394 Grad Norm 0.857768 0.12s/it\n","Train loss 22776 0.510624 Grad Norm 1.062310 0.12s/it\n","Train loss 22777 0.769973 Grad Norm 2.312140 0.11s/it\n","Train loss 22778 0.513763 Grad Norm 1.263884 0.15s/it\n","Train loss 22779 0.589753 Grad Norm 0.952959 0.12s/it\n","Train loss 22780 0.517737 Grad Norm 1.693518 0.11s/it\n","Train loss 22781 0.616885 Grad Norm 2.055955 0.12s/it\n","Train loss 22782 0.415184 Grad Norm 1.679101 0.14s/it\n","Train loss 22783 0.513865 Grad Norm 1.911728 0.14s/it\n","Train loss 22784 0.532462 Grad Norm 1.149452 0.12s/it\n","Train loss 22785 0.561493 Grad Norm 1.451452 0.11s/it\n","Train loss 22786 0.433141 Grad Norm 0.668940 0.15s/it\n","Train loss 22787 0.455822 Grad Norm 1.343818 0.11s/it\n","Train loss 22788 0.478565 Grad Norm 1.268916 0.11s/it\n","Train loss 22789 0.533718 Grad Norm 1.379562 0.12s/it\n","Train loss 22790 0.564122 Grad Norm 1.805023 0.10s/it\n","Train loss 22791 0.625524 Grad Norm 1.748475 0.13s/it\n","Train loss 22792 0.471193 Grad Norm 2.951675 0.12s/it\n","Train loss 22793 0.488381 Grad Norm 3.327450 0.10s/it\n","Train loss 22794 0.501737 Grad Norm 2.519081 0.16s/it\n","Train loss 22795 0.541755 Grad Norm 0.604117 0.14s/it\n","Train loss 22796 0.504174 Grad Norm 5.887914 0.14s/it\n","Train loss 22797 0.652115 Grad Norm 2.897158 0.13s/it\n","Train loss 22798 0.518981 Grad Norm 2.422498 0.11s/it\n","Train loss 22799 0.846666 Grad Norm 3.455476 0.13s/it\n","Train loss 22800 0.841249 Grad Norm 4.031569 0.15s/it\n","Train loss 22801 0.664995 Grad Norm 1.460109 0.11s/it\n","Train loss 22802 0.785299 Grad Norm 1.008424 0.16s/it\n","Train loss 22803 0.356040 Grad Norm 1.637643 0.14s/it\n","Train loss 22804 0.394907 Grad Norm 1.312429 0.11s/it\n","Train loss 22805 0.538995 Grad Norm 1.971497 0.13s/it\n","Train loss 22806 0.579601 Grad Norm 1.117019 0.11s/it\n","Train loss 22807 0.558061 Grad Norm 2.305952 0.11s/it\n","Train loss 22808 0.407297 Grad Norm 0.605366 0.13s/it\n","Train loss 22809 0.477197 Grad Norm 1.141022 0.13s/it\n","Train loss 22810 0.503115 Grad Norm 2.839608 0.14s/it\n","Train loss 22811 0.615448 Grad Norm 1.083184 0.16s/it\n","Train loss 22812 0.614519 Grad Norm 2.807012 0.12s/it\n","Train loss 22813 0.500779 Grad Norm 0.958653 0.16s/it\n","Train loss 22814 0.787029 Grad Norm 2.227561 0.12s/it\n","Train loss 22815 0.728015 Grad Norm 0.955383 0.13s/it\n","Train loss 22816 0.886430 Grad Norm 1.761276 0.13s/it\n","Train loss 22817 0.543648 Grad Norm 1.143219 0.12s/it\n","Train loss 22818 0.307980 Grad Norm 0.459062 0.11s/it\n","Train loss 22819 0.466378 Grad Norm 0.908313 0.14s/it\n","Train loss 22820 0.834935 Grad Norm 2.101045 0.13s/it\n","Train loss 22821 0.483210 Grad Norm 1.332530 0.13s/it\n","Train loss 22822 0.605904 Grad Norm 2.275809 0.11s/it\n","Train loss 22823 0.476496 Grad Norm 0.585051 0.13s/it\n","Train loss 22824 0.711010 Grad Norm 1.024506 0.14s/it\n","Train loss 22825 0.451883 Grad Norm 1.382193 0.13s/it\n","Train loss 22826 0.540408 Grad Norm 1.541207 0.14s/it\n","Train loss 22827 0.460844 Grad Norm 1.398870 0.13s/it\n","Train loss 22828 0.616808 Grad Norm 1.325265 0.16s/it\n","Train loss 22829 0.539294 Grad Norm 3.811078 0.18s/it\n","Train loss 22830 0.674745 Grad Norm 1.673771 0.12s/it\n","Train loss 22831 0.378863 Grad Norm 0.745996 0.15s/it\n","Train loss 22832 0.790321 Grad Norm 1.483937 0.11s/it\n","Train loss 22833 0.440234 Grad Norm 1.150197 0.15s/it\n","Train loss 22834 0.522080 Grad Norm 1.206453 0.13s/it\n","Train loss 22835 0.456575 Grad Norm 0.813706 0.11s/it\n","Train loss 22836 0.479257 Grad Norm 0.952150 0.13s/it\n","Train loss 22837 0.413615 Grad Norm 1.253113 0.11s/it\n","Train loss 22838 0.354766 Grad Norm 0.625963 0.15s/it\n","Train loss 22839 0.490368 Grad Norm 1.292764 0.14s/it\n","Train loss 22840 0.321340 Grad Norm 1.075467 0.13s/it\n","Train loss 22841 0.706531 Grad Norm 5.620799 0.13s/it\n","Train loss 22842 0.691193 Grad Norm 1.610029 0.12s/it\n","Train loss 22843 0.934663 Grad Norm 2.270143 0.14s/it\n","Train loss 22844 0.452539 Grad Norm 0.491357 0.13s/it\n","Train loss 22845 0.581234 Grad Norm 0.774666 0.15s/it\n","Train loss 22846 0.554914 Grad Norm 2.180853 0.11s/it\n","Train loss 22847 0.589628 Grad Norm 1.910858 0.12s/it\n","Train loss 22848 0.426914 Grad Norm 1.019246 0.10s/it\n","Train loss 22849 0.690516 Grad Norm 1.676955 0.12s/it\n","Train loss 22850 0.666415 Grad Norm 1.027122 0.16s/it\n","Train loss 22851 0.522158 Grad Norm 2.308761 0.12s/it\n","Train loss 22852 0.460545 Grad Norm 0.950641 0.11s/it\n","Train loss 22853 0.452505 Grad Norm 0.877008 0.13s/it\n","Train loss 22854 0.605869 Grad Norm 2.296380 0.13s/it\n","Train loss 22855 0.607096 Grad Norm 2.289139 0.12s/it\n","Train loss 22856 0.445332 Grad Norm 1.583103 0.12s/it\n","Train loss 22857 0.363416 Grad Norm 1.800505 0.11s/it\n","Train loss 22858 0.659586 Grad Norm 1.878826 0.12s/it\n","Train loss 22859 0.517371 Grad Norm 1.439059 0.10s/it\n","Train loss 22860 0.650238 Grad Norm 2.432326 0.13s/it\n","Train loss 22861 0.520165 Grad Norm 1.784312 0.16s/it\n","Train loss 22862 0.407548 Grad Norm 1.350443 0.12s/it\n","Train loss 22863 0.391712 Grad Norm 1.958258 0.14s/it\n","Train loss 22864 0.583457 Grad Norm 0.959946 0.12s/it\n","Train loss 22865 0.819345 Grad Norm 2.041529 0.11s/it\n","Train loss 22866 0.361309 Grad Norm 0.403469 0.12s/it\n","Train loss 22867 0.503556 Grad Norm 1.058731 0.17s/it\n","Train loss 22868 0.477883 Grad Norm 0.943868 0.10s/it\n","Train loss 22869 0.420947 Grad Norm 0.643436 0.15s/it\n","Train loss 22870 0.425432 Grad Norm 1.134237 0.11s/it\n","Train loss 22871 0.541603 Grad Norm 1.223285 0.12s/it\n","Train loss 22872 0.414225 Grad Norm 0.748943 0.13s/it\n","Train loss 22873 0.362513 Grad Norm 3.522389 0.14s/it\n","Train loss 22874 0.708105 Grad Norm 0.938148 0.11s/it\n","Train loss 22875 0.505897 Grad Norm 1.571871 0.14s/it\n","Train loss 22876 0.322556 Grad Norm 0.713016 0.11s/it\n","Train loss 22877 0.588006 Grad Norm 1.370449 0.12s/it\n","Train loss 22878 0.352678 Grad Norm 1.349667 0.15s/it\n","Train loss 22879 0.748298 Grad Norm 4.567490 0.11s/it\n","Train loss 22880 0.296877 Grad Norm 1.164175 0.15s/it\n","Train loss 22881 0.503149 Grad Norm 1.491617 0.11s/it\n","Train loss 22882 0.498855 Grad Norm 0.585290 0.14s/it\n","Train loss 22883 0.536375 Grad Norm 1.285897 0.12s/it\n","Train loss 22884 0.693404 Grad Norm 4.017176 0.12s/it\n","Train loss 22885 0.603967 Grad Norm 1.858698 0.11s/it\n","Train loss 22886 0.432173 Grad Norm 1.494752 0.15s/it\n","Train loss 22887 0.390705 Grad Norm 1.045568 0.11s/it\n","Train loss 22888 0.498937 Grad Norm 0.667450 0.13s/it\n","Train loss 22889 0.579599 Grad Norm 1.205001 0.11s/it\n","Train loss 22890 0.490844 Grad Norm 1.016357 0.13s/it\n","Train loss 22891 0.575435 Grad Norm 1.341765 0.14s/it\n","Train loss 22892 0.513892 Grad Norm 2.585479 0.13s/it\n","Train loss 22893 0.667108 Grad Norm 2.780819 0.13s/it\n","Train loss 22894 0.985623 Grad Norm 2.711141 0.12s/it\n","Train loss 22895 0.569881 Grad Norm 1.274762 0.13s/it\n","Train loss 22896 0.742618 Grad Norm 2.725406 0.13s/it\n","Train loss 22897 0.570406 Grad Norm 1.910319 0.11s/it\n","Train loss 22898 0.560590 Grad Norm 1.732931 0.10s/it\n","Train loss 22899 0.487592 Grad Norm 0.918079 0.10s/it\n","Train loss 22900 0.463079 Grad Norm 0.981521 0.11s/it\n","Train loss 22901 0.902530 Grad Norm 2.628350 0.10s/it\n","Train loss 22902 0.593212 Grad Norm 1.567401 0.13s/it\n","Train loss 22903 0.413722 Grad Norm 0.932482 0.15s/it\n","Train loss 22904 0.440822 Grad Norm 0.597571 0.14s/it\n","Train loss 22905 0.521690 Grad Norm 1.486459 0.12s/it\n","Train loss 22906 0.484701 Grad Norm 1.115171 0.13s/it\n","Train loss 22907 0.532602 Grad Norm 0.961561 0.12s/it\n","Train loss 22908 0.599120 Grad Norm 0.966343 0.14s/it\n","Train loss 22909 0.542650 Grad Norm 1.030488 0.12s/it\n","Train loss 22910 0.393608 Grad Norm 1.654417 0.16s/it\n","Train loss 22911 0.445241 Grad Norm 1.619294 0.14s/it\n","Train loss 22912 0.557640 Grad Norm 1.796177 0.14s/it\n","Train loss 22913 0.699862 Grad Norm 2.455990 0.11s/it\n","Train loss 22914 0.355927 Grad Norm 1.716249 0.14s/it\n","Train loss 22915 0.412591 Grad Norm 0.848148 0.15s/it\n","Train loss 22916 0.392882 Grad Norm 0.777057 0.13s/it\n","Train loss 22917 0.830794 Grad Norm 1.539302 0.13s/it\n","Train loss 22918 0.795675 Grad Norm 2.083581 0.12s/it\n","Train loss 22919 0.657279 Grad Norm 1.627850 0.13s/it\n","Train loss 22920 0.385035 Grad Norm 1.867870 0.14s/it\n","Train loss 22921 0.761211 Grad Norm 1.863423 0.14s/it\n","Train loss 22922 0.454547 Grad Norm 0.955225 0.13s/it\n","Train loss 22923 0.762827 Grad Norm 1.676095 0.11s/it\n","Train loss 22924 0.761312 Grad Norm 1.989060 0.11s/it\n","Train loss 22925 0.560401 Grad Norm 1.041784 0.12s/it\n","Train loss 22926 0.548616 Grad Norm 2.110133 0.11s/it\n","Train loss 22927 0.483603 Grad Norm 1.102340 0.11s/it\n","Train loss 22928 0.839493 Grad Norm 2.414511 0.14s/it\n","Train loss 22929 0.604397 Grad Norm 0.797572 0.10s/it\n","Train loss 22930 0.615578 Grad Norm 1.164209 0.12s/it\n","Train loss 22931 0.680295 Grad Norm 0.755329 0.13s/it\n","Train loss 22932 0.672205 Grad Norm 1.194867 0.13s/it\n","Train loss 22933 0.896146 Grad Norm 1.734833 0.14s/it\n","Train loss 22934 0.477443 Grad Norm 1.230227 0.14s/it\n","Train loss 22935 0.620841 Grad Norm 1.126411 0.13s/it\n","Train loss 22936 0.764936 Grad Norm 6.199880 0.11s/it\n","Train loss 22937 0.609742 Grad Norm 1.639250 0.12s/it\n","Train loss 22938 0.460789 Grad Norm 1.206450 0.10s/it\n","Train loss 22939 0.519019 Grad Norm 1.606083 0.15s/it\n","Train loss 22940 0.547668 Grad Norm 1.028151 0.11s/it\n","Train loss 22941 0.398202 Grad Norm 1.294753 0.13s/it\n","Train loss 22942 0.581193 Grad Norm 1.907632 0.11s/it\n","Train loss 22943 0.453779 Grad Norm 0.980660 0.12s/it\n","Train loss 22944 0.702040 Grad Norm 2.675336 0.11s/it\n","Train loss 22945 0.682563 Grad Norm 1.089278 0.12s/it\n","Train loss 22946 0.687399 Grad Norm 1.373144 0.14s/it\n","Train loss 22947 0.800263 Grad Norm 3.682591 0.16s/it\n","Train loss 22948 0.629951 Grad Norm 1.328249 0.12s/it\n","Train loss 22949 0.607304 Grad Norm 3.184396 0.11s/it\n","Train loss 22950 0.536623 Grad Norm 1.645673 0.11s/it\n","Train loss 22951 0.516021 Grad Norm 2.393982 0.13s/it\n","Train loss 22952 0.509933 Grad Norm 1.231231 0.13s/it\n","Train loss 22953 0.431524 Grad Norm 0.706802 0.11s/it\n","Train loss 22954 0.567326 Grad Norm 1.180411 0.12s/it\n","Train loss 22955 0.627857 Grad Norm 2.347951 0.15s/it\n","Train loss 22956 0.541131 Grad Norm 1.690792 0.13s/it\n","Train loss 22957 0.443178 Grad Norm 0.697320 0.14s/it\n","Train loss 22958 0.557271 Grad Norm 0.954886 0.14s/it\n","Train loss 22959 0.400171 Grad Norm 0.592837 0.12s/it\n","Train loss 22960 0.462204 Grad Norm 1.344942 0.12s/it\n","Train loss 22961 0.389977 Grad Norm 1.075773 0.10s/it\n","Train loss 22962 0.494187 Grad Norm 2.535230 0.10s/it\n","Train loss 22963 0.452376 Grad Norm 1.707278 0.13s/it\n","Train loss 22964 0.612393 Grad Norm 1.322684 0.13s/it\n","Train loss 22965 0.735149 Grad Norm 2.627626 0.14s/it\n","Train loss 22966 0.429979 Grad Norm 1.342633 0.13s/it\n","Train loss 22967 0.457841 Grad Norm 1.301482 0.13s/it\n","Train loss 22968 0.621181 Grad Norm 1.654660 0.14s/it\n","Train loss 22969 0.529894 Grad Norm 1.791148 0.14s/it\n","Train loss 22970 0.602024 Grad Norm 2.463890 0.12s/it\n","Train loss 22971 0.553228 Grad Norm 1.074687 0.13s/it\n","Train loss 22972 0.463517 Grad Norm 0.984829 0.14s/it\n","Train loss 22973 0.620093 Grad Norm 1.185762 0.12s/it\n","Train loss 22974 0.343002 Grad Norm 0.567239 0.13s/it\n","Train loss 22975 0.453985 Grad Norm 0.751207 0.13s/it\n","Train loss 22976 0.514884 Grad Norm 1.233410 0.11s/it\n","Train loss 22977 0.394801 Grad Norm 1.503672 0.10s/it\n","Train loss 22978 0.579443 Grad Norm 1.824441 0.13s/it\n","Train loss 22979 0.810803 Grad Norm 1.541904 0.13s/it\n","Train loss 22980 0.268047 Grad Norm 0.394303 0.11s/it\n","Train loss 22981 0.611163 Grad Norm 1.711666 0.12s/it\n","Train loss 22982 0.800789 Grad Norm 1.714460 0.11s/it\n","Train loss 22983 0.628563 Grad Norm 1.218424 0.13s/it\n","Train loss 22984 0.501902 Grad Norm 1.530923 0.13s/it\n","Train loss 22985 0.346263 Grad Norm 1.858017 0.14s/it\n","Train loss 22986 0.531238 Grad Norm 3.729013 0.10s/it\n","Train loss 22987 0.613496 Grad Norm 2.639041 0.12s/it\n","Train loss 22988 0.827189 Grad Norm 1.489149 0.11s/it\n","Train loss 22989 0.417654 Grad Norm 1.025108 0.11s/it\n","Train loss 22990 0.430160 Grad Norm 1.775762 0.11s/it\n","Train loss 22991 0.707114 Grad Norm 1.621690 0.11s/it\n","Train loss 22992 0.548180 Grad Norm 2.688687 0.12s/it\n","Train loss 22993 0.504797 Grad Norm 1.089339 0.13s/it\n","Train loss 22994 0.951916 Grad Norm 2.657445 0.12s/it\n","Train loss 22995 0.490749 Grad Norm 2.476385 0.12s/it\n","Train loss 22996 0.679683 Grad Norm 3.656189 0.12s/it\n","Train loss 22997 0.529451 Grad Norm 1.373803 0.16s/it\n","Train loss 22998 0.651219 Grad Norm 1.507441 0.14s/it\n","Train loss 22999 0.766851 Grad Norm 1.554488 0.16s/it\n","Train loss 23000 0.440074 Grad Norm 2.274819 0.16s/it\n","Validation loss 23000: 0.419095\n","Saving model and optimizer state at iteration 23000 to checkpoint_23000\n","Train loss 23001 0.775504 Grad Norm 1.243881 0.11s/it\n","Train loss 23002 0.560231 Grad Norm 1.427127 0.12s/it\n","Train loss 23003 0.789581 Grad Norm 2.112727 0.15s/it\n","Train loss 23004 0.561587 Grad Norm 0.758311 0.15s/it\n","Train loss 23005 0.688086 Grad Norm 1.095351 0.14s/it\n","Train loss 23006 0.570796 Grad Norm 7.289161 0.12s/it\n","Train loss 23007 0.504878 Grad Norm 1.829546 0.14s/it\n","Train loss 23008 0.645752 Grad Norm 4.061485 0.11s/it\n","Train loss 23009 0.665456 Grad Norm 1.445158 0.12s/it\n","Train loss 23010 0.626542 Grad Norm 1.390327 0.12s/it\n","Train loss 23011 0.434986 Grad Norm 1.654722 0.13s/it\n","Train loss 23012 0.475389 Grad Norm 1.350876 0.13s/it\n","Train loss 23013 0.566128 Grad Norm 2.526699 0.10s/it\n","Train loss 23014 0.436645 Grad Norm 0.955505 0.10s/it\n","Train loss 23015 0.532822 Grad Norm 0.985188 0.12s/it\n","Train loss 23016 0.491329 Grad Norm 1.214443 0.12s/it\n","Train loss 23017 0.460557 Grad Norm 0.714737 0.14s/it\n","Train loss 23018 0.525287 Grad Norm 2.072320 0.12s/it\n","Train loss 23019 0.501437 Grad Norm 0.726500 0.14s/it\n","Train loss 23020 0.393753 Grad Norm 0.532328 0.11s/it\n","Train loss 23021 0.449235 Grad Norm 2.279360 0.14s/it\n","Train loss 23022 0.661571 Grad Norm 1.438090 0.13s/it\n","Train loss 23023 0.496966 Grad Norm 0.882285 0.13s/it\n","Train loss 23024 0.411577 Grad Norm 0.877062 0.14s/it\n","Train loss 23025 0.532924 Grad Norm 1.339653 0.11s/it\n","Train loss 23026 0.476193 Grad Norm 1.339189 0.15s/it\n","Train loss 23027 0.573341 Grad Norm 4.045975 0.12s/it\n","Train loss 23028 0.773016 Grad Norm 1.494661 0.12s/it\n","Train loss 23029 0.777785 Grad Norm 2.109674 0.14s/it\n","Train loss 23030 0.466875 Grad Norm 1.378251 0.13s/it\n","Train loss 23031 0.622574 Grad Norm 2.373627 0.12s/it\n","Train loss 23032 0.679938 Grad Norm 1.172174 0.13s/it\n","Train loss 23033 0.507240 Grad Norm 1.193366 0.14s/it\n","Train loss 23034 0.630149 Grad Norm 1.699246 0.11s/it\n","Train loss 23035 0.736764 Grad Norm 1.489500 0.13s/it\n","Train loss 23036 0.640531 Grad Norm 1.257071 0.11s/it\n","Train loss 23037 0.388628 Grad Norm 1.152980 0.13s/it\n","Train loss 23038 0.589368 Grad Norm 1.243982 0.14s/it\n","Train loss 23039 0.651231 Grad Norm 1.919100 0.14s/it\n","Train loss 23040 0.969122 Grad Norm 3.298330 0.12s/it\n","Train loss 23041 0.474771 Grad Norm 0.824444 0.14s/it\n","Train loss 23042 0.589599 Grad Norm 1.243856 0.12s/it\n","Train loss 23043 0.496909 Grad Norm 1.096739 0.10s/it\n","Train loss 23044 0.439428 Grad Norm 0.659333 0.09s/it\n","Train loss 23045 0.287102 Grad Norm 0.530227 0.13s/it\n","Train loss 23046 0.505901 Grad Norm 1.764238 0.18s/it\n","Train loss 23047 0.382090 Grad Norm 0.600357 0.13s/it\n","Train loss 23048 0.528986 Grad Norm 1.154840 0.12s/it\n","Train loss 23049 0.489216 Grad Norm 0.960866 0.11s/it\n","Train loss 23050 0.418431 Grad Norm 0.948692 0.13s/it\n","Train loss 23051 0.639066 Grad Norm 1.859770 0.14s/it\n","Train loss 23052 0.455628 Grad Norm 0.788205 0.10s/it\n","Train loss 23053 0.603979 Grad Norm 1.401339 0.12s/it\n","Train loss 23054 0.568440 Grad Norm 0.920340 0.12s/it\n","Train loss 23055 0.498769 Grad Norm 1.252614 0.14s/it\n","Train loss 23056 0.538356 Grad Norm 1.238150 0.15s/it\n","Train loss 23057 0.644087 Grad Norm 2.083362 0.12s/it\n","Train loss 23058 0.606294 Grad Norm 0.710391 0.12s/it\n","Train loss 23059 0.702139 Grad Norm 1.706963 0.11s/it\n","Train loss 23060 0.441738 Grad Norm 1.236688 0.10s/it\n","Train loss 23061 0.617931 Grad Norm 2.078552 0.12s/it\n","Train loss 23062 0.532434 Grad Norm 1.318501 0.12s/it\n","Train loss 23063 0.553953 Grad Norm 0.866136 0.15s/it\n","Train loss 23064 0.948254 Grad Norm 1.259184 0.15s/it\n","Train loss 23065 0.708663 Grad Norm 2.485490 0.12s/it\n","Train loss 23066 0.991598 Grad Norm 1.911648 0.12s/it\n","Train loss 23067 0.555704 Grad Norm 4.630407 0.13s/it\n","Train loss 23068 0.375183 Grad Norm 0.674781 0.09s/it\n","Train loss 23069 0.573746 Grad Norm 1.455863 0.14s/it\n","Train loss 23070 0.823775 Grad Norm 1.457843 0.11s/it\n","Train loss 23071 0.634757 Grad Norm 1.688907 0.11s/it\n","Train loss 23072 0.490757 Grad Norm 1.639754 0.13s/it\n","Train loss 23073 0.420253 Grad Norm 1.153295 0.13s/it\n","Train loss 23074 0.492724 Grad Norm 1.014951 0.10s/it\n","Train loss 23075 0.495690 Grad Norm 0.734107 0.11s/it\n","Train loss 23076 0.556337 Grad Norm 1.292325 0.14s/it\n","Train loss 23077 0.820146 Grad Norm 2.128602 0.11s/it\n","Train loss 23078 0.660681 Grad Norm 2.205446 0.11s/it\n","Train loss 23079 0.449358 Grad Norm 1.311002 0.13s/it\n","Train loss 23080 0.291060 Grad Norm 0.640258 0.14s/it\n","Train loss 23081 0.319504 Grad Norm 0.821077 0.11s/it\n","Train loss 23082 0.559450 Grad Norm 2.113086 0.12s/it\n","Train loss 23083 0.534273 Grad Norm 1.378105 0.12s/it\n","Train loss 23084 0.476053 Grad Norm 0.628618 0.11s/it\n","Train loss 23085 0.474995 Grad Norm 0.902605 0.11s/it\n","Train loss 23086 0.715994 Grad Norm 1.779204 0.11s/it\n","Train loss 23087 0.373609 Grad Norm 0.554501 0.09s/it\n","Train loss 23088 0.630018 Grad Norm 0.964747 0.13s/it\n","Train loss 23089 0.411077 Grad Norm 1.365299 0.16s/it\n","Train loss 23090 0.431108 Grad Norm 1.395108 0.12s/it\n","Train loss 23091 0.440400 Grad Norm 2.962148 0.12s/it\n","Train loss 23092 0.471966 Grad Norm 0.741019 0.13s/it\n","Train loss 23093 0.848887 Grad Norm 1.804680 0.13s/it\n","Train loss 23094 0.507001 Grad Norm 1.430759 0.14s/it\n","Train loss 23095 0.568766 Grad Norm 1.022113 0.13s/it\n","Train loss 23096 0.581712 Grad Norm 1.524683 0.12s/it\n","Train loss 23097 0.628928 Grad Norm 1.141397 0.14s/it\n","Train loss 23098 0.477349 Grad Norm 1.115672 0.13s/it\n","Train loss 23099 0.631505 Grad Norm 3.557166 0.14s/it\n","Train loss 23100 0.481182 Grad Norm 2.445125 0.13s/it\n","Train loss 23101 0.628615 Grad Norm 1.608386 0.13s/it\n","Train loss 23102 0.910612 Grad Norm 3.885070 0.11s/it\n","Train loss 23103 0.798456 Grad Norm 3.371795 0.10s/it\n","Train loss 23104 0.300513 Grad Norm 1.434118 0.12s/it\n","Train loss 23105 0.608671 Grad Norm 1.893884 0.13s/it\n","Train loss 23106 0.506770 Grad Norm 1.798903 0.11s/it\n","Train loss 23107 0.514226 Grad Norm 1.466052 0.15s/it\n","Train loss 23108 0.683499 Grad Norm 2.326438 0.12s/it\n","Train loss 23109 0.470475 Grad Norm 1.568554 0.12s/it\n","Train loss 23110 0.473982 Grad Norm 1.045561 0.14s/it\n","Train loss 23111 0.709586 Grad Norm 1.744739 0.13s/it\n","Train loss 23112 0.624529 Grad Norm 2.105063 0.11s/it\n","Train loss 23113 0.492127 Grad Norm 1.295787 0.14s/it\n","Train loss 23114 0.470010 Grad Norm 0.820035 0.11s/it\n","Train loss 23115 0.685845 Grad Norm 2.894734 0.12s/it\n","Train loss 23116 0.537044 Grad Norm 1.863775 0.11s/it\n","Train loss 23117 0.680772 Grad Norm 2.095779 0.11s/it\n","Train loss 23118 0.367834 Grad Norm 1.427523 0.14s/it\n","Train loss 23119 0.592695 Grad Norm 1.887137 0.15s/it\n","Train loss 23120 0.552528 Grad Norm 2.397722 0.14s/it\n","Train loss 23121 0.636547 Grad Norm 1.094443 0.14s/it\n","Train loss 23122 0.477674 Grad Norm 1.464499 0.16s/it\n","Train loss 23123 0.460305 Grad Norm 1.132698 0.14s/it\n","Train loss 23124 0.461503 Grad Norm 1.079525 0.12s/it\n","Train loss 23125 0.409938 Grad Norm 0.955567 0.13s/it\n","Train loss 23126 0.620098 Grad Norm 2.059669 0.13s/it\n","Train loss 23127 0.488430 Grad Norm 3.156530 0.13s/it\n","Train loss 23128 0.384741 Grad Norm 2.266445 0.11s/it\n","Train loss 23129 0.550580 Grad Norm 1.865369 0.11s/it\n","Train loss 23130 0.477870 Grad Norm 0.977445 0.13s/it\n","Train loss 23131 0.513185 Grad Norm 1.809509 0.12s/it\n","Train loss 23132 0.515505 Grad Norm 1.021533 0.17s/it\n","Train loss 23133 0.464546 Grad Norm 3.893983 0.12s/it\n","Train loss 23134 0.653770 Grad Norm 1.332974 0.12s/it\n","Train loss 23135 0.578874 Grad Norm 0.943997 0.13s/it\n","Train loss 23136 0.355944 Grad Norm 0.410336 0.16s/it\n","Train loss 23137 0.446426 Grad Norm 1.629225 0.15s/it\n","Train loss 23138 0.698715 Grad Norm 1.605142 0.12s/it\n","Train loss 23139 0.368831 Grad Norm 1.050698 0.13s/it\n","Train loss 23140 0.464132 Grad Norm 1.055705 0.10s/it\n","Train loss 23141 0.581996 Grad Norm 0.878638 0.12s/it\n","Train loss 23142 0.677472 Grad Norm 2.223030 0.12s/it\n","Train loss 23143 0.568012 Grad Norm 2.278995 0.15s/it\n","Train loss 23144 0.537365 Grad Norm 1.434876 0.14s/it\n","Train loss 23145 0.516573 Grad Norm 1.427370 0.15s/it\n","Train loss 23146 0.358863 Grad Norm 0.947575 0.12s/it\n","Train loss 23147 0.396878 Grad Norm 1.451199 0.14s/it\n","Train loss 23148 0.962381 Grad Norm 1.656945 0.12s/it\n","Train loss 23149 0.588835 Grad Norm 0.654073 0.16s/it\n","Train loss 23150 0.637032 Grad Norm 1.624205 0.09s/it\n","Train loss 23151 0.348934 Grad Norm 0.587761 0.15s/it\n","Train loss 23152 0.388816 Grad Norm 0.904854 0.15s/it\n","Train loss 23153 0.582783 Grad Norm 1.002047 0.12s/it\n","Train loss 23154 0.339012 Grad Norm 1.657724 0.13s/it\n","Train loss 23155 0.584537 Grad Norm 2.266409 0.13s/it\n","Train loss 23156 0.543704 Grad Norm 1.935484 0.10s/it\n","Train loss 23157 0.506267 Grad Norm 1.013407 0.11s/it\n","Train loss 23158 0.749574 Grad Norm 1.089783 0.12s/it\n","Train loss 23159 0.488125 Grad Norm 1.328484 0.15s/it\n","Train loss 23160 0.583298 Grad Norm 2.400739 0.13s/it\n","Train loss 23161 0.747751 Grad Norm 0.887898 0.13s/it\n","Train loss 23162 0.669462 Grad Norm 1.264257 0.13s/it\n","Train loss 23163 0.584062 Grad Norm 4.802759 0.10s/it\n","Train loss 23164 0.877443 Grad Norm 2.324435 0.11s/it\n","Train loss 23165 0.626707 Grad Norm 1.462624 0.14s/it\n","Train loss 23166 0.562766 Grad Norm 1.014379 0.11s/it\n","Train loss 23167 0.546410 Grad Norm 1.799365 0.12s/it\n","Train loss 23168 0.628583 Grad Norm 1.106051 0.12s/it\n","Train loss 23169 0.412342 Grad Norm 0.868833 0.14s/it\n","Train loss 23170 0.665883 Grad Norm 1.520114 0.13s/it\n","Train loss 23171 0.401641 Grad Norm 1.848458 0.12s/it\n","Train loss 23172 0.548045 Grad Norm 0.689290 0.13s/it\n","Train loss 23173 0.489453 Grad Norm 1.125475 0.13s/it\n","Train loss 23174 0.590260 Grad Norm 3.874758 0.12s/it\n","Epoch: 3\n","Train loss 23175 0.377807 Grad Norm 0.655154 0.12s/it\n","Train loss 23176 0.510669 Grad Norm 1.110280 0.13s/it\n","Train loss 23177 0.631604 Grad Norm 1.221513 0.15s/it\n","Train loss 23178 0.464186 Grad Norm 4.020377 0.11s/it\n","Train loss 23179 0.536688 Grad Norm 0.681702 0.12s/it\n","Train loss 23180 0.755804 Grad Norm 2.728430 0.11s/it\n","Train loss 23181 0.606873 Grad Norm 1.720602 0.14s/it\n","Train loss 23182 0.713270 Grad Norm 2.078266 0.11s/it\n","Train loss 23183 0.670649 Grad Norm 1.580082 0.13s/it\n","Train loss 23184 0.664325 Grad Norm 1.041952 0.11s/it\n","Train loss 23185 0.382502 Grad Norm 3.054921 0.11s/it\n","Train loss 23186 0.561359 Grad Norm 1.165743 0.14s/it\n","Train loss 23187 0.343939 Grad Norm 0.705845 0.13s/it\n","Train loss 23188 0.481213 Grad Norm 1.052237 0.14s/it\n","Train loss 23189 0.543300 Grad Norm 1.679478 0.13s/it\n","Train loss 23190 0.419429 Grad Norm 0.810692 0.13s/it\n","Train loss 23191 0.565349 Grad Norm 3.245853 0.14s/it\n","Train loss 23192 0.619176 Grad Norm 1.381029 0.15s/it\n","Train loss 23193 0.917763 Grad Norm 2.810432 0.09s/it\n","Train loss 23194 0.383083 Grad Norm 1.107754 0.13s/it\n","Train loss 23195 0.707642 Grad Norm 1.362996 0.11s/it\n","Train loss 23196 0.641958 Grad Norm 2.577868 0.13s/it\n","Train loss 23197 0.518955 Grad Norm 1.862690 0.13s/it\n","Train loss 23198 0.667766 Grad Norm 0.838539 0.12s/it\n","Train loss 23199 0.526275 Grad Norm 1.320621 0.10s/it\n","Train loss 23200 0.555113 Grad Norm 2.924167 0.13s/it\n","Train loss 23201 0.509671 Grad Norm 1.203352 0.12s/it\n","Train loss 23202 0.465154 Grad Norm 1.286940 0.11s/it\n","Train loss 23203 0.535532 Grad Norm 1.091960 0.13s/it\n","Train loss 23204 0.741355 Grad Norm 2.339536 0.14s/it\n","Train loss 23205 0.490484 Grad Norm 0.961216 0.12s/it\n","Train loss 23206 0.499637 Grad Norm 1.098430 0.13s/it\n","Train loss 23207 0.772455 Grad Norm 1.348429 0.13s/it\n","Train loss 23208 0.493102 Grad Norm 0.880190 0.12s/it\n","Train loss 23209 0.567109 Grad Norm 1.148465 0.12s/it\n","Train loss 23210 0.616004 Grad Norm 1.171171 0.13s/it\n","Train loss 23211 0.469902 Grad Norm 1.506088 0.15s/it\n","Train loss 23212 0.672698 Grad Norm 1.238516 0.12s/it\n","Train loss 23213 0.609589 Grad Norm 1.063681 0.14s/it\n","Train loss 23214 0.314668 Grad Norm 1.028943 0.11s/it\n","Train loss 23215 0.503185 Grad Norm 0.833037 0.12s/it\n","Train loss 23216 0.502033 Grad Norm 0.913952 0.15s/it\n","Train loss 23217 0.525383 Grad Norm 1.190521 0.13s/it\n","Train loss 23218 0.497216 Grad Norm 0.973161 0.13s/it\n","Train loss 23219 0.434417 Grad Norm 0.658221 0.11s/it\n","Train loss 23220 0.544928 Grad Norm 0.856125 0.11s/it\n","Train loss 23221 0.553293 Grad Norm 1.335786 0.12s/it\n","Train loss 23222 0.738619 Grad Norm 2.020560 0.12s/it\n","Train loss 23223 0.486648 Grad Norm 1.444848 0.12s/it\n","Train loss 23224 0.783689 Grad Norm 1.303227 0.12s/it\n","Train loss 23225 0.469572 Grad Norm 1.636712 0.17s/it\n","Train loss 23226 0.616912 Grad Norm 1.512260 0.13s/it\n","Train loss 23227 0.655657 Grad Norm 1.995973 0.12s/it\n","Train loss 23228 0.617251 Grad Norm 1.820905 0.14s/it\n","Train loss 23229 0.760764 Grad Norm 1.110906 0.12s/it\n","Train loss 23230 0.552232 Grad Norm 1.370192 0.13s/it\n","Train loss 23231 0.338595 Grad Norm 1.307944 0.12s/it\n","Train loss 23232 0.668060 Grad Norm 1.656409 0.11s/it\n","Train loss 23233 0.567615 Grad Norm 1.356413 0.15s/it\n","Train loss 23234 0.424996 Grad Norm 2.854164 0.11s/it\n","Train loss 23235 0.535792 Grad Norm 2.641617 0.12s/it\n","Train loss 23236 0.481092 Grad Norm 0.761856 0.11s/it\n","Train loss 23237 0.577376 Grad Norm 0.704414 0.14s/it\n","Train loss 23238 0.515515 Grad Norm 0.792228 0.13s/it\n","Train loss 23239 0.568241 Grad Norm 2.841404 0.11s/it\n","Train loss 23240 0.511440 Grad Norm 2.081344 0.10s/it\n","Train loss 23241 0.429341 Grad Norm 1.683210 0.14s/it\n","Train loss 23242 0.587910 Grad Norm 1.621611 0.14s/it\n","Train loss 23243 0.481675 Grad Norm 0.818022 0.15s/it\n","Train loss 23244 0.679434 Grad Norm 1.242665 0.14s/it\n","Train loss 23245 0.699106 Grad Norm 3.088786 0.14s/it\n","Train loss 23246 0.584511 Grad Norm 1.068753 0.16s/it\n","Train loss 23247 0.642744 Grad Norm 1.274005 0.13s/it\n","Train loss 23248 0.532216 Grad Norm 1.372935 0.11s/it\n","Train loss 23249 0.495824 Grad Norm 0.950995 0.13s/it\n","Train loss 23250 0.816853 Grad Norm 1.857492 0.11s/it\n","Train loss 23251 0.758393 Grad Norm 3.537946 0.10s/it\n","Train loss 23252 0.475098 Grad Norm 1.599760 0.13s/it\n","Train loss 23253 0.881960 Grad Norm 2.136239 0.11s/it\n","Train loss 23254 0.688695 Grad Norm 2.421500 0.11s/it\n","Train loss 23255 0.859776 Grad Norm 3.401057 0.10s/it\n","Train loss 23256 0.494088 Grad Norm 1.039777 0.14s/it\n","Train loss 23257 0.601789 Grad Norm 0.797693 0.13s/it\n","Train loss 23258 0.410772 Grad Norm 1.358591 0.16s/it\n","Train loss 23259 0.598053 Grad Norm 3.210760 0.09s/it\n","Train loss 23260 0.685927 Grad Norm 2.363480 0.12s/it\n","Train loss 23261 0.478740 Grad Norm 1.702538 0.12s/it\n","Train loss 23262 0.444747 Grad Norm 0.689897 0.15s/it\n","Train loss 23263 0.600441 Grad Norm 0.748059 0.10s/it\n","Train loss 23264 0.523861 Grad Norm 1.614818 0.11s/it\n","Train loss 23265 0.617846 Grad Norm 2.859595 0.11s/it\n","Train loss 23266 0.519484 Grad Norm 1.719229 0.13s/it\n","Train loss 23267 0.658795 Grad Norm 1.763518 0.13s/it\n","Train loss 23268 0.383831 Grad Norm 0.894883 0.12s/it\n","Train loss 23269 0.776579 Grad Norm 1.701395 0.14s/it\n","Train loss 23270 0.592212 Grad Norm 1.126096 0.12s/it\n","Train loss 23271 0.516383 Grad Norm 0.876542 0.14s/it\n","Train loss 23272 0.532247 Grad Norm 1.169602 0.13s/it\n","Train loss 23273 0.383233 Grad Norm 0.521467 0.11s/it\n","Train loss 23274 0.491679 Grad Norm 1.997861 0.13s/it\n","Train loss 23275 0.553181 Grad Norm 1.235700 0.13s/it\n","Train loss 23276 0.562200 Grad Norm 0.816643 0.13s/it\n","Train loss 23277 0.542950 Grad Norm 0.861257 0.13s/it\n","Train loss 23278 0.630953 Grad Norm 1.556605 0.11s/it\n","Train loss 23279 0.538630 Grad Norm 1.170493 0.11s/it\n","Train loss 23280 0.614301 Grad Norm 1.448140 0.13s/it\n","Train loss 23281 0.413019 Grad Norm 1.363092 0.11s/it\n","Train loss 23282 0.496755 Grad Norm 10.235274 0.14s/it\n","Train loss 23283 0.422415 Grad Norm 0.876090 0.12s/it\n","Train loss 23284 0.571244 Grad Norm 1.382457 0.11s/it\n","Train loss 23285 0.558420 Grad Norm 1.025064 0.15s/it\n","Train loss 23286 0.459686 Grad Norm 1.090912 0.11s/it\n","Train loss 23287 0.478311 Grad Norm 0.972120 0.13s/it\n","Train loss 23288 0.816042 Grad Norm 1.713253 0.13s/it\n","Train loss 23289 0.394000 Grad Norm 0.486638 0.12s/it\n","Train loss 23290 0.562026 Grad Norm 2.106550 0.10s/it\n","Train loss 23291 1.234219 Grad Norm 2.810120 0.13s/it\n","Train loss 23292 0.519005 Grad Norm 1.002829 0.15s/it\n","Train loss 23293 0.413429 Grad Norm 1.235628 0.15s/it\n","Train loss 23294 0.570837 Grad Norm 1.288586 0.12s/it\n","Train loss 23295 0.349764 Grad Norm 0.853861 0.12s/it\n","Train loss 23296 0.406911 Grad Norm 1.922135 0.14s/it\n","Train loss 23297 0.368776 Grad Norm 0.784743 0.14s/it\n","Train loss 23298 0.580077 Grad Norm 1.833545 0.11s/it\n","Train loss 23299 0.527431 Grad Norm 1.978562 0.13s/it\n","Train loss 23300 0.344317 Grad Norm 1.006929 0.10s/it\n","Train loss 23301 0.611882 Grad Norm 1.608006 0.12s/it\n","Train loss 23302 0.634134 Grad Norm 1.185188 0.13s/it\n","Train loss 23303 0.390386 Grad Norm 1.653744 0.10s/it\n","Train loss 23304 0.393752 Grad Norm 0.821880 0.14s/it\n","Train loss 23305 0.474926 Grad Norm 1.519565 0.12s/it\n","Train loss 23306 0.501145 Grad Norm 0.777438 0.11s/it\n","Train loss 23307 0.432823 Grad Norm 0.785402 0.11s/it\n","Train loss 23308 0.440532 Grad Norm 1.292905 0.12s/it\n","Train loss 23309 0.560993 Grad Norm 1.021356 0.13s/it\n","Train loss 23310 0.748182 Grad Norm 1.981238 0.12s/it\n","Train loss 23311 0.430323 Grad Norm 1.173669 0.12s/it\n","Train loss 23312 0.524435 Grad Norm 1.131765 0.15s/it\n","Train loss 23313 0.671661 Grad Norm 1.072395 0.11s/it\n","Train loss 23314 0.559830 Grad Norm 0.931760 0.14s/it\n","Train loss 23315 0.432292 Grad Norm 1.319824 0.09s/it\n","Train loss 23316 0.659758 Grad Norm 1.737499 0.12s/it\n","Train loss 23317 0.378066 Grad Norm 1.247895 0.11s/it\n","Train loss 23318 0.416511 Grad Norm 0.888559 0.12s/it\n","Train loss 23319 0.763327 Grad Norm 3.914340 0.12s/it\n","Train loss 23320 0.655113 Grad Norm 1.719923 0.12s/it\n","Train loss 23321 0.597281 Grad Norm 1.016861 0.11s/it\n","Train loss 23322 0.381672 Grad Norm 4.287019 0.12s/it\n","Train loss 23323 0.775335 Grad Norm 3.446190 0.10s/it\n","Train loss 23324 0.914078 Grad Norm 2.788494 0.11s/it\n","Train loss 23325 0.435250 Grad Norm 0.917432 0.12s/it\n","Train loss 23326 0.478874 Grad Norm 2.353174 0.12s/it\n","Train loss 23327 0.609025 Grad Norm 1.070931 0.12s/it\n","Train loss 23328 0.369178 Grad Norm 2.093187 0.10s/it\n","Train loss 23329 0.511151 Grad Norm 1.141011 0.13s/it\n","Train loss 23330 0.445765 Grad Norm 1.986013 0.12s/it\n","Train loss 23331 0.444181 Grad Norm 1.349618 0.13s/it\n","Train loss 23332 0.507085 Grad Norm 2.419755 0.13s/it\n","Train loss 23333 0.457347 Grad Norm 1.224533 0.12s/it\n","Train loss 23334 0.548380 Grad Norm 2.214786 0.14s/it\n","Train loss 23335 0.679906 Grad Norm 1.047997 0.12s/it\n","Train loss 23336 0.415582 Grad Norm 2.942833 0.12s/it\n","Train loss 23337 0.560574 Grad Norm 1.920680 0.10s/it\n","Train loss 23338 0.403453 Grad Norm 1.477681 0.14s/it\n","Train loss 23339 0.433154 Grad Norm 0.954621 0.16s/it\n","Train loss 23340 0.489500 Grad Norm 1.851712 0.13s/it\n","Train loss 23341 0.392846 Grad Norm 2.143009 0.12s/it\n","Train loss 23342 0.386852 Grad Norm 1.139031 0.15s/it\n","Train loss 23343 0.622410 Grad Norm 1.559098 0.14s/it\n","Train loss 23344 0.507217 Grad Norm 1.102818 0.11s/it\n","Train loss 23345 0.711147 Grad Norm 2.590286 0.14s/it\n","Train loss 23346 0.768369 Grad Norm 1.405301 0.13s/it\n","Train loss 23347 0.613248 Grad Norm 1.738049 0.12s/it\n","Train loss 23348 0.566543 Grad Norm 4.581629 0.10s/it\n","Train loss 23349 0.628877 Grad Norm 2.985705 0.11s/it\n","Train loss 23350 0.691196 Grad Norm 1.362982 0.14s/it\n","Train loss 23351 0.692808 Grad Norm 2.544858 0.14s/it\n","Train loss 23352 0.625619 Grad Norm 1.550100 0.15s/it\n","Train loss 23353 0.460189 Grad Norm 1.443601 0.15s/it\n","Train loss 23354 0.768753 Grad Norm 1.278297 0.11s/it\n","Train loss 23355 0.600121 Grad Norm 3.773333 0.13s/it\n","Train loss 23356 0.598304 Grad Norm 1.408025 0.11s/it\n","Train loss 23357 0.441362 Grad Norm 25.645826 0.14s/it\n","Train loss 23358 0.488864 Grad Norm 1.815195 0.12s/it\n","Train loss 23359 0.751343 Grad Norm 1.720822 0.12s/it\n","Train loss 23360 0.720874 Grad Norm 5.615333 0.13s/it\n","Train loss 23361 0.467755 Grad Norm 1.066935 0.14s/it\n","Train loss 23362 0.783198 Grad Norm 1.778325 0.15s/it\n","Train loss 23363 0.429721 Grad Norm 0.795367 0.11s/it\n","Train loss 23364 0.431294 Grad Norm 0.667870 0.11s/it\n","Train loss 23365 0.706659 Grad Norm 1.971790 0.11s/it\n","Train loss 23366 0.461419 Grad Norm 1.851351 0.09s/it\n","Train loss 23367 0.477222 Grad Norm 1.402544 0.13s/it\n","Train loss 23368 0.728834 Grad Norm 2.204870 0.12s/it\n","Train loss 23369 0.686556 Grad Norm 2.429017 0.13s/it\n","Train loss 23370 0.658534 Grad Norm 0.889733 0.12s/it\n","Train loss 23371 0.828502 Grad Norm 1.544152 0.15s/it\n","Train loss 23372 0.473205 Grad Norm 0.951107 0.16s/it\n","Train loss 23373 0.526382 Grad Norm 1.178183 0.14s/it\n","Train loss 23374 0.557906 Grad Norm 1.899530 0.12s/it\n","Train loss 23375 0.463546 Grad Norm 0.851154 0.10s/it\n","Train loss 23376 0.569062 Grad Norm 1.615760 0.12s/it\n","Train loss 23377 0.709149 Grad Norm 2.238117 0.11s/it\n","Train loss 23378 0.555348 Grad Norm 1.249939 0.10s/it\n","Train loss 23379 0.677905 Grad Norm 3.503663 0.11s/it\n","Train loss 23380 0.664067 Grad Norm 2.405828 0.13s/it\n","Train loss 23381 0.514651 Grad Norm 2.514413 0.10s/it\n","Train loss 23382 0.539829 Grad Norm 0.711865 0.12s/it\n","Train loss 23383 0.294745 Grad Norm 0.925703 0.10s/it\n","Train loss 23384 0.564646 Grad Norm 0.884246 0.12s/it\n","Train loss 23385 0.392950 Grad Norm 0.703526 0.13s/it\n","Train loss 23386 0.651601 Grad Norm 2.459338 0.14s/it\n","Train loss 23387 0.450416 Grad Norm 1.228572 0.12s/it\n","Train loss 23388 0.447531 Grad Norm 0.615938 0.11s/it\n","Train loss 23389 0.579371 Grad Norm 1.168471 0.12s/it\n","Train loss 23390 0.441206 Grad Norm 0.759742 0.11s/it\n","Train loss 23391 0.664491 Grad Norm 2.395995 0.10s/it\n","Train loss 23392 0.375954 Grad Norm 0.778767 0.13s/it\n","Train loss 23393 0.679326 Grad Norm 2.160537 0.10s/it\n","Train loss 23394 0.719720 Grad Norm 2.722081 0.10s/it\n","Train loss 23395 0.570073 Grad Norm 1.939963 0.12s/it\n","Train loss 23396 0.974622 Grad Norm 2.036159 0.11s/it\n","Train loss 23397 0.514141 Grad Norm 1.692729 0.13s/it\n","Train loss 23398 0.438262 Grad Norm 0.810568 0.14s/it\n","Train loss 23399 0.510659 Grad Norm 0.966818 0.16s/it\n","Train loss 23400 0.507480 Grad Norm 1.753276 0.11s/it\n","Train loss 23401 0.698034 Grad Norm 1.085629 0.13s/it\n","Train loss 23402 0.539639 Grad Norm 1.008295 0.11s/it\n","Train loss 23403 0.475277 Grad Norm 2.026251 0.12s/it\n","Train loss 23404 0.746241 Grad Norm 3.345935 0.11s/it\n","Train loss 23405 0.482160 Grad Norm 0.847263 0.14s/it\n","Train loss 23406 0.578218 Grad Norm 1.444448 0.11s/it\n","Train loss 23407 0.363292 Grad Norm 0.820146 0.11s/it\n","Train loss 23408 0.587494 Grad Norm 1.772948 0.12s/it\n","Train loss 23409 0.381503 Grad Norm 0.935360 0.15s/it\n","Train loss 23410 0.493304 Grad Norm 2.687124 0.11s/it\n","Train loss 23411 0.515667 Grad Norm 8.888200 0.13s/it\n","Train loss 23412 0.374621 Grad Norm 1.269246 0.13s/it\n","Train loss 23413 0.573436 Grad Norm 2.104465 0.13s/it\n","Train loss 23414 0.545339 Grad Norm 2.813653 0.12s/it\n","Train loss 23415 0.442189 Grad Norm 0.705499 0.12s/it\n","Train loss 23416 0.530189 Grad Norm 2.418705 0.14s/it\n","Train loss 23417 0.551219 Grad Norm 2.099908 0.11s/it\n","Train loss 23418 0.420893 Grad Norm 0.698936 0.10s/it\n","Train loss 23419 0.669757 Grad Norm 1.128528 0.09s/it\n","Train loss 23420 0.601106 Grad Norm 1.300486 0.11s/it\n","Train loss 23421 0.851410 Grad Norm 1.392437 0.10s/it\n","Train loss 23422 0.482143 Grad Norm 2.229479 0.16s/it\n","Train loss 23423 0.639539 Grad Norm 1.650159 0.13s/it\n","Train loss 23424 0.470714 Grad Norm 1.092616 0.11s/it\n","Train loss 23425 0.469484 Grad Norm 1.138453 0.11s/it\n","Train loss 23426 0.795023 Grad Norm 3.053884 0.11s/it\n","Train loss 23427 0.613381 Grad Norm 0.992680 0.14s/it\n","Train loss 23428 0.891315 Grad Norm 2.662758 0.10s/it\n","Train loss 23429 0.472115 Grad Norm 2.099126 0.14s/it\n","Train loss 23430 0.580119 Grad Norm 1.725460 0.12s/it\n","Train loss 23431 0.440784 Grad Norm 0.832161 0.13s/it\n","Train loss 23432 0.436787 Grad Norm 1.382570 0.12s/it\n","Train loss 23433 0.536422 Grad Norm 1.373191 0.12s/it\n","Train loss 23434 0.761778 Grad Norm 1.147928 0.12s/it\n","Train loss 23435 0.624139 Grad Norm 0.907696 0.14s/it\n","Train loss 23436 0.471110 Grad Norm 0.953052 0.12s/it\n","Train loss 23437 0.473198 Grad Norm 1.923583 0.12s/it\n","Train loss 23438 0.535097 Grad Norm 1.116493 0.13s/it\n","Train loss 23439 0.504927 Grad Norm 1.285969 0.14s/it\n","Train loss 23440 0.610732 Grad Norm 1.091143 0.12s/it\n","Train loss 23441 0.490721 Grad Norm 1.766691 0.12s/it\n","Train loss 23442 0.591172 Grad Norm 0.905717 0.14s/it\n","Train loss 23443 0.615714 Grad Norm 1.682914 0.15s/it\n","Train loss 23444 0.366638 Grad Norm 0.777513 0.12s/it\n","Train loss 23445 0.411905 Grad Norm 1.514047 0.13s/it\n","Train loss 23446 0.635431 Grad Norm 2.339738 0.10s/it\n","Train loss 23447 0.486626 Grad Norm 0.714012 0.12s/it\n","Train loss 23448 0.666921 Grad Norm 1.649627 0.11s/it\n","Train loss 23449 0.329318 Grad Norm 0.681430 0.15s/it\n","Train loss 23450 0.517598 Grad Norm 1.020957 0.13s/it\n","Train loss 23451 0.749489 Grad Norm 1.805243 0.13s/it\n","Train loss 23452 0.553691 Grad Norm 1.405606 0.11s/it\n","Train loss 23453 0.393851 Grad Norm 0.654943 0.11s/it\n","Train loss 23454 0.466671 Grad Norm 0.936759 0.11s/it\n","Train loss 23455 0.480633 Grad Norm 0.843985 0.13s/it\n","Train loss 23456 0.334682 Grad Norm 0.696550 0.12s/it\n","Train loss 23457 0.502517 Grad Norm 1.044904 0.11s/it\n","Train loss 23458 0.428914 Grad Norm 0.807609 0.13s/it\n","Train loss 23459 0.454554 Grad Norm 0.738320 0.12s/it\n","Train loss 23460 0.525597 Grad Norm 1.039587 0.13s/it\n","Train loss 23461 0.464450 Grad Norm 0.907664 0.13s/it\n","Train loss 23462 0.340273 Grad Norm 0.841465 0.14s/it\n","Train loss 23463 0.513262 Grad Norm 1.524903 0.11s/it\n","Train loss 23464 0.494428 Grad Norm 0.856224 0.12s/it\n","Train loss 23465 0.506473 Grad Norm 1.718449 0.11s/it\n","Train loss 23466 0.586797 Grad Norm 2.391898 0.14s/it\n","Train loss 23467 0.555063 Grad Norm 1.263599 0.15s/it\n","Train loss 23468 0.578214 Grad Norm 1.124827 0.12s/it\n","Train loss 23469 0.481479 Grad Norm 0.603707 0.12s/it\n","Train loss 23470 0.673084 Grad Norm 1.361256 0.13s/it\n","Train loss 23471 0.516865 Grad Norm 1.939746 0.10s/it\n","Train loss 23472 0.717335 Grad Norm 2.274581 0.11s/it\n","Train loss 23473 0.439386 Grad Norm 2.317755 0.14s/it\n","Train loss 23474 0.626894 Grad Norm 2.537285 0.11s/it\n","Train loss 23475 0.474365 Grad Norm 2.259696 0.14s/it\n","Train loss 23476 0.798209 Grad Norm 2.644536 0.11s/it\n","Train loss 23477 0.472563 Grad Norm 0.717921 0.12s/it\n","Train loss 23478 0.537261 Grad Norm 1.000387 0.14s/it\n","Train loss 23479 0.711213 Grad Norm 1.847888 0.11s/it\n","Train loss 23480 0.802528 Grad Norm 4.475946 0.11s/it\n","Train loss 23481 0.446549 Grad Norm 1.197173 0.12s/it\n","Train loss 23482 0.540712 Grad Norm 1.212822 0.13s/it\n","Train loss 23483 0.377568 Grad Norm 0.821799 0.14s/it\n","Train loss 23484 0.703245 Grad Norm 2.094326 0.10s/it\n","Train loss 23485 0.416796 Grad Norm 0.719317 0.12s/it\n","Train loss 23486 0.748431 Grad Norm 3.503035 0.12s/it\n","Train loss 23487 0.485285 Grad Norm 1.072688 0.12s/it\n","Train loss 23488 0.387919 Grad Norm 0.814847 0.12s/it\n","Train loss 23489 0.613477 Grad Norm 0.901589 0.11s/it\n","Train loss 23490 0.496332 Grad Norm 1.258339 0.14s/it\n","Train loss 23491 0.554266 Grad Norm 2.582602 0.10s/it\n","Train loss 23492 0.561771 Grad Norm 1.467434 0.13s/it\n","Train loss 23493 0.386785 Grad Norm 0.880289 0.12s/it\n","Train loss 23494 0.545758 Grad Norm 1.227796 0.14s/it\n","Train loss 23495 0.415696 Grad Norm 0.648243 0.10s/it\n","Train loss 23496 0.540140 Grad Norm 1.144540 0.16s/it\n","Train loss 23497 0.491288 Grad Norm 0.677936 0.13s/it\n","Train loss 23498 0.624888 Grad Norm 1.425599 0.11s/it\n","Train loss 23499 0.532923 Grad Norm 1.779128 0.14s/it\n","Train loss 23500 0.449733 Grad Norm 0.847348 0.11s/it\n","Train loss 23501 0.432687 Grad Norm 0.554235 0.13s/it\n","Train loss 23502 0.843902 Grad Norm 4.309696 0.13s/it\n","Train loss 23503 0.793602 Grad Norm 1.679772 0.11s/it\n","Train loss 23504 0.685573 Grad Norm 1.200210 0.14s/it\n","Train loss 23505 0.545455 Grad Norm 1.238809 0.13s/it\n","Train loss 23506 0.843745 Grad Norm 1.711581 0.11s/it\n","Train loss 23507 0.549062 Grad Norm 2.160928 0.12s/it\n","Train loss 23508 0.543478 Grad Norm 1.241995 0.14s/it\n","Train loss 23509 0.447795 Grad Norm 0.969590 0.13s/it\n","Train loss 23510 0.615138 Grad Norm 0.781578 0.13s/it\n","Train loss 23511 0.389836 Grad Norm 1.056838 0.10s/it\n","Train loss 23512 0.759265 Grad Norm 2.056250 0.14s/it\n","Train loss 23513 0.772926 Grad Norm 2.073020 0.12s/it\n","Train loss 23514 0.556194 Grad Norm 2.370944 0.12s/it\n","Train loss 23515 0.525447 Grad Norm 1.047494 0.11s/it\n","Train loss 23516 0.800737 Grad Norm 4.043587 0.10s/it\n","Train loss 23517 0.819666 Grad Norm 1.764289 0.12s/it\n","Train loss 23518 0.524468 Grad Norm 2.287493 0.12s/it\n","Train loss 23519 0.704655 Grad Norm 1.318631 0.14s/it\n","Train loss 23520 0.420342 Grad Norm 0.847631 0.15s/it\n","Train loss 23521 0.637306 Grad Norm 1.751833 0.12s/it\n","Train loss 23522 0.664903 Grad Norm 1.246029 0.12s/it\n","Train loss 23523 0.782813 Grad Norm 1.927438 0.10s/it\n","Train loss 23524 1.018369 Grad Norm 2.311452 0.11s/it\n","Train loss 23525 0.497595 Grad Norm 1.338483 0.14s/it\n","Train loss 23526 0.807481 Grad Norm 2.379208 0.12s/it\n","Train loss 23527 0.383448 Grad Norm 1.524285 0.13s/it\n","Train loss 23528 0.449165 Grad Norm 0.884993 0.10s/it\n","Train loss 23529 0.534184 Grad Norm 1.301448 0.12s/it\n","Train loss 23530 0.488680 Grad Norm 1.264203 0.12s/it\n","Train loss 23531 0.559165 Grad Norm 2.233794 0.11s/it\n","Train loss 23532 0.689253 Grad Norm 1.162399 0.12s/it\n","Train loss 23533 1.047680 Grad Norm 2.107685 0.11s/it\n","Train loss 23534 0.512579 Grad Norm 0.956317 0.13s/it\n","Train loss 23535 0.406973 Grad Norm 0.653512 0.10s/it\n","Train loss 23536 0.496861 Grad Norm 0.930874 0.13s/it\n","Train loss 23537 0.449743 Grad Norm 0.763279 0.12s/it\n","Train loss 23538 0.405522 Grad Norm 0.764991 0.13s/it\n","Train loss 23539 0.546581 Grad Norm 1.718833 0.12s/it\n","Train loss 23540 0.711639 Grad Norm 1.493502 0.13s/it\n","Train loss 23541 0.488141 Grad Norm 1.485320 0.12s/it\n","Train loss 23542 0.347137 Grad Norm 0.648516 0.10s/it\n","Train loss 23543 0.579398 Grad Norm 2.050187 0.13s/it\n","Train loss 23544 0.379853 Grad Norm 1.069312 0.14s/it\n","Train loss 23545 0.471162 Grad Norm 1.065752 0.13s/it\n","Train loss 23546 0.526976 Grad Norm 1.481468 0.15s/it\n","Train loss 23547 0.631038 Grad Norm 1.063680 0.14s/it\n","Train loss 23548 0.620529 Grad Norm 1.098152 0.13s/it\n","Train loss 23549 0.570037 Grad Norm 0.886122 0.13s/it\n","Train loss 23550 0.614324 Grad Norm 1.279365 0.14s/it\n","Train loss 23551 0.476456 Grad Norm 1.398446 0.09s/it\n","Train loss 23552 0.503632 Grad Norm 1.335255 0.15s/it\n","Train loss 23553 0.510328 Grad Norm 1.836783 0.10s/it\n","Train loss 23554 0.467227 Grad Norm 4.799861 0.12s/it\n","Train loss 23555 0.526906 Grad Norm 2.213554 0.12s/it\n","Train loss 23556 0.928172 Grad Norm 3.034792 0.11s/it\n","Train loss 23557 0.553923 Grad Norm 0.872772 0.12s/it\n","Train loss 23558 0.512954 Grad Norm 1.808831 0.12s/it\n","Train loss 23559 0.475194 Grad Norm 1.237857 0.14s/it\n","Train loss 23560 0.343529 Grad Norm 2.910287 0.09s/it\n","Train loss 23561 0.735946 Grad Norm 1.756466 0.11s/it\n","Train loss 23562 0.478440 Grad Norm 2.961808 0.13s/it\n","Train loss 23563 0.462521 Grad Norm 3.714592 0.10s/it\n","Train loss 23564 0.284148 Grad Norm 0.490168 0.11s/it\n","Train loss 23565 0.508209 Grad Norm 1.948138 0.14s/it\n","Train loss 23566 0.422539 Grad Norm 0.930772 0.12s/it\n","Train loss 23567 0.766727 Grad Norm 1.149276 0.12s/it\n","Train loss 23568 0.588139 Grad Norm 0.989958 0.14s/it\n","Train loss 23569 0.741375 Grad Norm 1.473348 0.12s/it\n","Train loss 23570 0.562309 Grad Norm 1.908895 0.11s/it\n","Train loss 23571 0.743832 Grad Norm 1.658396 0.16s/it\n","Train loss 23572 0.525041 Grad Norm 1.598144 0.16s/it\n","Train loss 23573 0.878427 Grad Norm 2.240315 0.12s/it\n","Train loss 23574 0.691137 Grad Norm 1.147436 0.13s/it\n","Train loss 23575 0.657365 Grad Norm 1.248666 0.11s/it\n","Train loss 23576 0.492192 Grad Norm 1.295138 0.12s/it\n","Train loss 23577 0.676331 Grad Norm 2.117224 0.14s/it\n","Train loss 23578 0.557381 Grad Norm 1.608945 0.13s/it\n","Train loss 23579 0.516395 Grad Norm 1.628801 0.12s/it\n","Train loss 23580 0.507732 Grad Norm 1.306202 0.12s/it\n","Train loss 23581 0.406811 Grad Norm 1.884706 0.10s/it\n","Train loss 23582 0.642392 Grad Norm 1.765007 0.14s/it\n","Train loss 23583 0.623664 Grad Norm 1.413873 0.13s/it\n","Train loss 23584 0.624828 Grad Norm 1.642352 0.13s/it\n","Train loss 23585 0.622232 Grad Norm 1.435280 0.12s/it\n","Train loss 23586 0.453242 Grad Norm 1.103485 0.13s/it\n","Train loss 23587 0.878139 Grad Norm 1.848463 0.09s/it\n","Train loss 23588 0.539125 Grad Norm 1.607052 0.13s/it\n","Train loss 23589 0.622075 Grad Norm 1.525047 0.13s/it\n","Train loss 23590 0.651327 Grad Norm 2.493514 0.12s/it\n","Train loss 23591 0.602340 Grad Norm 2.693070 0.13s/it\n","Train loss 23592 0.522635 Grad Norm 1.450475 0.11s/it\n","Train loss 23593 0.582137 Grad Norm 1.285609 0.13s/it\n","Train loss 23594 0.496856 Grad Norm 1.227006 0.15s/it\n","Train loss 23595 0.490991 Grad Norm 0.983593 0.12s/it\n","Train loss 23596 0.485087 Grad Norm 1.727894 0.12s/it\n","Train loss 23597 0.527987 Grad Norm 1.299786 0.12s/it\n","Train loss 23598 0.642460 Grad Norm 1.763936 0.12s/it\n","Train loss 23599 0.261661 Grad Norm 0.502027 0.13s/it\n","Train loss 23600 0.292995 Grad Norm 1.126912 0.13s/it\n","Train loss 23601 0.534218 Grad Norm 2.281750 0.12s/it\n","Train loss 23602 0.648035 Grad Norm 1.804396 0.14s/it\n","Train loss 23603 0.399969 Grad Norm 1.291898 0.10s/it\n","Train loss 23604 0.410114 Grad Norm 1.158970 0.12s/it\n","Train loss 23605 0.598629 Grad Norm 2.329583 0.13s/it\n","Train loss 23606 0.508060 Grad Norm 1.304252 0.13s/it\n","Train loss 23607 0.462485 Grad Norm 1.486746 0.13s/it\n","Train loss 23608 0.407766 Grad Norm 1.369733 0.12s/it\n","Train loss 23609 0.649800 Grad Norm 1.807828 0.12s/it\n","Train loss 23610 0.665744 Grad Norm 2.359979 0.16s/it\n","Train loss 23611 0.699989 Grad Norm 10.691198 0.10s/it\n","Train loss 23612 0.732742 Grad Norm 1.152724 0.13s/it\n","Train loss 23613 0.581782 Grad Norm 1.753052 0.12s/it\n","Train loss 23614 0.528364 Grad Norm 1.362974 0.13s/it\n","Train loss 23615 0.604638 Grad Norm 1.672554 0.12s/it\n","Train loss 23616 0.441975 Grad Norm 0.652628 0.12s/it\n","Train loss 23617 0.607875 Grad Norm 0.976794 0.15s/it\n","Train loss 23618 0.434445 Grad Norm 0.684003 0.15s/it\n","Train loss 23619 0.577010 Grad Norm 1.723991 0.13s/it\n","Train loss 23620 0.562842 Grad Norm 0.934527 0.12s/it\n","Train loss 23621 0.286341 Grad Norm 0.568658 0.13s/it\n","Train loss 23622 0.409199 Grad Norm 0.502573 0.11s/it\n","Train loss 23623 0.834285 Grad Norm 4.977818 0.10s/it\n","Train loss 23624 0.489753 Grad Norm 1.687247 0.13s/it\n","Train loss 23625 0.687204 Grad Norm 1.071435 0.12s/it\n","Train loss 23626 0.613866 Grad Norm 1.095068 0.14s/it\n","Train loss 23627 0.573574 Grad Norm 1.183062 0.11s/it\n","Train loss 23628 0.563061 Grad Norm 1.535782 0.10s/it\n","Train loss 23629 0.506535 Grad Norm 1.479254 0.13s/it\n","Train loss 23630 0.537457 Grad Norm 1.086809 0.13s/it\n","Train loss 23631 0.714365 Grad Norm 2.390232 0.11s/it\n","Train loss 23632 0.540253 Grad Norm 1.385397 0.11s/it\n","Train loss 23633 0.467665 Grad Norm 0.713065 0.14s/it\n","Train loss 23634 0.673611 Grad Norm 1.730599 0.14s/it\n","Train loss 23635 0.828608 Grad Norm 4.167255 0.12s/it\n","Train loss 23636 0.605844 Grad Norm 1.597355 0.14s/it\n","Train loss 23637 0.392284 Grad Norm 1.012545 0.10s/it\n","Train loss 23638 0.867528 Grad Norm 2.553493 0.10s/it\n","Train loss 23639 0.611712 Grad Norm 1.919671 0.10s/it\n","Train loss 23640 0.619816 Grad Norm 1.075170 0.12s/it\n","Train loss 23641 0.524383 Grad Norm 2.056153 0.14s/it\n","Train loss 23642 0.647849 Grad Norm 0.990846 0.13s/it\n","Train loss 23643 0.603812 Grad Norm 0.981932 0.13s/it\n","Train loss 23644 0.515542 Grad Norm 1.378849 0.13s/it\n","Train loss 23645 0.517613 Grad Norm 1.361652 0.11s/it\n","Train loss 23646 0.475900 Grad Norm 1.423583 0.11s/it\n","Train loss 23647 0.421531 Grad Norm 0.785065 0.13s/it\n","Train loss 23648 0.511347 Grad Norm 1.859698 0.15s/it\n","Train loss 23649 0.392886 Grad Norm 0.661010 0.12s/it\n","Train loss 23650 0.566686 Grad Norm 1.342924 0.13s/it\n","Train loss 23651 0.580484 Grad Norm 1.212134 0.11s/it\n","Train loss 23652 0.579051 Grad Norm 1.596226 0.13s/it\n","Train loss 23653 0.513812 Grad Norm 1.086640 0.11s/it\n","Train loss 23654 0.704749 Grad Norm 2.912669 0.12s/it\n","Train loss 23655 0.714591 Grad Norm 2.052387 0.12s/it\n","Train loss 23656 0.667974 Grad Norm 0.689799 0.13s/it\n","Train loss 23657 0.632778 Grad Norm 1.080416 0.11s/it\n","Train loss 23658 0.629026 Grad Norm 1.609459 0.13s/it\n","Train loss 23659 0.494068 Grad Norm 0.863192 0.10s/it\n","Train loss 23660 0.477467 Grad Norm 0.863762 0.11s/it\n","Train loss 23661 0.799083 Grad Norm 1.325664 0.13s/it\n","Train loss 23662 0.431188 Grad Norm 1.360786 0.13s/it\n","Train loss 23663 0.648089 Grad Norm 1.798717 0.13s/it\n","Train loss 23664 0.486406 Grad Norm 1.732857 0.14s/it\n","Train loss 23665 0.604612 Grad Norm 3.899191 0.11s/it\n","Train loss 23666 0.749031 Grad Norm 1.893221 0.11s/it\n","Train loss 23667 0.656500 Grad Norm 0.919671 0.15s/it\n","Train loss 23668 0.646251 Grad Norm 1.133090 0.13s/it\n","Train loss 23669 0.466834 Grad Norm 1.209773 0.10s/it\n","Train loss 23670 0.445589 Grad Norm 1.425438 0.13s/it\n","Train loss 23671 0.385279 Grad Norm 0.969637 0.12s/it\n","Train loss 23672 0.590251 Grad Norm 1.382820 0.12s/it\n","Train loss 23673 0.400313 Grad Norm 1.484160 0.13s/it\n","Train loss 23674 0.499701 Grad Norm 1.191106 0.12s/it\n","Train loss 23675 0.482387 Grad Norm 1.037277 0.16s/it\n","Train loss 23676 0.600044 Grad Norm 1.255595 0.12s/it\n","Train loss 23677 0.490235 Grad Norm 1.074209 0.12s/it\n","Train loss 23678 0.471973 Grad Norm 1.039915 0.14s/it\n","Train loss 23679 0.636144 Grad Norm 1.240829 0.12s/it\n","Train loss 23680 0.537046 Grad Norm 1.264200 0.12s/it\n","Train loss 23681 0.392353 Grad Norm 1.721791 0.10s/it\n","Train loss 23682 0.377229 Grad Norm 1.441860 0.14s/it\n","Train loss 23683 0.449189 Grad Norm 0.486457 0.12s/it\n","Train loss 23684 0.698568 Grad Norm 1.771737 0.12s/it\n","Train loss 23685 0.509422 Grad Norm 1.265129 0.13s/it\n","Train loss 23686 0.353619 Grad Norm 0.838259 0.11s/it\n","Train loss 23687 0.599853 Grad Norm 1.597999 0.11s/it\n","Train loss 23688 0.494313 Grad Norm 1.083981 0.13s/it\n","Train loss 23689 0.410668 Grad Norm 1.176715 0.12s/it\n","Train loss 23690 0.533484 Grad Norm 1.540031 0.11s/it\n","Train loss 23691 0.519551 Grad Norm 1.389204 0.12s/it\n","Train loss 23692 0.584009 Grad Norm 2.078255 0.13s/it\n","Train loss 23693 0.541911 Grad Norm 2.865234 0.13s/it\n","Train loss 23694 0.810635 Grad Norm 1.582528 0.12s/it\n","Train loss 23695 0.541120 Grad Norm 0.737055 0.12s/it\n","Train loss 23696 0.579435 Grad Norm 0.726859 0.13s/it\n","Train loss 23697 0.506417 Grad Norm 1.023739 0.15s/it\n","Train loss 23698 0.592219 Grad Norm 1.103366 0.12s/it\n","Train loss 23699 0.623892 Grad Norm 0.789115 0.11s/it\n","Train loss 23700 0.572133 Grad Norm 4.308153 0.11s/it\n","Train loss 23701 0.645533 Grad Norm 0.975136 0.12s/it\n","Train loss 23702 0.452370 Grad Norm 1.069167 0.16s/it\n","Train loss 23703 0.467389 Grad Norm 0.666851 0.15s/it\n","Train loss 23704 0.523692 Grad Norm 1.257524 0.11s/it\n","Train loss 23705 0.612641 Grad Norm 3.072219 0.13s/it\n","Train loss 23706 0.744208 Grad Norm 3.774335 0.11s/it\n","Train loss 23707 0.541651 Grad Norm 1.587771 0.15s/it\n","Train loss 23708 0.443131 Grad Norm 1.845994 0.11s/it\n","Train loss 23709 0.380337 Grad Norm 0.710289 0.14s/it\n","Train loss 23710 0.649826 Grad Norm 2.683281 0.11s/it\n","Train loss 23711 0.453976 Grad Norm 1.500186 0.12s/it\n","Train loss 23712 0.437923 Grad Norm 0.786642 0.10s/it\n","Train loss 23713 0.365156 Grad Norm 0.590255 0.11s/it\n","Train loss 23714 0.591311 Grad Norm 1.283439 0.12s/it\n","Train loss 23715 0.409939 Grad Norm 0.871648 0.13s/it\n","Train loss 23716 0.563877 Grad Norm 1.468900 0.13s/it\n","Train loss 23717 0.553771 Grad Norm 2.175915 0.12s/it\n","Train loss 23718 0.644691 Grad Norm 1.748696 0.12s/it\n","Train loss 23719 0.703144 Grad Norm 2.150308 0.11s/it\n","Train loss 23720 0.408042 Grad Norm 1.615394 0.11s/it\n","Train loss 23721 0.480886 Grad Norm 0.994882 0.11s/it\n","Train loss 23722 0.456465 Grad Norm 0.564565 0.14s/it\n","Train loss 23723 0.689113 Grad Norm 1.949290 0.11s/it\n","Train loss 23724 0.568832 Grad Norm 2.857458 0.10s/it\n","Train loss 23725 0.679294 Grad Norm 1.230331 0.09s/it\n","Train loss 23726 0.606178 Grad Norm 2.693681 0.10s/it\n","Train loss 23727 0.650351 Grad Norm 1.508301 0.11s/it\n","Train loss 23728 0.581554 Grad Norm 0.763413 0.15s/it\n","Train loss 23729 0.586600 Grad Norm 1.663609 0.11s/it\n","Train loss 23730 0.432737 Grad Norm 0.907814 0.14s/it\n","Train loss 23731 0.423204 Grad Norm 2.141404 0.12s/it\n","Train loss 23732 0.328493 Grad Norm 0.945643 0.15s/it\n","Train loss 23733 0.422884 Grad Norm 1.005500 0.12s/it\n","Train loss 23734 0.398868 Grad Norm 0.679888 0.17s/it\n","Train loss 23735 0.569087 Grad Norm 4.517813 0.11s/it\n","Train loss 23736 0.528370 Grad Norm 0.850576 0.11s/it\n","Train loss 23737 0.250545 Grad Norm 0.454589 0.14s/it\n","Train loss 23738 0.891649 Grad Norm 1.673867 0.12s/it\n","Train loss 23739 0.663797 Grad Norm 3.006656 0.11s/it\n","Train loss 23740 0.537171 Grad Norm 2.034274 0.11s/it\n","Train loss 23741 0.690886 Grad Norm 1.603627 0.13s/it\n","Train loss 23742 0.764157 Grad Norm 4.230978 0.11s/it\n","Train loss 23743 0.601882 Grad Norm 2.275128 0.10s/it\n","Train loss 23744 0.534959 Grad Norm 1.746168 0.10s/it\n","Train loss 23745 0.737039 Grad Norm 2.291632 0.11s/it\n","Train loss 23746 0.555976 Grad Norm 1.907772 0.14s/it\n","Train loss 23747 0.542170 Grad Norm 3.117453 0.09s/it\n","Train loss 23748 0.569232 Grad Norm 1.566991 0.12s/it\n","Train loss 23749 0.389681 Grad Norm 0.696572 0.15s/it\n","Train loss 23750 0.538213 Grad Norm 1.325613 0.11s/it\n","Train loss 23751 0.472110 Grad Norm 2.025098 0.14s/it\n","Train loss 23752 0.526068 Grad Norm 0.950346 0.13s/it\n","Train loss 23753 0.472736 Grad Norm 1.978771 0.13s/it\n","Train loss 23754 0.597382 Grad Norm 3.655281 0.11s/it\n","Train loss 23755 0.413821 Grad Norm 1.713533 0.10s/it\n","Train loss 23756 0.787519 Grad Norm 1.520899 0.17s/it\n","Train loss 23757 0.404839 Grad Norm 1.168352 0.12s/it\n","Train loss 23758 0.767396 Grad Norm 3.115967 0.11s/it\n","Train loss 23759 0.583491 Grad Norm 1.434559 0.13s/it\n","Train loss 23760 0.575014 Grad Norm 1.925916 0.10s/it\n","Train loss 23761 0.942210 Grad Norm 1.872391 0.11s/it\n","Train loss 23762 0.555132 Grad Norm 1.451072 0.10s/it\n","Train loss 23763 0.885243 Grad Norm 1.359464 0.12s/it\n","Train loss 23764 0.607441 Grad Norm 2.294335 0.12s/it\n","Train loss 23765 0.685286 Grad Norm 2.655077 0.12s/it\n","Train loss 23766 0.430164 Grad Norm 1.232267 0.14s/it\n","Train loss 23767 0.448764 Grad Norm 1.177705 0.12s/it\n","Train loss 23768 0.586377 Grad Norm 2.286975 0.11s/it\n","Train loss 23769 0.509910 Grad Norm 1.258542 0.10s/it\n","Train loss 23770 0.792098 Grad Norm 1.673038 0.13s/it\n","Train loss 23771 0.669848 Grad Norm 2.670228 0.13s/it\n","Train loss 23772 0.488360 Grad Norm 1.324061 0.11s/it\n","Train loss 23773 0.615920 Grad Norm 1.993259 0.13s/it\n","Train loss 23774 0.408882 Grad Norm 0.934807 0.10s/it\n","Train loss 23775 0.469835 Grad Norm 1.140024 0.11s/it\n","Train loss 23776 0.511182 Grad Norm 1.150776 0.13s/it\n","Train loss 23777 0.412456 Grad Norm 1.047133 0.15s/it\n","Train loss 23778 0.480091 Grad Norm 1.124192 0.13s/it\n","Train loss 23779 0.501348 Grad Norm 0.861277 0.13s/it\n","Train loss 23780 0.685892 Grad Norm 1.226538 0.12s/it\n","Train loss 23781 0.426491 Grad Norm 0.789887 0.13s/it\n","Train loss 23782 0.458861 Grad Norm 2.080941 0.09s/it\n","Train loss 23783 0.702902 Grad Norm 0.918281 0.14s/it\n","Train loss 23784 0.506659 Grad Norm 1.635283 0.12s/it\n","Train loss 23785 0.633312 Grad Norm 2.351591 0.11s/it\n","Train loss 23786 0.313858 Grad Norm 0.874373 0.14s/it\n","Train loss 23787 0.377271 Grad Norm 1.043762 0.12s/it\n","Train loss 23788 0.511871 Grad Norm 2.043211 0.13s/it\n","Train loss 23789 0.553546 Grad Norm 0.818717 0.12s/it\n","Train loss 23790 0.650123 Grad Norm 1.217970 0.13s/it\n","Train loss 23791 0.713854 Grad Norm 1.989380 0.10s/it\n","Train loss 23792 0.672346 Grad Norm 1.635537 0.13s/it\n","Train loss 23793 0.636740 Grad Norm 1.165193 0.13s/it\n","Train loss 23794 0.462795 Grad Norm 1.603178 0.17s/it\n","Train loss 23795 0.390735 Grad Norm 0.532039 0.14s/it\n","Train loss 23796 0.394893 Grad Norm 0.754108 0.11s/it\n","Train loss 23797 0.634600 Grad Norm 3.391795 0.15s/it\n","Train loss 23798 0.499383 Grad Norm 0.755645 0.16s/it\n","Train loss 23799 0.712031 Grad Norm 1.649479 0.11s/it\n","Train loss 23800 0.746788 Grad Norm 3.254776 0.11s/it\n","Train loss 23801 0.405242 Grad Norm 1.119732 0.14s/it\n","Train loss 23802 0.495428 Grad Norm 0.750159 0.10s/it\n","Train loss 23803 0.370921 Grad Norm 0.682259 0.13s/it\n","Train loss 23804 0.662528 Grad Norm 0.990804 0.11s/it\n","Train loss 23805 0.755055 Grad Norm 4.067627 0.13s/it\n","Train loss 23806 0.331407 Grad Norm 0.764349 0.14s/it\n","Train loss 23807 0.574689 Grad Norm 1.138668 0.13s/it\n","Train loss 23808 0.994188 Grad Norm 4.247381 0.10s/it\n","Train loss 23809 0.458891 Grad Norm 1.413867 0.10s/it\n","Train loss 23810 0.600228 Grad Norm 1.685051 0.12s/it\n","Train loss 23811 0.513663 Grad Norm 1.093827 0.11s/it\n","Train loss 23812 0.543843 Grad Norm 0.925221 0.13s/it\n","Train loss 23813 0.572253 Grad Norm 1.441347 0.11s/it\n","Train loss 23814 0.517179 Grad Norm 1.943929 0.12s/it\n","Train loss 23815 0.523337 Grad Norm 3.999813 0.12s/it\n","Train loss 23816 0.587950 Grad Norm 1.142330 0.11s/it\n","Train loss 23817 0.545515 Grad Norm 1.994615 0.12s/it\n","Train loss 23818 0.443132 Grad Norm 1.171021 0.13s/it\n","Train loss 23819 1.088099 Grad Norm 3.189182 0.11s/it\n","Train loss 23820 0.340805 Grad Norm 0.768197 0.15s/it\n","Train loss 23821 0.354740 Grad Norm 1.082331 0.12s/it\n","Train loss 23822 0.523789 Grad Norm 1.487705 0.12s/it\n","Train loss 23823 0.586319 Grad Norm 1.970408 0.11s/it\n","Train loss 23824 0.574380 Grad Norm 0.749546 0.12s/it\n","Train loss 23825 0.448066 Grad Norm 1.748328 0.12s/it\n","Train loss 23826 0.590081 Grad Norm 2.165359 0.12s/it\n","Train loss 23827 0.589806 Grad Norm 1.596461 0.15s/it\n","Train loss 23828 0.475082 Grad Norm 1.495518 0.11s/it\n","Train loss 23829 0.611654 Grad Norm 0.808493 0.13s/it\n","Train loss 23830 0.746971 Grad Norm 1.387489 0.13s/it\n","Train loss 23831 0.596154 Grad Norm 0.831319 0.12s/it\n","Train loss 23832 0.285792 Grad Norm 1.804591 0.13s/it\n","Train loss 23833 0.629781 Grad Norm 1.336572 0.10s/it\n","Train loss 23834 0.842418 Grad Norm 2.509374 0.11s/it\n","Train loss 23835 0.504259 Grad Norm 0.952001 0.10s/it\n","Train loss 23836 0.666797 Grad Norm 2.563638 0.12s/it\n","Train loss 23837 0.385961 Grad Norm 1.245417 0.12s/it\n","Train loss 23838 0.689999 Grad Norm 1.499778 0.12s/it\n","Train loss 23839 0.641897 Grad Norm 2.562798 0.12s/it\n","Train loss 23840 0.755012 Grad Norm 3.404591 0.12s/it\n","Train loss 23841 0.578941 Grad Norm 2.456561 0.14s/it\n","Train loss 23842 0.511120 Grad Norm 0.835606 0.14s/it\n","Train loss 23843 0.442160 Grad Norm 1.391007 0.12s/it\n","Train loss 23844 0.943611 Grad Norm 1.678333 0.11s/it\n","Train loss 23845 0.584222 Grad Norm 0.986931 0.15s/it\n","Train loss 23846 0.677411 Grad Norm 1.512330 0.14s/it\n","Train loss 23847 0.832487 Grad Norm 1.982992 0.12s/it\n","Train loss 23848 0.421061 Grad Norm 1.957225 0.14s/it\n","Train loss 23849 0.403780 Grad Norm 0.901455 0.12s/it\n","Train loss 23850 0.643906 Grad Norm 0.964125 0.11s/it\n","Train loss 23851 0.453573 Grad Norm 0.697635 0.11s/it\n","Train loss 23852 0.398533 Grad Norm 0.719818 0.12s/it\n","Train loss 23853 0.726341 Grad Norm 1.225519 0.13s/it\n","Train loss 23854 0.476968 Grad Norm 1.025360 0.10s/it\n","Train loss 23855 0.373739 Grad Norm 1.443220 0.15s/it\n","Train loss 23856 0.622065 Grad Norm 0.906131 0.11s/it\n","Train loss 23857 0.423896 Grad Norm 0.839048 0.15s/it\n","Train loss 23858 0.656671 Grad Norm 1.874784 0.13s/it\n","Train loss 23859 0.583518 Grad Norm 0.940253 0.12s/it\n","Train loss 23860 0.852952 Grad Norm 1.691559 0.11s/it\n","Train loss 23861 0.988624 Grad Norm 3.062093 0.13s/it\n","Train loss 23862 0.350509 Grad Norm 1.894328 0.16s/it\n","Train loss 23863 0.401513 Grad Norm 0.577858 0.15s/it\n","Train loss 23864 0.743159 Grad Norm 2.344110 0.13s/it\n","Train loss 23865 0.488101 Grad Norm 1.277097 0.11s/it\n","Train loss 23866 0.534392 Grad Norm 1.343489 0.11s/it\n","Train loss 23867 0.393562 Grad Norm 0.826421 0.13s/it\n","Train loss 23868 0.532410 Grad Norm 1.315333 0.13s/it\n","Train loss 23869 0.576179 Grad Norm 1.053320 0.12s/it\n","Train loss 23870 0.339391 Grad Norm 0.588572 0.13s/it\n","Train loss 23871 0.407560 Grad Norm 2.521521 0.11s/it\n","Train loss 23872 0.591890 Grad Norm 1.037653 0.14s/it\n","Train loss 23873 0.831003 Grad Norm 3.526445 0.12s/it\n","Train loss 23874 0.599502 Grad Norm 1.892048 0.12s/it\n","Train loss 23875 0.469666 Grad Norm 1.116550 0.12s/it\n","Train loss 23876 0.530458 Grad Norm 0.947883 0.11s/it\n","Train loss 23877 0.602338 Grad Norm 1.678169 0.12s/it\n","Train loss 23878 0.658912 Grad Norm 1.849535 0.11s/it\n","Train loss 23879 0.454875 Grad Norm 1.622186 0.12s/it\n","Train loss 23880 0.460612 Grad Norm 0.857166 0.11s/it\n","Train loss 23881 0.489409 Grad Norm 2.907456 0.12s/it\n","Train loss 23882 0.792913 Grad Norm 1.938097 0.13s/it\n","Train loss 23883 0.335354 Grad Norm 0.953065 0.14s/it\n","Train loss 23884 0.631312 Grad Norm 0.995278 0.13s/it\n","Train loss 23885 0.810216 Grad Norm 1.511990 0.11s/it\n","Train loss 23886 0.483086 Grad Norm 1.347101 0.13s/it\n","Train loss 23887 0.405975 Grad Norm 0.852095 0.16s/it\n","Train loss 23888 0.547175 Grad Norm 1.964229 0.13s/it\n","Train loss 23889 0.808075 Grad Norm 2.737519 0.11s/it\n","Train loss 23890 0.423415 Grad Norm 0.760973 0.14s/it\n","Train loss 23891 0.732911 Grad Norm 2.230932 0.14s/it\n","Train loss 23892 0.426965 Grad Norm 1.779620 0.14s/it\n","Train loss 23893 0.646515 Grad Norm 1.488823 0.13s/it\n","Train loss 23894 0.448002 Grad Norm 1.761467 0.12s/it\n","Train loss 23895 0.762457 Grad Norm 0.905601 0.13s/it\n","Train loss 23896 0.275341 Grad Norm 0.380316 0.12s/it\n","Train loss 23897 0.566647 Grad Norm 0.798411 0.15s/it\n","Train loss 23898 0.409152 Grad Norm 1.867055 0.13s/it\n","Train loss 23899 0.401541 Grad Norm 0.532823 0.14s/it\n","Train loss 23900 0.640775 Grad Norm 1.314076 0.10s/it\n","Train loss 23901 0.780481 Grad Norm 3.177763 0.12s/it\n","Train loss 23902 0.442176 Grad Norm 1.033449 0.16s/it\n","Train loss 23903 0.645186 Grad Norm 4.651979 0.14s/it\n","Train loss 23904 0.783141 Grad Norm 1.806327 0.11s/it\n","Train loss 23905 0.457448 Grad Norm 1.138667 0.12s/it\n","Train loss 23906 0.969297 Grad Norm 3.070683 0.10s/it\n","Train loss 23907 0.566884 Grad Norm 0.886797 0.13s/it\n","Train loss 23908 0.369872 Grad Norm 1.026694 0.12s/it\n","Train loss 23909 0.534902 Grad Norm 1.200486 0.15s/it\n","Train loss 23910 0.436488 Grad Norm 0.586318 0.13s/it\n","Train loss 23911 0.569107 Grad Norm 1.781870 0.12s/it\n","Train loss 23912 0.605815 Grad Norm 0.744855 0.15s/it\n","Train loss 23913 0.497764 Grad Norm 2.020992 0.13s/it\n","Train loss 23914 0.509879 Grad Norm 1.337881 0.11s/it\n","Train loss 23915 0.650982 Grad Norm 2.859951 0.11s/it\n","Train loss 23916 0.439929 Grad Norm 1.097518 0.13s/it\n","Train loss 23917 0.776048 Grad Norm 1.408436 0.15s/it\n","Train loss 23918 0.358863 Grad Norm 1.257186 0.10s/it\n","Train loss 23919 0.554086 Grad Norm 2.367841 0.10s/it\n","Train loss 23920 0.462009 Grad Norm 0.865910 0.13s/it\n","Train loss 23921 0.403375 Grad Norm 0.862323 0.11s/it\n","Train loss 23922 0.625517 Grad Norm 1.201645 0.11s/it\n","Train loss 23923 0.827394 Grad Norm 1.996993 0.12s/it\n","Train loss 23924 0.533179 Grad Norm 1.305584 0.12s/it\n","Train loss 23925 0.360511 Grad Norm 0.665521 0.13s/it\n","Train loss 23926 0.379425 Grad Norm 0.571311 0.11s/it\n","Train loss 23927 0.525308 Grad Norm 1.608645 0.12s/it\n","Train loss 23928 0.748986 Grad Norm 1.853641 0.13s/it\n","Train loss 23929 0.775323 Grad Norm 2.132241 0.11s/it\n","Train loss 23930 0.696340 Grad Norm 1.166787 0.12s/it\n","Train loss 23931 0.322143 Grad Norm 0.458408 0.14s/it\n","Train loss 23932 0.500035 Grad Norm 1.025977 0.12s/it\n","Train loss 23933 0.656289 Grad Norm 1.233303 0.12s/it\n","Train loss 23934 0.786253 Grad Norm 2.057136 0.12s/it\n","Train loss 23935 0.413730 Grad Norm 0.931854 0.14s/it\n","Train loss 23936 0.494197 Grad Norm 0.982129 0.17s/it\n","Train loss 23937 0.790276 Grad Norm 1.145341 0.11s/it\n","Train loss 23938 0.830224 Grad Norm 1.746536 0.13s/it\n","Train loss 23939 0.372673 Grad Norm 0.824110 0.15s/it\n","Train loss 23940 0.807006 Grad Norm 1.455205 0.11s/it\n","Train loss 23941 0.396222 Grad Norm 1.327549 0.13s/it\n","Train loss 23942 0.479370 Grad Norm 0.927815 0.14s/it\n","Train loss 23943 0.427667 Grad Norm 0.937053 0.12s/it\n","Train loss 23944 0.417953 Grad Norm 0.744396 0.10s/it\n","Train loss 23945 0.557066 Grad Norm 1.709511 0.10s/it\n","Train loss 23946 0.459780 Grad Norm 0.856640 0.12s/it\n","Train loss 23947 0.626265 Grad Norm 1.421249 0.13s/it\n","Train loss 23948 0.819984 Grad Norm 1.879770 0.12s/it\n","Train loss 23949 0.328081 Grad Norm 0.845700 0.15s/it\n","Train loss 23950 0.480949 Grad Norm 1.095909 0.14s/it\n","Train loss 23951 0.572934 Grad Norm 1.366053 0.13s/it\n","Train loss 23952 0.766487 Grad Norm 2.127645 0.10s/it\n","Train loss 23953 0.553198 Grad Norm 1.678351 0.13s/it\n","Train loss 23954 0.473686 Grad Norm 1.035676 0.15s/it\n","Train loss 23955 0.552353 Grad Norm 1.245087 0.11s/it\n","Train loss 23956 0.503709 Grad Norm 2.141886 0.13s/it\n","Train loss 23957 0.681256 Grad Norm 1.057895 0.14s/it\n","Train loss 23958 0.576139 Grad Norm 1.036570 0.13s/it\n","Train loss 23959 0.522807 Grad Norm 0.701063 0.15s/it\n","Train loss 23960 0.348229 Grad Norm 2.084717 0.14s/it\n","Train loss 23961 0.475787 Grad Norm 1.884625 0.08s/it\n","Train loss 23962 0.621173 Grad Norm 1.427659 0.13s/it\n","Train loss 23963 0.527230 Grad Norm 1.480633 0.12s/it\n","Train loss 23964 0.693974 Grad Norm 2.678797 0.12s/it\n","Train loss 23965 0.443521 Grad Norm 2.425298 0.12s/it\n","Train loss 23966 0.328476 Grad Norm 0.473229 0.12s/it\n","Train loss 23967 0.644639 Grad Norm 2.062747 0.13s/it\n","Train loss 23968 0.509554 Grad Norm 0.912326 0.13s/it\n","Train loss 23969 0.519654 Grad Norm 1.621449 0.11s/it\n","Train loss 23970 0.556937 Grad Norm 1.169591 0.12s/it\n","Train loss 23971 0.408326 Grad Norm 0.562308 0.16s/it\n","Train loss 23972 0.544228 Grad Norm 1.878828 0.14s/it\n","Train loss 23973 0.472477 Grad Norm 0.902520 0.12s/it\n","Train loss 23974 0.535132 Grad Norm 1.211320 0.14s/it\n","Train loss 23975 0.462897 Grad Norm 0.751612 0.12s/it\n","Train loss 23976 0.650774 Grad Norm 2.478113 0.14s/it\n","Train loss 23977 0.530547 Grad Norm 1.008625 0.13s/it\n","Train loss 23978 0.581112 Grad Norm 1.610303 0.12s/it\n","Train loss 23979 0.641344 Grad Norm 1.460358 0.11s/it\n","Train loss 23980 0.310890 Grad Norm 0.424968 0.15s/it\n","Train loss 23981 0.587465 Grad Norm 0.992627 0.11s/it\n","Train loss 23982 0.564621 Grad Norm 1.312063 0.11s/it\n","Train loss 23983 0.543236 Grad Norm 1.086040 0.12s/it\n","Train loss 23984 0.597284 Grad Norm 1.152705 0.12s/it\n","Train loss 23985 0.573080 Grad Norm 1.469943 0.11s/it\n","Train loss 23986 0.540084 Grad Norm 0.986755 0.14s/it\n","Train loss 23987 0.438995 Grad Norm 1.765604 0.12s/it\n","Train loss 23988 0.570062 Grad Norm 3.015923 0.14s/it\n","Train loss 23989 0.591592 Grad Norm 1.464103 0.12s/it\n","Train loss 23990 0.827863 Grad Norm 1.335937 0.12s/it\n","Train loss 23991 0.548394 Grad Norm 1.401070 0.98s/it\n","Train loss 23992 0.363546 Grad Norm 0.717349 0.12s/it\n","Train loss 23993 0.837092 Grad Norm 2.909266 0.11s/it\n","Train loss 23994 0.704792 Grad Norm 2.714138 0.12s/it\n","Train loss 23995 0.592960 Grad Norm 1.002408 0.12s/it\n","Train loss 23996 0.425273 Grad Norm 0.908497 0.15s/it\n","Train loss 23997 0.593324 Grad Norm 1.659158 0.12s/it\n","Train loss 23998 0.580899 Grad Norm 2.746012 0.12s/it\n","Train loss 23999 0.800179 Grad Norm 1.979934 0.13s/it\n","Train loss 24000 0.564899 Grad Norm 1.123557 0.13s/it\n","Validation loss 24000: 0.403692\n","Saving model and optimizer state at iteration 24000 to checkpoint_24000\n","Train loss 24001 0.426079 Grad Norm 1.098221 0.14s/it\n","Train loss 24002 0.557480 Grad Norm 0.779174 0.12s/it\n","Train loss 24003 0.293897 Grad Norm 0.351034 0.10s/it\n","Train loss 24004 0.480938 Grad Norm 0.629916 0.12s/it\n","Train loss 24005 0.377259 Grad Norm 0.732369 0.13s/it\n","Train loss 24006 0.622467 Grad Norm 1.990041 0.13s/it\n","Train loss 24007 0.441195 Grad Norm 1.421247 0.11s/it\n","Train loss 24008 0.523022 Grad Norm 1.285879 0.12s/it\n","Train loss 24009 0.371692 Grad Norm 0.507978 0.14s/it\n","Train loss 24010 0.665063 Grad Norm 1.758422 0.13s/it\n","Train loss 24011 0.721522 Grad Norm 1.814095 0.12s/it\n","Train loss 24012 0.462993 Grad Norm 1.250679 0.12s/it\n","Train loss 24013 0.472909 Grad Norm 1.385849 0.11s/it\n","Train loss 24014 0.847330 Grad Norm 2.109829 0.11s/it\n","Train loss 24015 0.481256 Grad Norm 0.901121 0.15s/it\n","Train loss 24016 0.549322 Grad Norm 1.877858 0.13s/it\n","Train loss 24017 0.440378 Grad Norm 1.455532 0.12s/it\n","Train loss 24018 0.409993 Grad Norm 1.383092 0.13s/it\n","Train loss 24019 0.573430 Grad Norm 2.024253 0.12s/it\n","Train loss 24020 0.354271 Grad Norm 2.377006 0.14s/it\n","Train loss 24021 0.359879 Grad Norm 1.097553 0.11s/it\n","Train loss 24022 0.421799 Grad Norm 0.790418 0.14s/it\n","Train loss 24023 0.691065 Grad Norm 1.341163 0.11s/it\n","Train loss 24024 0.428216 Grad Norm 1.008112 0.14s/it\n","Train loss 24025 0.507731 Grad Norm 3.716067 0.11s/it\n","Train loss 24026 0.584180 Grad Norm 0.923288 0.11s/it\n","Train loss 24027 0.407567 Grad Norm 1.461250 0.13s/it\n","Train loss 24028 0.816915 Grad Norm 1.987934 0.12s/it\n","Train loss 24029 0.333677 Grad Norm 0.712767 0.15s/it\n","Train loss 24030 0.653739 Grad Norm 1.776320 0.11s/it\n","Train loss 24031 0.674312 Grad Norm 2.938385 0.12s/it\n","Train loss 24032 0.521337 Grad Norm 0.921607 0.14s/it\n","Train loss 24033 0.623144 Grad Norm 1.513621 0.10s/it\n","Train loss 24034 0.526352 Grad Norm 1.293008 0.15s/it\n","Train loss 24035 0.545765 Grad Norm 0.851822 0.10s/it\n","Train loss 24036 0.717155 Grad Norm 1.732011 0.13s/it\n","Train loss 24037 0.525591 Grad Norm 1.231248 0.14s/it\n","Train loss 24038 0.713118 Grad Norm 2.141032 0.13s/it\n","Train loss 24039 0.474173 Grad Norm 0.785338 0.10s/it\n","Train loss 24040 0.466304 Grad Norm 6.643830 0.14s/it\n","Train loss 24041 0.424532 Grad Norm 1.473567 0.11s/it\n","Train loss 24042 0.598568 Grad Norm 2.040976 0.14s/it\n","Train loss 24043 0.740796 Grad Norm 4.433082 0.11s/it\n","Train loss 24044 0.551079 Grad Norm 1.449713 0.15s/it\n","Train loss 24045 0.588518 Grad Norm 3.352524 0.10s/it\n","Train loss 24046 0.504948 Grad Norm 1.030818 0.12s/it\n","Train loss 24047 0.477785 Grad Norm 1.652421 0.12s/it\n","Train loss 24048 0.525949 Grad Norm 0.982220 0.13s/it\n","Train loss 24049 0.755790 Grad Norm 2.318712 0.12s/it\n","Train loss 24050 0.476147 Grad Norm 0.986942 0.14s/it\n","Train loss 24051 0.730950 Grad Norm 2.805161 0.11s/it\n","Train loss 24052 0.537268 Grad Norm 1.635124 0.13s/it\n","Train loss 24053 0.792292 Grad Norm 3.388281 0.12s/it\n","Train loss 24054 0.467066 Grad Norm 0.854433 0.13s/it\n","Train loss 24055 0.323209 Grad Norm 0.616637 0.16s/it\n","Train loss 24056 0.552864 Grad Norm 1.108059 0.10s/it\n","Train loss 24057 0.827570 Grad Norm 2.518451 0.13s/it\n","Train loss 24058 0.628607 Grad Norm 1.264399 0.12s/it\n","Train loss 24059 0.476733 Grad Norm 0.799550 0.15s/it\n","Train loss 24060 0.430185 Grad Norm 0.694137 0.10s/it\n","Train loss 24061 0.448253 Grad Norm 1.918662 0.11s/it\n","Train loss 24062 0.725792 Grad Norm 2.220243 0.12s/it\n","Train loss 24063 0.398215 Grad Norm 1.297548 0.12s/it\n","Train loss 24064 0.515244 Grad Norm 1.223393 0.14s/it\n","Train loss 24065 0.629579 Grad Norm 1.554961 0.13s/it\n","Train loss 24066 0.623991 Grad Norm 2.701339 0.11s/it\n","Train loss 24067 0.613894 Grad Norm 3.309226 0.14s/it\n","Train loss 24068 0.659651 Grad Norm 2.170676 0.11s/it\n","Train loss 24069 0.582356 Grad Norm 3.245520 0.14s/it\n","Train loss 24070 0.504664 Grad Norm 1.459728 0.12s/it\n","Train loss 24071 0.403204 Grad Norm 0.747005 0.12s/it\n","Train loss 24072 0.650565 Grad Norm 0.936387 0.12s/it\n","Train loss 24073 0.467583 Grad Norm 1.158078 0.12s/it\n","Train loss 24074 0.530224 Grad Norm 1.671244 0.11s/it\n","Train loss 24075 0.320681 Grad Norm 2.165338 0.14s/it\n","Train loss 24076 0.560433 Grad Norm 1.549785 0.12s/it\n","Train loss 24077 0.395234 Grad Norm 1.640418 0.12s/it\n","Train loss 24078 0.512247 Grad Norm 1.370851 0.13s/it\n","Train loss 24079 0.458740 Grad Norm 0.722527 0.14s/it\n","Train loss 24080 0.582079 Grad Norm 1.132477 0.11s/it\n","Train loss 24081 0.372565 Grad Norm 0.617697 0.14s/it\n","Train loss 24082 0.657852 Grad Norm 0.860700 0.12s/it\n","Train loss 24083 0.797123 Grad Norm 2.687377 0.13s/it\n","Train loss 24084 0.446676 Grad Norm 0.906179 0.13s/it\n","Train loss 24085 0.627642 Grad Norm 2.016960 0.14s/it\n","Train loss 24086 0.536497 Grad Norm 0.618273 0.16s/it\n","Train loss 24087 0.703949 Grad Norm 2.306381 0.11s/it\n","Train loss 24088 0.389372 Grad Norm 0.887267 0.15s/it\n","Train loss 24089 0.815334 Grad Norm 2.789056 0.10s/it\n","Train loss 24090 0.578504 Grad Norm 1.179492 0.15s/it\n","Train loss 24091 0.594675 Grad Norm 0.845711 0.13s/it\n","Train loss 24092 0.578158 Grad Norm 2.324248 0.14s/it\n","Train loss 24093 0.472500 Grad Norm 0.662212 0.12s/it\n","Train loss 24094 1.072764 Grad Norm 1.857275 0.12s/it\n","Train loss 24095 0.762062 Grad Norm 1.717487 0.12s/it\n","Train loss 24096 0.648005 Grad Norm 2.005461 0.11s/it\n","Train loss 24097 0.662023 Grad Norm 2.121586 0.13s/it\n","Train loss 24098 0.323012 Grad Norm 0.354628 0.15s/it\n","Train loss 24099 1.011252 Grad Norm 2.862805 0.11s/it\n","Train loss 24100 0.641617 Grad Norm 0.746600 0.15s/it\n","Train loss 24101 0.609009 Grad Norm 1.635701 0.14s/it\n","Train loss 24102 0.558232 Grad Norm 2.315797 0.11s/it\n","Train loss 24103 0.848523 Grad Norm 1.095573 0.11s/it\n","Train loss 24104 0.436854 Grad Norm 0.618615 0.14s/it\n","Train loss 24105 0.483386 Grad Norm 0.850972 0.10s/it\n","Train loss 24106 0.715830 Grad Norm 3.161955 0.10s/it\n","Train loss 24107 0.431024 Grad Norm 1.073236 0.12s/it\n","Train loss 24108 0.754303 Grad Norm 3.281635 0.11s/it\n","Train loss 24109 0.702635 Grad Norm 2.155287 0.11s/it\n","Train loss 24110 0.421448 Grad Norm 0.741054 0.13s/it\n","Train loss 24111 0.490815 Grad Norm 1.217260 0.12s/it\n","Train loss 24112 0.626155 Grad Norm 0.967520 0.15s/it\n","Train loss 24113 0.615210 Grad Norm 1.125758 0.14s/it\n","Train loss 24114 0.426109 Grad Norm 0.586936 0.13s/it\n","Train loss 24115 0.572274 Grad Norm 2.105073 0.13s/it\n","Train loss 24116 0.583258 Grad Norm 0.820168 0.14s/it\n","Train loss 24117 0.539381 Grad Norm 1.440805 0.14s/it\n","Train loss 24118 0.462094 Grad Norm 1.678136 0.13s/it\n","Train loss 24119 0.645885 Grad Norm 2.162071 0.14s/it\n","Train loss 24120 0.597029 Grad Norm 1.229410 0.13s/it\n","Train loss 24121 0.560009 Grad Norm 1.142642 0.11s/it\n","Train loss 24122 0.450870 Grad Norm 1.722952 0.12s/it\n","Train loss 24123 0.605902 Grad Norm 1.139096 0.11s/it\n","Train loss 24124 0.523138 Grad Norm 1.698518 0.12s/it\n","Train loss 24125 0.429614 Grad Norm 0.382171 0.14s/it\n","Train loss 24126 0.396580 Grad Norm 0.604181 0.13s/it\n","Train loss 24127 0.627533 Grad Norm 2.314530 0.12s/it\n","Train loss 24128 0.521899 Grad Norm 1.145617 0.13s/it\n","Train loss 24129 0.655204 Grad Norm 3.623733 0.13s/it\n","Train loss 24130 0.423961 Grad Norm 0.662168 0.15s/it\n","Train loss 24131 0.709280 Grad Norm 1.634242 0.11s/it\n","Train loss 24132 0.636541 Grad Norm 0.866591 0.10s/it\n","Train loss 24133 0.506637 Grad Norm 1.715408 0.15s/it\n","Train loss 24134 0.503502 Grad Norm 0.913193 0.11s/it\n","Train loss 24135 0.444649 Grad Norm 1.454168 0.11s/it\n","Train loss 24136 0.512037 Grad Norm 0.927894 0.14s/it\n","Train loss 24137 0.776969 Grad Norm 1.342843 0.11s/it\n","Train loss 24138 0.469167 Grad Norm 0.937616 0.11s/it\n","Train loss 24139 0.513773 Grad Norm 1.468339 0.13s/it\n","Train loss 24140 0.464029 Grad Norm 2.041799 0.13s/it\n","Train loss 24141 0.591489 Grad Norm 1.143881 0.16s/it\n","Train loss 24142 0.582278 Grad Norm 2.302935 0.12s/it\n","Train loss 24143 0.935905 Grad Norm 2.210998 0.12s/it\n","Train loss 24144 0.429543 Grad Norm 0.582525 0.12s/it\n","Train loss 24145 0.523588 Grad Norm 0.949950 0.12s/it\n","Train loss 24146 0.377510 Grad Norm 0.868484 0.16s/it\n","Train loss 24147 0.666383 Grad Norm 1.102277 0.12s/it\n","Train loss 24148 0.654011 Grad Norm 1.975117 0.11s/it\n","Train loss 24149 0.476683 Grad Norm 1.164316 0.10s/it\n","Train loss 24150 0.530344 Grad Norm 1.607280 0.13s/it\n","Train loss 24151 0.566554 Grad Norm 3.788263 0.12s/it\n","Train loss 24152 0.640793 Grad Norm 1.953217 0.13s/it\n","Train loss 24153 0.416353 Grad Norm 1.142115 0.11s/it\n","Train loss 24154 0.559756 Grad Norm 2.810903 0.12s/it\n","Train loss 24155 0.825344 Grad Norm 1.859034 0.13s/it\n","Train loss 24156 0.250226 Grad Norm 0.384794 0.11s/it\n","Train loss 24157 0.563820 Grad Norm 2.477125 0.13s/it\n","Train loss 24158 0.527874 Grad Norm 0.849187 0.13s/it\n","Train loss 24159 0.408024 Grad Norm 1.236716 0.10s/it\n","Train loss 24160 0.783479 Grad Norm 2.153713 0.11s/it\n","Train loss 24161 0.808550 Grad Norm 1.373829 0.12s/it\n","Train loss 24162 0.838935 Grad Norm 1.519340 0.11s/it\n","Train loss 24163 0.402605 Grad Norm 1.976816 0.12s/it\n","Train loss 24164 0.554080 Grad Norm 1.671475 0.14s/it\n","Train loss 24165 0.654620 Grad Norm 1.367975 0.13s/it\n","Train loss 24166 0.372478 Grad Norm 0.782967 0.10s/it\n","Train loss 24167 0.471664 Grad Norm 0.374260 0.13s/it\n","Train loss 24168 0.663502 Grad Norm 1.294914 0.10s/it\n","Train loss 24169 0.586212 Grad Norm 1.610803 0.13s/it\n","Train loss 24170 0.398959 Grad Norm 1.022792 0.13s/it\n","Train loss 24171 0.348940 Grad Norm 2.493162 0.11s/it\n","Train loss 24172 0.504456 Grad Norm 2.056120 0.13s/it\n","Train loss 24173 0.726412 Grad Norm 1.782028 0.12s/it\n","Train loss 24174 0.307008 Grad Norm 0.694714 0.13s/it\n","Train loss 24175 0.899737 Grad Norm 1.908399 0.14s/it\n","Train loss 24176 0.448689 Grad Norm 1.534990 0.11s/it\n","Train loss 24177 0.702669 Grad Norm 1.606451 0.14s/it\n","Train loss 24178 0.747490 Grad Norm 2.057541 0.13s/it\n","Train loss 24179 0.492898 Grad Norm 1.410095 0.15s/it\n","Train loss 24180 0.641986 Grad Norm 1.086649 0.11s/it\n","Train loss 24181 0.833920 Grad Norm 1.972719 0.13s/it\n","Train loss 24182 0.352239 Grad Norm 0.929284 0.11s/it\n","Train loss 24183 0.785529 Grad Norm 1.492089 0.13s/it\n","Train loss 24184 0.446394 Grad Norm 1.749763 0.14s/it\n","Train loss 24185 0.634691 Grad Norm 1.415188 0.11s/it\n","Train loss 24186 0.594578 Grad Norm 1.116451 0.12s/it\n","Train loss 24187 0.531078 Grad Norm 1.280570 0.14s/it\n","Train loss 24188 0.518464 Grad Norm 2.432390 0.10s/it\n","Train loss 24189 0.595682 Grad Norm 1.733553 0.12s/it\n","Train loss 24190 1.030408 Grad Norm 2.288164 0.12s/it\n","Train loss 24191 0.760157 Grad Norm 3.144070 0.11s/it\n","Train loss 24192 0.303082 Grad Norm 0.539620 0.15s/it\n","Train loss 24193 0.814580 Grad Norm 1.511032 0.11s/it\n","Train loss 24194 0.591499 Grad Norm 1.818860 0.10s/it\n","Train loss 24195 0.819727 Grad Norm 2.284428 0.12s/it\n","Train loss 24196 0.693349 Grad Norm 2.019531 0.10s/it\n","Train loss 24197 0.530775 Grad Norm 2.319036 0.12s/it\n","Train loss 24198 0.741501 Grad Norm 1.360437 0.13s/it\n","Train loss 24199 0.585728 Grad Norm 1.432354 0.11s/it\n","Train loss 24200 0.723720 Grad Norm 1.619707 0.14s/it\n","Train loss 24201 0.302409 Grad Norm 0.356977 0.14s/it\n","Train loss 24202 0.623228 Grad Norm 1.864446 0.12s/it\n","Train loss 24203 0.590350 Grad Norm 1.689768 0.14s/it\n","Train loss 24204 0.849373 Grad Norm 2.046700 0.12s/it\n","Train loss 24205 0.684150 Grad Norm 1.218394 0.13s/it\n","Train loss 24206 0.827469 Grad Norm 2.323610 0.14s/it\n","Train loss 24207 0.563787 Grad Norm 2.009972 0.12s/it\n","Train loss 24208 0.943021 Grad Norm 2.059398 0.11s/it\n","Train loss 24209 0.428616 Grad Norm 1.027704 0.13s/it\n","Train loss 24210 0.695460 Grad Norm 0.736398 0.11s/it\n","Train loss 24211 0.890796 Grad Norm 0.916334 0.12s/it\n","Train loss 24212 0.722862 Grad Norm 1.304754 0.11s/it\n","Train loss 24213 0.600557 Grad Norm 1.563940 0.12s/it\n","Train loss 24214 0.591883 Grad Norm 1.708404 0.13s/it\n","Train loss 24215 0.614269 Grad Norm 1.916729 0.13s/it\n","Train loss 24216 0.501039 Grad Norm 1.102386 0.11s/it\n","Train loss 24217 0.443712 Grad Norm 1.504756 0.13s/it\n","Train loss 24218 0.832816 Grad Norm 1.596045 0.13s/it\n","Train loss 24219 0.338360 Grad Norm 0.817567 0.14s/it\n","Train loss 24220 0.430238 Grad Norm 1.169124 0.12s/it\n","Train loss 24221 0.475682 Grad Norm 2.298624 0.09s/it\n","Train loss 24222 0.406568 Grad Norm 0.858627 0.10s/it\n","Train loss 24223 0.456320 Grad Norm 1.360284 0.13s/it\n","Train loss 24224 0.417336 Grad Norm 0.619586 0.14s/it\n","Train loss 24225 0.322615 Grad Norm 0.501485 0.13s/it\n","Train loss 24226 0.720278 Grad Norm 2.732011 0.11s/it\n","Train loss 24227 0.418033 Grad Norm 0.878482 0.14s/it\n","Train loss 24228 0.568796 Grad Norm 1.459109 0.12s/it\n","Train loss 24229 0.725590 Grad Norm 1.506121 0.11s/it\n","Train loss 24230 0.487800 Grad Norm 0.773453 0.10s/it\n","Train loss 24231 0.681331 Grad Norm 1.257254 0.11s/it\n","Train loss 24232 0.531837 Grad Norm 1.895231 0.14s/it\n","Train loss 24233 0.480701 Grad Norm 1.087510 0.14s/it\n","Train loss 24234 0.453188 Grad Norm 1.426713 0.10s/it\n","Train loss 24235 0.489561 Grad Norm 2.628930 0.16s/it\n","Train loss 24236 0.518257 Grad Norm 2.287313 0.12s/it\n","Train loss 24237 0.537825 Grad Norm 0.940260 0.12s/it\n","Train loss 24238 0.491493 Grad Norm 0.655315 0.13s/it\n","Train loss 24239 0.829489 Grad Norm 2.191318 0.12s/it\n","Train loss 24240 0.533222 Grad Norm 1.099797 0.11s/it\n","Train loss 24241 0.779958 Grad Norm 3.218234 0.11s/it\n","Train loss 24242 0.370369 Grad Norm 1.410624 0.15s/it\n","Train loss 24243 0.380917 Grad Norm 0.851181 0.13s/it\n","Train loss 24244 0.604121 Grad Norm 1.587492 0.12s/it\n","Train loss 24245 0.590037 Grad Norm 1.154598 0.12s/it\n","Train loss 24246 0.432060 Grad Norm 0.930171 0.12s/it\n","Train loss 24247 0.499968 Grad Norm 2.614391 0.12s/it\n","Train loss 24248 0.473966 Grad Norm 2.525838 0.11s/it\n","Train loss 24249 0.869459 Grad Norm 1.793712 0.11s/it\n","Train loss 24250 0.536411 Grad Norm 1.323799 0.12s/it\n","Train loss 24251 0.553872 Grad Norm 0.936323 0.11s/it\n","Train loss 24252 0.477341 Grad Norm 2.083952 0.11s/it\n","Train loss 24253 0.347831 Grad Norm 0.691444 0.11s/it\n","Train loss 24254 0.533778 Grad Norm 1.327466 0.13s/it\n","Train loss 24255 0.609946 Grad Norm 1.619806 0.13s/it\n","Train loss 24256 0.737707 Grad Norm 0.867265 0.12s/it\n","Train loss 24257 0.319141 Grad Norm 0.796695 0.13s/it\n","Train loss 24258 0.453159 Grad Norm 1.253046 0.14s/it\n","Train loss 24259 0.714961 Grad Norm 1.234825 0.12s/it\n","Train loss 24260 0.376067 Grad Norm 1.091151 0.11s/it\n","Train loss 24261 0.411887 Grad Norm 1.940360 0.13s/it\n","Train loss 24262 0.553268 Grad Norm 0.900887 0.12s/it\n","Train loss 24263 0.488620 Grad Norm 3.982836 0.11s/it\n","Train loss 24264 0.724805 Grad Norm 1.354209 0.11s/it\n","Train loss 24265 0.493227 Grad Norm 1.693947 0.11s/it\n","Train loss 24266 0.339149 Grad Norm 0.802222 0.12s/it\n","Train loss 24267 0.304728 Grad Norm 1.463866 0.14s/it\n","Train loss 24268 0.274318 Grad Norm 0.608289 0.17s/it\n","Train loss 24269 0.372633 Grad Norm 2.484809 0.11s/it\n","Train loss 24270 0.583401 Grad Norm 1.129386 0.14s/it\n","Train loss 24271 0.600315 Grad Norm 1.876489 0.11s/it\n","Train loss 24272 0.479945 Grad Norm 3.332900 0.10s/it\n","Train loss 24273 0.560779 Grad Norm 0.671858 0.12s/it\n","Train loss 24274 0.333204 Grad Norm 1.888044 0.12s/it\n","Train loss 24275 0.543748 Grad Norm 0.806466 0.12s/it\n","Train loss 24276 0.557339 Grad Norm 1.116399 0.12s/it\n","Train loss 24277 0.380920 Grad Norm 1.202244 0.11s/it\n","Train loss 24278 0.754737 Grad Norm 1.561993 0.11s/it\n","Train loss 24279 0.479150 Grad Norm 1.984589 0.16s/it\n","Train loss 24280 0.575221 Grad Norm 1.368030 0.09s/it\n","Train loss 24281 0.541058 Grad Norm 1.246305 0.13s/it\n","Train loss 24282 0.609687 Grad Norm 1.295967 0.13s/it\n","Train loss 24283 0.458499 Grad Norm 0.671801 0.13s/it\n","Train loss 24284 0.529311 Grad Norm 2.388733 0.14s/it\n","Train loss 24285 0.525463 Grad Norm 1.858830 0.11s/it\n","Train loss 24286 0.338532 Grad Norm 0.387240 0.14s/it\n","Train loss 24287 0.593903 Grad Norm 2.796920 0.14s/it\n","Train loss 24288 0.715624 Grad Norm 1.835812 0.11s/it\n","Train loss 24289 0.362987 Grad Norm 0.507870 0.11s/it\n","Train loss 24290 0.360872 Grad Norm 1.261583 0.14s/it\n","Train loss 24291 0.589594 Grad Norm 1.761014 0.10s/it\n","Train loss 24292 0.490379 Grad Norm 1.963948 0.12s/it\n","Train loss 24293 0.349574 Grad Norm 0.407362 0.12s/it\n","Train loss 24294 0.622676 Grad Norm 3.150043 0.12s/it\n","Train loss 24295 0.533727 Grad Norm 1.894800 0.15s/it\n","Train loss 24296 0.654793 Grad Norm 1.189539 0.13s/it\n","Train loss 24297 0.515644 Grad Norm 0.819331 0.12s/it\n","Train loss 24298 0.418976 Grad Norm 0.808174 0.14s/it\n","Train loss 24299 0.548304 Grad Norm 0.879063 0.15s/it\n","Train loss 24300 0.754195 Grad Norm 2.104783 0.12s/it\n","Train loss 24301 0.589083 Grad Norm 1.109796 0.11s/it\n","Train loss 24302 0.673073 Grad Norm 4.141639 0.11s/it\n","Train loss 24303 0.592955 Grad Norm 1.846672 0.11s/it\n","Train loss 24304 0.581807 Grad Norm 1.133593 0.14s/it\n","Train loss 24305 0.326819 Grad Norm 0.675170 0.14s/it\n","Train loss 24306 0.395286 Grad Norm 1.753258 0.10s/it\n","Train loss 24307 0.560095 Grad Norm 1.381915 0.13s/it\n","Train loss 24308 0.578535 Grad Norm 1.733094 0.13s/it\n","Train loss 24309 0.440344 Grad Norm 1.399102 0.17s/it\n","Train loss 24310 0.620371 Grad Norm 1.541478 0.15s/it\n","Train loss 24311 0.546743 Grad Norm 3.691214 0.12s/it\n","Train loss 24312 0.411458 Grad Norm 1.339504 0.15s/it\n","Train loss 24313 0.674841 Grad Norm 1.545856 0.11s/it\n","Train loss 24314 0.454380 Grad Norm 0.709242 0.11s/it\n","Train loss 24315 0.450572 Grad Norm 1.587157 0.12s/it\n","Train loss 24316 0.666762 Grad Norm 1.878639 0.13s/it\n","Train loss 24317 0.336971 Grad Norm 1.371171 0.13s/it\n","Train loss 24318 0.723520 Grad Norm 1.691708 0.12s/it\n","Train loss 24319 0.487782 Grad Norm 1.000877 0.12s/it\n","Train loss 24320 0.832118 Grad Norm 1.427586 0.13s/it\n","Train loss 24321 0.715675 Grad Norm 2.472418 0.13s/it\n","Train loss 24322 0.596946 Grad Norm 1.069178 0.13s/it\n","Train loss 24323 0.574744 Grad Norm 1.581708 0.13s/it\n","Train loss 24324 0.644035 Grad Norm 1.329291 0.15s/it\n","Train loss 24325 0.870672 Grad Norm 1.799628 0.10s/it\n","Train loss 24326 0.579403 Grad Norm 1.559927 0.14s/it\n","Train loss 24327 0.331006 Grad Norm 0.783662 0.11s/it\n","Train loss 24328 0.515409 Grad Norm 1.837247 0.15s/it\n","Train loss 24329 0.463014 Grad Norm 2.217809 0.13s/it\n","Train loss 24330 0.571540 Grad Norm 1.493376 0.15s/it\n","Train loss 24331 0.392973 Grad Norm 0.855748 0.14s/it\n","Train loss 24332 0.531171 Grad Norm 1.467433 0.14s/it\n","Train loss 24333 0.676512 Grad Norm 1.410528 0.12s/it\n","Train loss 24334 0.411126 Grad Norm 1.057772 0.13s/it\n","Train loss 24335 0.329881 Grad Norm 0.699296 0.13s/it\n","Train loss 24336 0.479344 Grad Norm 0.869249 0.10s/it\n","Train loss 24337 0.421765 Grad Norm 0.964703 0.13s/it\n","Train loss 24338 0.501279 Grad Norm 2.121338 0.13s/it\n","Train loss 24339 0.611578 Grad Norm 1.234838 0.10s/it\n","Train loss 24340 0.580836 Grad Norm 2.007463 0.10s/it\n","Train loss 24341 0.621354 Grad Norm 2.072267 0.10s/it\n","Train loss 24342 0.481795 Grad Norm 1.344253 0.12s/it\n","Train loss 24343 0.547788 Grad Norm 1.687439 0.11s/it\n","Train loss 24344 0.513648 Grad Norm 1.666154 0.11s/it\n","Train loss 24345 0.379798 Grad Norm 0.718620 0.13s/it\n","Train loss 24346 0.419596 Grad Norm 1.425003 0.11s/it\n","Train loss 24347 0.419488 Grad Norm 1.535362 0.15s/it\n","Train loss 24348 0.765281 Grad Norm 1.116911 0.15s/it\n","Train loss 24349 0.342673 Grad Norm 1.467937 0.12s/it\n","Train loss 24350 0.583978 Grad Norm 1.480339 0.12s/it\n","Train loss 24351 0.590666 Grad Norm 3.358799 0.10s/it\n","Train loss 24352 0.433889 Grad Norm 0.753641 0.13s/it\n","Train loss 24353 0.599311 Grad Norm 1.037766 0.12s/it\n","Train loss 24354 0.445387 Grad Norm 1.060983 0.12s/it\n","Train loss 24355 0.376705 Grad Norm 0.678183 0.13s/it\n","Train loss 24356 0.804462 Grad Norm 1.937088 0.14s/it\n","Train loss 24357 0.523380 Grad Norm 1.115877 0.13s/it\n","Train loss 24358 0.476396 Grad Norm 0.738004 0.11s/it\n","Train loss 24359 0.334815 Grad Norm 0.572949 0.15s/it\n","Train loss 24360 0.543713 Grad Norm 1.258708 0.11s/it\n","Train loss 24361 0.626863 Grad Norm 0.955039 0.14s/it\n","Train loss 24362 0.713428 Grad Norm 2.510861 0.11s/it\n","Train loss 24363 0.582507 Grad Norm 0.857043 0.15s/it\n","Train loss 24364 0.426870 Grad Norm 0.909166 0.13s/it\n","Train loss 24365 0.643014 Grad Norm 2.397855 0.12s/it\n","Train loss 24366 0.709961 Grad Norm 1.562503 0.13s/it\n","Train loss 24367 0.389840 Grad Norm 0.525048 0.12s/it\n","Train loss 24368 0.548467 Grad Norm 1.106130 0.11s/it\n","Train loss 24369 0.747682 Grad Norm 4.187424 0.12s/it\n","Train loss 24370 0.628048 Grad Norm 2.701871 0.12s/it\n","Train loss 24371 0.521558 Grad Norm 1.130073 0.12s/it\n","Train loss 24372 0.361504 Grad Norm 3.410987 0.14s/it\n","Train loss 24373 0.528725 Grad Norm 0.869282 0.12s/it\n","Train loss 24374 0.828355 Grad Norm 1.150541 0.14s/it\n","Train loss 24375 0.416004 Grad Norm 1.076859 0.13s/it\n","Train loss 24376 0.544879 Grad Norm 2.054951 0.11s/it\n","Train loss 24377 0.427453 Grad Norm 1.203070 0.11s/it\n","Train loss 24378 0.841295 Grad Norm 2.230531 0.13s/it\n","Train loss 24379 0.576768 Grad Norm 1.402328 0.12s/it\n","Train loss 24380 0.497503 Grad Norm 0.873558 0.13s/it\n","Train loss 24381 0.532681 Grad Norm 1.512906 0.11s/it\n","Train loss 24382 0.863806 Grad Norm 2.256740 0.11s/it\n","Train loss 24383 0.445813 Grad Norm 0.998929 0.13s/it\n","Train loss 24384 0.735954 Grad Norm 1.508458 0.12s/it\n","Train loss 24385 0.704510 Grad Norm 0.978369 0.12s/it\n","Train loss 24386 0.446567 Grad Norm 1.335392 0.13s/it\n","Train loss 24387 0.776084 Grad Norm 3.144234 0.12s/it\n","Train loss 24388 0.541178 Grad Norm 1.489389 0.13s/it\n","Train loss 24389 0.597243 Grad Norm 2.172931 0.12s/it\n","Train loss 24390 0.402401 Grad Norm 1.166793 0.10s/it\n","Train loss 24391 0.684735 Grad Norm 2.312555 0.13s/it\n","Train loss 24392 0.882367 Grad Norm 1.818405 0.13s/it\n","Train loss 24393 0.523329 Grad Norm 0.904043 0.10s/it\n","Train loss 24394 0.605665 Grad Norm 0.903745 0.12s/it\n","Train loss 24395 0.423611 Grad Norm 2.029078 0.14s/it\n","Train loss 24396 0.602483 Grad Norm 1.254614 0.14s/it\n","Train loss 24397 0.523311 Grad Norm 0.849930 0.12s/it\n","Train loss 24398 0.505969 Grad Norm 0.844087 0.14s/it\n","Train loss 24399 0.364607 Grad Norm 1.220607 0.11s/it\n","Train loss 24400 0.452862 Grad Norm 1.321090 0.13s/it\n","Train loss 24401 0.521668 Grad Norm 1.691226 0.11s/it\n","Train loss 24402 0.684714 Grad Norm 1.567890 0.11s/it\n","Train loss 24403 0.648431 Grad Norm 1.930130 0.13s/it\n","Train loss 24404 0.648820 Grad Norm 1.032794 0.15s/it\n","Train loss 24405 0.413640 Grad Norm 0.415596 0.11s/it\n","Train loss 24406 0.886634 Grad Norm 2.862357 0.10s/it\n","Train loss 24407 0.354534 Grad Norm 1.494973 0.10s/it\n","Train loss 24408 0.438750 Grad Norm 0.454003 0.12s/it\n","Train loss 24409 1.015697 Grad Norm 1.394956 0.13s/it\n","Train loss 24410 0.723829 Grad Norm 1.359305 0.14s/it\n","Train loss 24411 0.549240 Grad Norm 4.135144 0.12s/it\n","Train loss 24412 0.416875 Grad Norm 0.771835 0.11s/it\n","Train loss 24413 0.463150 Grad Norm 1.601394 0.13s/it\n","Train loss 24414 0.582760 Grad Norm 1.245969 0.13s/it\n","Train loss 24415 0.594747 Grad Norm 1.987667 0.12s/it\n","Train loss 24416 0.814940 Grad Norm 2.159818 0.11s/it\n","Train loss 24417 0.461057 Grad Norm 0.471185 0.11s/it\n","Train loss 24418 0.523428 Grad Norm 1.918247 0.13s/it\n","Train loss 24419 0.601680 Grad Norm 1.610400 0.12s/it\n","Train loss 24420 0.438986 Grad Norm 1.013338 0.12s/it\n","Train loss 24421 0.703535 Grad Norm 1.450643 0.10s/it\n","Train loss 24422 0.690613 Grad Norm 2.209069 0.11s/it\n","Train loss 24423 0.360061 Grad Norm 0.565094 0.11s/it\n","Train loss 24424 0.418782 Grad Norm 0.841084 0.11s/it\n","Train loss 24425 0.590131 Grad Norm 2.345661 0.14s/it\n","Train loss 24426 0.517963 Grad Norm 1.245049 0.14s/it\n","Train loss 24427 0.468440 Grad Norm 1.041037 0.11s/it\n","Train loss 24428 0.526372 Grad Norm 1.038046 0.13s/it\n","Train loss 24429 0.553600 Grad Norm 1.068604 0.11s/it\n","Train loss 24430 0.707024 Grad Norm 3.167423 0.12s/it\n","Train loss 24431 0.656556 Grad Norm 2.427242 0.11s/it\n","Train loss 24432 0.471010 Grad Norm 1.358483 0.12s/it\n","Train loss 24433 0.615510 Grad Norm 1.341528 0.15s/it\n","Train loss 24434 0.275784 Grad Norm 0.572979 0.13s/it\n","Train loss 24435 0.637508 Grad Norm 1.926706 0.13s/it\n","Train loss 24436 0.467834 Grad Norm 2.395153 0.14s/it\n","Train loss 24437 0.541064 Grad Norm 1.705225 0.12s/it\n","Train loss 24438 0.453426 Grad Norm 1.118333 0.12s/it\n","Train loss 24439 0.542887 Grad Norm 1.608042 0.10s/it\n","Train loss 24440 0.570414 Grad Norm 1.438547 0.13s/it\n","Train loss 24441 0.583868 Grad Norm 1.420133 0.12s/it\n","Train loss 24442 0.491232 Grad Norm 0.769440 0.12s/it\n","Train loss 24443 0.535886 Grad Norm 1.080953 0.15s/it\n","Train loss 24444 0.898472 Grad Norm 5.200766 0.12s/it\n","Train loss 24445 0.719915 Grad Norm 1.608759 0.12s/it\n","Train loss 24446 0.734759 Grad Norm 1.309869 0.14s/it\n","Train loss 24447 0.791766 Grad Norm 2.307350 0.12s/it\n","Train loss 24448 0.630111 Grad Norm 1.552485 0.14s/it\n","Train loss 24449 0.716819 Grad Norm 5.061781 0.11s/it\n","Train loss 24450 0.464069 Grad Norm 3.852378 0.16s/it\n","Train loss 24451 0.563067 Grad Norm 1.424597 0.13s/it\n","Train loss 24452 0.438940 Grad Norm 1.626896 0.13s/it\n","Train loss 24453 0.815482 Grad Norm 1.499653 0.14s/it\n","Train loss 24454 0.466848 Grad Norm 0.948209 0.13s/it\n","Train loss 24455 0.894866 Grad Norm 2.129000 0.11s/it\n","Train loss 24456 0.351015 Grad Norm 0.497480 0.16s/it\n","Train loss 24457 0.457152 Grad Norm 3.842113 0.15s/it\n","Train loss 24458 0.484137 Grad Norm 1.239551 0.13s/it\n","Train loss 24459 0.568726 Grad Norm 1.047556 0.12s/it\n","Train loss 24460 0.381490 Grad Norm 4.133665 0.14s/it\n","Train loss 24461 0.568204 Grad Norm 1.158130 0.12s/it\n","Train loss 24462 0.549517 Grad Norm 0.482524 0.10s/it\n","Train loss 24463 0.803572 Grad Norm 3.040020 0.10s/it\n","Train loss 24464 0.535362 Grad Norm 2.050594 0.10s/it\n","Train loss 24465 0.584509 Grad Norm 1.671811 0.12s/it\n","Train loss 24466 0.651081 Grad Norm 0.918419 0.13s/it\n","Train loss 24467 0.781563 Grad Norm 7.930691 0.10s/it\n","Train loss 24468 0.628428 Grad Norm 1.049776 0.12s/it\n","Train loss 24469 0.384789 Grad Norm 1.249787 0.12s/it\n","Train loss 24470 0.440979 Grad Norm 1.253696 0.10s/it\n","Train loss 24471 0.378849 Grad Norm 1.023602 0.14s/it\n","Train loss 24472 0.479035 Grad Norm 1.181475 0.14s/it\n","Train loss 24473 0.414661 Grad Norm 2.095730 0.12s/it\n","Train loss 24474 0.426791 Grad Norm 0.811394 0.11s/it\n","Train loss 24475 0.499939 Grad Norm 1.904459 0.14s/it\n","Train loss 24476 0.444789 Grad Norm 0.768175 0.14s/it\n","Train loss 24477 0.485764 Grad Norm 1.121895 0.13s/it\n","Train loss 24478 0.447723 Grad Norm 1.131927 0.13s/it\n","Train loss 24479 0.831615 Grad Norm 2.958500 0.11s/it\n","Train loss 24480 0.589694 Grad Norm 1.488581 0.13s/it\n","Train loss 24481 0.545074 Grad Norm 2.446563 0.13s/it\n","Train loss 24482 0.651738 Grad Norm 2.909509 0.10s/it\n","Train loss 24483 0.595127 Grad Norm 1.111446 0.11s/it\n","Train loss 24484 0.592390 Grad Norm 1.527164 0.13s/it\n","Train loss 24485 0.577611 Grad Norm 2.036920 0.13s/it\n","Train loss 24486 0.477228 Grad Norm 2.243251 0.15s/it\n","Train loss 24487 0.580710 Grad Norm 0.642248 0.13s/it\n","Train loss 24488 0.696087 Grad Norm 3.849620 0.10s/it\n","Train loss 24489 0.735252 Grad Norm 2.201172 0.11s/it\n","Train loss 24490 0.549538 Grad Norm 2.328175 0.10s/it\n","Train loss 24491 0.510976 Grad Norm 1.528412 0.11s/it\n","Train loss 24492 0.652294 Grad Norm 1.518134 0.12s/it\n","Train loss 24493 0.877180 Grad Norm 2.889768 0.11s/it\n","Train loss 24494 0.375875 Grad Norm 0.512195 0.12s/it\n","Train loss 24495 0.595226 Grad Norm 2.579545 0.15s/it\n","Train loss 24496 0.685569 Grad Norm 4.453754 0.15s/it\n","Train loss 24497 0.751593 Grad Norm 1.266515 0.13s/it\n","Train loss 24498 0.851192 Grad Norm 1.460717 0.11s/it\n","Train loss 24499 0.437884 Grad Norm 1.411151 0.15s/it\n","Train loss 24500 0.645669 Grad Norm 1.271330 0.12s/it\n","Train loss 24501 0.552183 Grad Norm 1.942658 0.13s/it\n","Train loss 24502 0.309329 Grad Norm 1.555791 0.13s/it\n","Train loss 24503 0.528586 Grad Norm 2.174658 0.15s/it\n","Train loss 24504 0.649046 Grad Norm 1.664923 0.11s/it\n","Train loss 24505 0.487686 Grad Norm 0.879168 0.14s/it\n","Train loss 24506 0.545003 Grad Norm 1.080376 0.13s/it\n","Train loss 24507 0.491921 Grad Norm 1.147863 0.13s/it\n","Train loss 24508 0.671987 Grad Norm 1.405791 0.12s/it\n","Train loss 24509 0.422156 Grad Norm 0.670922 0.14s/it\n","Train loss 24510 0.532554 Grad Norm 1.528787 0.13s/it\n","Train loss 24511 0.699917 Grad Norm 1.815812 0.13s/it\n","Train loss 24512 0.505325 Grad Norm 1.146465 0.13s/it\n","Train loss 24513 0.527507 Grad Norm 1.079069 0.13s/it\n","Train loss 24514 0.377229 Grad Norm 0.496219 0.11s/it\n","Train loss 24515 0.534597 Grad Norm 1.571033 0.12s/it\n","Train loss 24516 0.688031 Grad Norm 1.724750 0.10s/it\n","Train loss 24517 0.647680 Grad Norm 0.974748 0.12s/it\n","Train loss 24518 0.584253 Grad Norm 1.831937 0.12s/it\n","Train loss 24519 0.315424 Grad Norm 0.987586 0.12s/it\n","Train loss 24520 0.487691 Grad Norm 1.556328 0.10s/it\n","Train loss 24521 0.344205 Grad Norm 0.868596 0.11s/it\n","Train loss 24522 0.604797 Grad Norm 1.342776 0.13s/it\n","Train loss 24523 0.551906 Grad Norm 1.209725 0.12s/it\n","Train loss 24524 0.392774 Grad Norm 0.455237 0.09s/it\n","Train loss 24525 0.711550 Grad Norm 1.847049 0.14s/it\n","Train loss 24526 0.571766 Grad Norm 1.939704 0.11s/it\n","Train loss 24527 0.641434 Grad Norm 1.142315 0.13s/it\n","Train loss 24528 0.408833 Grad Norm 1.132505 0.13s/it\n","Train loss 24529 0.663578 Grad Norm 3.166630 0.12s/it\n","Train loss 24530 0.480960 Grad Norm 0.719567 0.10s/it\n","Train loss 24531 0.870691 Grad Norm 3.128083 0.13s/it\n","Train loss 24532 0.694757 Grad Norm 1.704873 0.13s/it\n","Train loss 24533 0.476991 Grad Norm 1.960365 0.11s/it\n","Train loss 24534 0.429588 Grad Norm 0.690489 0.15s/it\n","Train loss 24535 0.601511 Grad Norm 2.414340 0.13s/it\n","Train loss 24536 0.666240 Grad Norm 5.142448 0.12s/it\n","Train loss 24537 0.551101 Grad Norm 1.163175 0.15s/it\n","Train loss 24538 0.481214 Grad Norm 1.735961 0.11s/it\n","Train loss 24539 0.420028 Grad Norm 1.254248 0.16s/it\n","Train loss 24540 0.524304 Grad Norm 0.854577 0.12s/it\n","Train loss 24541 0.309804 Grad Norm 0.832548 0.13s/it\n","Train loss 24542 1.012058 Grad Norm 2.841932 0.11s/it\n","Train loss 24543 0.454496 Grad Norm 1.281970 0.12s/it\n","Train loss 24544 0.467573 Grad Norm 1.864060 0.13s/it\n","Train loss 24545 0.665478 Grad Norm 1.394938 0.13s/it\n","Train loss 24546 0.520699 Grad Norm 0.961057 0.14s/it\n","Train loss 24547 0.569724 Grad Norm 0.842949 0.13s/it\n","Train loss 24548 0.509361 Grad Norm 1.895544 0.10s/it\n","Train loss 24549 0.607573 Grad Norm 3.592689 0.11s/it\n","Train loss 24550 0.594324 Grad Norm 1.076779 0.12s/it\n","Train loss 24551 0.479727 Grad Norm 0.991223 0.11s/it\n","Train loss 24552 0.408417 Grad Norm 1.897101 0.15s/it\n","Train loss 24553 0.471864 Grad Norm 2.005436 0.11s/it\n","Train loss 24554 0.746578 Grad Norm 2.096195 0.12s/it\n","Train loss 24555 0.532376 Grad Norm 1.321934 0.13s/it\n","Train loss 24556 0.548866 Grad Norm 5.487453 0.13s/it\n","Train loss 24557 0.491589 Grad Norm 1.458875 0.11s/it\n","Train loss 24558 0.565292 Grad Norm 1.076994 0.13s/it\n","Train loss 24559 0.403882 Grad Norm 0.870976 0.12s/it\n","Train loss 24560 0.553539 Grad Norm 1.513917 0.13s/it\n","Train loss 24561 0.877993 Grad Norm 1.879535 0.12s/it\n","Train loss 24562 0.589975 Grad Norm 1.699121 0.14s/it\n","Train loss 24563 0.385518 Grad Norm 0.487824 0.13s/it\n","Train loss 24564 0.424624 Grad Norm 1.186118 0.12s/it\n","Train loss 24565 0.498399 Grad Norm 2.494306 0.12s/it\n","Train loss 24566 0.699674 Grad Norm 1.249215 0.12s/it\n","Train loss 24567 0.570599 Grad Norm 2.424538 0.12s/it\n","Train loss 24568 0.660656 Grad Norm 1.417987 0.14s/it\n","Train loss 24569 0.332454 Grad Norm 0.854025 0.14s/it\n","Train loss 24570 0.620338 Grad Norm 1.513188 0.13s/it\n","Train loss 24571 0.480879 Grad Norm 1.414715 0.11s/it\n","Train loss 24572 0.445308 Grad Norm 0.483941 0.12s/it\n","Train loss 24573 0.561910 Grad Norm 3.071395 0.12s/it\n","Train loss 24574 0.539769 Grad Norm 2.915964 0.13s/it\n","Train loss 24575 0.763687 Grad Norm 2.672014 0.12s/it\n","Train loss 24576 0.631255 Grad Norm 2.120508 0.09s/it\n","Train loss 24577 0.478637 Grad Norm 0.863225 0.12s/it\n","Train loss 24578 0.635027 Grad Norm 2.092877 0.11s/it\n","Train loss 24579 0.384915 Grad Norm 1.788708 0.12s/it\n","Train loss 24580 0.397603 Grad Norm 0.596186 0.13s/it\n","Train loss 24581 0.395420 Grad Norm 1.035314 0.18s/it\n","Train loss 24582 0.403717 Grad Norm 0.867064 0.11s/it\n","Train loss 24583 0.510201 Grad Norm 1.009902 0.11s/it\n","Train loss 24584 0.664970 Grad Norm 2.262787 0.12s/it\n","Train loss 24585 0.526044 Grad Norm 1.120266 0.14s/it\n","Train loss 24586 0.391755 Grad Norm 0.784383 0.13s/it\n","Train loss 24587 0.442432 Grad Norm 0.785070 0.15s/it\n","Train loss 24588 0.543330 Grad Norm 1.469718 0.12s/it\n","Train loss 24589 0.393540 Grad Norm 0.891535 0.12s/it\n","Train loss 24590 0.834152 Grad Norm 2.785555 0.11s/it\n","Train loss 24591 0.808229 Grad Norm 3.861250 0.13s/it\n","Train loss 24592 0.351453 Grad Norm 1.402401 0.12s/it\n","Train loss 24593 0.616123 Grad Norm 4.118439 0.11s/it\n","Train loss 24594 0.504289 Grad Norm 1.646530 0.11s/it\n","Train loss 24595 0.725145 Grad Norm 1.572941 0.12s/it\n","Train loss 24596 0.505887 Grad Norm 1.546891 0.10s/it\n","Train loss 24597 0.752717 Grad Norm 1.506601 0.10s/it\n","Train loss 24598 0.577310 Grad Norm 1.438035 0.12s/it\n","Train loss 24599 0.719842 Grad Norm 3.587338 0.10s/it\n","Train loss 24600 0.337586 Grad Norm 1.684073 0.10s/it\n","Train loss 24601 0.712757 Grad Norm 1.941213 0.13s/it\n","Train loss 24602 0.711334 Grad Norm 1.683620 0.12s/it\n","Train loss 24603 0.519127 Grad Norm 0.981242 0.15s/it\n","Train loss 24604 0.532550 Grad Norm 0.969429 0.15s/it\n","Train loss 24605 0.487035 Grad Norm 0.728871 0.13s/it\n","Train loss 24606 0.645512 Grad Norm 1.075259 0.13s/it\n","Train loss 24607 0.370785 Grad Norm 0.563077 0.12s/it\n","Train loss 24608 0.472678 Grad Norm 1.402010 0.12s/it\n","Train loss 24609 0.463148 Grad Norm 1.589006 0.10s/it\n","Train loss 24610 0.544619 Grad Norm 1.610625 0.10s/it\n","Train loss 24611 0.432062 Grad Norm 0.870313 0.12s/it\n","Train loss 24612 0.922822 Grad Norm 1.859200 0.12s/it\n","Train loss 24613 0.335958 Grad Norm 0.413381 0.13s/it\n","Train loss 24614 0.385556 Grad Norm 1.136671 0.12s/it\n","Train loss 24615 0.695303 Grad Norm 2.020167 0.12s/it\n","Train loss 24616 0.359148 Grad Norm 1.282221 0.13s/it\n","Train loss 24617 0.591391 Grad Norm 2.447294 0.09s/it\n","Train loss 24618 0.670538 Grad Norm 1.528198 0.12s/it\n","Train loss 24619 0.827837 Grad Norm 2.022752 0.12s/it\n","Train loss 24620 0.573065 Grad Norm 0.908273 0.13s/it\n","Train loss 24621 0.497405 Grad Norm 1.381559 0.12s/it\n","Train loss 24622 0.570461 Grad Norm 3.435822 0.12s/it\n","Train loss 24623 0.444273 Grad Norm 1.686460 0.11s/it\n","Train loss 24624 0.555144 Grad Norm 0.865694 0.12s/it\n","Train loss 24625 0.840878 Grad Norm 3.938968 0.13s/it\n","Train loss 24626 0.713510 Grad Norm 1.913705 0.13s/it\n","Train loss 24627 0.782686 Grad Norm 2.583806 0.11s/it\n","Train loss 24628 0.664003 Grad Norm 1.124902 0.12s/it\n","Train loss 24629 0.864992 Grad Norm 1.696519 0.12s/it\n","Train loss 24630 0.702339 Grad Norm 0.896923 0.12s/it\n","Train loss 24631 0.337554 Grad Norm 0.529781 0.10s/it\n","Train loss 24632 0.641428 Grad Norm 1.101032 0.13s/it\n","Train loss 24633 0.606360 Grad Norm 1.094564 0.13s/it\n","Train loss 24634 0.775145 Grad Norm 2.392316 0.10s/it\n","Train loss 24635 0.401362 Grad Norm 0.691238 0.14s/it\n","Train loss 24636 0.539409 Grad Norm 1.130972 0.11s/it\n","Train loss 24637 0.743011 Grad Norm 1.746103 0.12s/it\n","Train loss 24638 0.471542 Grad Norm 1.516058 0.09s/it\n","Train loss 24639 0.582437 Grad Norm 1.615427 0.11s/it\n","Train loss 24640 0.409937 Grad Norm 0.852296 0.12s/it\n","Train loss 24641 0.498442 Grad Norm 1.837738 0.13s/it\n","Train loss 24642 0.547185 Grad Norm 1.570464 0.12s/it\n","Train loss 24643 0.631972 Grad Norm 1.382769 0.12s/it\n","Train loss 24644 0.715019 Grad Norm 1.143842 0.10s/it\n","Train loss 24645 0.462216 Grad Norm 1.078292 0.13s/it\n","Train loss 24646 0.537832 Grad Norm 1.257242 0.12s/it\n","Train loss 24647 0.539661 Grad Norm 0.691402 0.12s/it\n","Train loss 24648 0.387528 Grad Norm 1.063910 0.14s/it\n","Train loss 24649 0.420878 Grad Norm 0.824479 0.12s/it\n","Train loss 24650 0.586131 Grad Norm 1.261366 0.09s/it\n","Train loss 24651 0.664062 Grad Norm 1.555626 0.12s/it\n","Train loss 24652 0.399131 Grad Norm 0.916864 0.11s/it\n","Train loss 24653 0.607463 Grad Norm 2.550413 0.13s/it\n","Train loss 24654 0.532667 Grad Norm 1.462714 0.11s/it\n","Train loss 24655 0.297038 Grad Norm 0.707907 0.13s/it\n","Train loss 24656 0.583947 Grad Norm 1.357334 0.12s/it\n","Train loss 24657 0.446773 Grad Norm 1.573964 0.12s/it\n","Train loss 24658 0.615363 Grad Norm 1.690244 0.11s/it\n","Train loss 24659 0.649728 Grad Norm 1.730534 0.14s/it\n","Train loss 24660 0.436814 Grad Norm 1.469044 0.12s/it\n","Train loss 24661 0.286895 Grad Norm 0.431683 0.15s/it\n","Train loss 24662 0.760076 Grad Norm 1.215978 0.13s/it\n","Train loss 24663 0.723878 Grad Norm 1.589570 0.14s/it\n","Train loss 24664 0.668429 Grad Norm 2.084300 0.13s/it\n","Train loss 24665 0.357706 Grad Norm 1.024290 0.13s/it\n","Train loss 24666 0.548780 Grad Norm 0.913362 0.10s/it\n","Train loss 24667 0.626462 Grad Norm 1.031383 0.14s/it\n","Train loss 24668 0.283033 Grad Norm 1.589885 0.11s/it\n","Train loss 24669 0.355627 Grad Norm 0.829601 0.12s/it\n","Train loss 24670 0.449367 Grad Norm 1.124623 0.13s/it\n","Train loss 24671 0.513259 Grad Norm 1.415664 0.12s/it\n","Train loss 24672 0.668272 Grad Norm 1.320408 0.13s/it\n","Train loss 24673 0.550721 Grad Norm 1.651087 0.13s/it\n","Train loss 24674 0.501907 Grad Norm 0.871000 0.13s/it\n","Train loss 24675 0.395583 Grad Norm 1.111084 0.14s/it\n","Train loss 24676 0.546124 Grad Norm 3.684891 0.11s/it\n","Train loss 24677 0.524806 Grad Norm 1.143326 0.12s/it\n","Train loss 24678 0.492907 Grad Norm 1.630015 0.13s/it\n","Train loss 24679 0.589091 Grad Norm 0.791596 0.12s/it\n","Train loss 24680 0.590820 Grad Norm 1.108296 0.13s/it\n","Train loss 24681 0.627381 Grad Norm 1.474600 0.11s/it\n","Train loss 24682 0.529281 Grad Norm 1.528178 0.13s/it\n","Train loss 24683 0.698364 Grad Norm 1.129907 0.12s/it\n","Train loss 24684 0.476743 Grad Norm 2.194578 0.10s/it\n","Train loss 24685 0.469027 Grad Norm 1.141932 0.15s/it\n","Train loss 24686 0.456711 Grad Norm 1.127204 0.12s/it\n","Train loss 24687 0.488365 Grad Norm 1.312602 0.09s/it\n","Train loss 24688 0.343308 Grad Norm 0.673183 0.12s/it\n","Train loss 24689 0.547030 Grad Norm 1.059040 0.11s/it\n","Train loss 24690 0.357013 Grad Norm 0.910135 0.12s/it\n","Train loss 24691 0.452813 Grad Norm 0.979217 0.13s/it\n","Train loss 24692 0.372136 Grad Norm 1.391772 0.10s/it\n","Train loss 24693 0.638133 Grad Norm 2.417427 0.13s/it\n","Train loss 24694 0.401022 Grad Norm 0.923974 0.10s/it\n","Train loss 24695 0.520753 Grad Norm 1.783764 0.13s/it\n","Train loss 24696 0.507187 Grad Norm 1.735667 0.13s/it\n","Train loss 24697 0.652560 Grad Norm 2.515615 0.12s/it\n","Train loss 24698 0.468549 Grad Norm 1.455753 0.15s/it\n","Train loss 24699 0.653938 Grad Norm 1.291488 0.13s/it\n","Train loss 24700 0.533669 Grad Norm 0.934735 0.11s/it\n","Train loss 24701 0.354717 Grad Norm 0.934990 0.12s/it\n","Train loss 24702 0.427502 Grad Norm 0.667828 0.15s/it\n","Train loss 24703 0.707169 Grad Norm 2.560891 0.13s/it\n","Train loss 24704 0.524935 Grad Norm 2.347914 0.13s/it\n","Train loss 24705 0.367052 Grad Norm 1.154040 0.12s/it\n","Train loss 24706 0.744624 Grad Norm 2.310663 0.11s/it\n","Train loss 24707 0.503749 Grad Norm 1.650149 0.11s/it\n","Train loss 24708 0.406842 Grad Norm 0.583026 0.12s/it\n","Train loss 24709 0.499391 Grad Norm 1.051085 0.14s/it\n","Train loss 24710 0.607672 Grad Norm 1.754564 0.12s/it\n","Train loss 24711 0.647420 Grad Norm 1.427225 0.13s/it\n","Train loss 24712 0.476538 Grad Norm 1.540448 0.12s/it\n","Train loss 24713 0.490472 Grad Norm 2.457249 0.12s/it\n","Train loss 24714 0.501651 Grad Norm 1.171550 0.14s/it\n","Train loss 24715 0.441128 Grad Norm 1.053001 0.17s/it\n","Train loss 24716 0.597603 Grad Norm 3.560102 0.13s/it\n","Train loss 24717 0.511480 Grad Norm 0.777675 0.15s/it\n","Train loss 24718 0.726120 Grad Norm 1.767755 0.13s/it\n","Train loss 24719 0.516910 Grad Norm 2.205014 0.12s/it\n","Train loss 24720 0.511875 Grad Norm 1.497409 0.12s/it\n","Train loss 24721 0.534271 Grad Norm 1.686525 0.10s/it\n","Train loss 24722 0.615602 Grad Norm 2.523805 0.13s/it\n","Train loss 24723 0.493453 Grad Norm 1.388556 0.10s/it\n","Train loss 24724 0.367265 Grad Norm 0.785716 0.12s/it\n","Train loss 24725 0.407930 Grad Norm 1.802023 0.10s/it\n","Train loss 24726 0.552473 Grad Norm 3.372590 0.12s/it\n","Train loss 24727 0.614694 Grad Norm 1.382924 0.12s/it\n","Train loss 24728 0.661040 Grad Norm 1.880759 0.12s/it\n","Train loss 24729 0.485572 Grad Norm 0.915726 0.13s/it\n","Train loss 24730 0.316178 Grad Norm 0.907839 0.11s/it\n","Train loss 24731 0.422457 Grad Norm 0.555510 0.11s/it\n","Train loss 24732 0.706076 Grad Norm 3.375827 0.11s/it\n","Train loss 24733 0.600001 Grad Norm 1.281297 0.11s/it\n","Train loss 24734 0.538881 Grad Norm 1.552762 0.12s/it\n","Train loss 24735 0.835544 Grad Norm 3.362279 0.12s/it\n","Train loss 24736 0.558980 Grad Norm 1.730465 0.15s/it\n","Train loss 24737 0.808403 Grad Norm 3.513590 0.13s/it\n","Train loss 24738 0.532510 Grad Norm 1.428249 0.12s/it\n","Train loss 24739 0.496969 Grad Norm 1.091258 0.11s/it\n","Train loss 24740 0.602513 Grad Norm 0.954084 0.13s/it\n","Train loss 24741 0.427057 Grad Norm 0.830988 0.16s/it\n","Train loss 24742 0.387170 Grad Norm 0.757487 0.15s/it\n","Train loss 24743 0.857392 Grad Norm 3.540524 0.11s/it\n","Train loss 24744 0.530105 Grad Norm 0.877713 0.11s/it\n","Train loss 24745 0.571463 Grad Norm 1.046585 0.14s/it\n","Train loss 24746 0.491423 Grad Norm 1.335635 0.12s/it\n","Train loss 24747 0.546434 Grad Norm 1.883653 0.13s/it\n","Train loss 24748 0.752782 Grad Norm 1.498346 0.13s/it\n","Train loss 24749 0.698400 Grad Norm 2.202337 0.11s/it\n","Train loss 24750 0.557817 Grad Norm 1.939372 0.11s/it\n","Train loss 24751 0.708977 Grad Norm 2.650895 0.12s/it\n","Train loss 24752 0.557481 Grad Norm 1.008549 0.13s/it\n","Train loss 24753 0.626631 Grad Norm 1.603341 0.12s/it\n","Train loss 24754 0.430383 Grad Norm 1.053912 0.11s/it\n","Train loss 24755 0.547915 Grad Norm 2.143245 0.13s/it\n","Train loss 24756 0.589292 Grad Norm 1.235773 0.14s/it\n","Train loss 24757 0.672856 Grad Norm 2.290329 0.11s/it\n","Train loss 24758 0.511922 Grad Norm 2.437463 0.11s/it\n","Train loss 24759 0.579763 Grad Norm 2.776296 0.15s/it\n","Train loss 24760 0.850444 Grad Norm 1.600160 0.12s/it\n","Train loss 24761 0.777057 Grad Norm 1.106525 0.12s/it\n","Train loss 24762 0.760267 Grad Norm 1.766261 0.10s/it\n","Train loss 24763 0.642107 Grad Norm 2.663700 0.11s/it\n","Train loss 24764 0.511969 Grad Norm 1.861804 0.12s/it\n","Train loss 24765 0.963615 Grad Norm 5.318378 0.11s/it\n","Train loss 24766 0.459314 Grad Norm 0.484540 0.12s/it\n","Train loss 24767 0.647458 Grad Norm 1.225740 0.11s/it\n","Train loss 24768 0.573727 Grad Norm 0.872674 0.12s/it\n","Train loss 24769 0.390406 Grad Norm 0.651258 0.15s/it\n","Train loss 24770 0.554285 Grad Norm 3.355493 0.12s/it\n","Train loss 24771 0.487564 Grad Norm 1.046234 0.13s/it\n","Train loss 24772 0.395694 Grad Norm 1.968059 0.14s/it\n","Train loss 24773 0.768577 Grad Norm 3.493377 0.11s/it\n","Train loss 24774 0.879304 Grad Norm 2.573050 0.13s/it\n","Train loss 24775 0.715203 Grad Norm 1.743286 0.12s/it\n","Train loss 24776 0.549844 Grad Norm 0.955359 0.14s/it\n","Train loss 24777 0.420935 Grad Norm 0.993233 0.12s/it\n","Train loss 24778 0.348816 Grad Norm 1.100033 0.13s/it\n","Train loss 24779 0.980434 Grad Norm 3.577005 0.10s/it\n","Train loss 24780 0.335047 Grad Norm 0.698599 0.10s/it\n","Train loss 24781 0.483919 Grad Norm 0.739846 0.11s/it\n","Train loss 24782 0.591460 Grad Norm 1.077871 0.12s/it\n","Train loss 24783 0.490849 Grad Norm 1.148690 0.12s/it\n","Train loss 24784 0.225974 Grad Norm 0.548085 0.13s/it\n","Train loss 24785 0.592175 Grad Norm 1.636594 0.13s/it\n","Train loss 24786 0.268547 Grad Norm 0.478983 0.14s/it\n","Train loss 24787 0.503512 Grad Norm 3.506039 0.11s/it\n","Train loss 24788 0.544095 Grad Norm 1.884587 0.11s/it\n","Train loss 24789 0.368573 Grad Norm 1.193503 0.12s/it\n","Train loss 24790 0.607265 Grad Norm 1.204377 0.11s/it\n","Train loss 24791 0.509292 Grad Norm 1.616528 0.14s/it\n","Train loss 24792 0.522242 Grad Norm 1.182431 0.14s/it\n","Train loss 24793 0.439761 Grad Norm 0.504331 0.14s/it\n","Train loss 24794 0.514912 Grad Norm 0.648044 0.13s/it\n","Train loss 24795 0.507679 Grad Norm 1.530795 0.15s/it\n","Train loss 24796 0.599395 Grad Norm 0.935794 0.11s/it\n","Train loss 24797 0.562531 Grad Norm 0.697532 0.14s/it\n","Train loss 24798 0.546661 Grad Norm 1.211576 0.12s/it\n","Train loss 24799 0.517840 Grad Norm 1.759475 0.10s/it\n","Train loss 24800 0.512352 Grad Norm 0.931074 0.11s/it\n","Train loss 24801 0.549035 Grad Norm 1.215384 0.12s/it\n","Train loss 24802 0.522206 Grad Norm 1.095602 0.11s/it\n","Train loss 24803 0.581514 Grad Norm 1.614701 0.16s/it\n","Train loss 24804 0.335261 Grad Norm 1.073162 0.15s/it\n","Train loss 24805 0.655462 Grad Norm 1.183398 0.12s/it\n","Train loss 24806 0.421193 Grad Norm 0.923586 0.12s/it\n","Train loss 24807 0.485028 Grad Norm 1.206563 0.13s/it\n","Train loss 24808 0.545380 Grad Norm 1.989936 0.13s/it\n","Train loss 24809 0.490415 Grad Norm 1.051356 0.13s/it\n","Train loss 24810 0.503946 Grad Norm 2.886892 0.12s/it\n","Train loss 24811 0.666284 Grad Norm 3.608047 0.13s/it\n","Train loss 24812 0.695153 Grad Norm 1.534880 0.12s/it\n","Train loss 24813 0.235829 Grad Norm 0.390513 0.14s/it\n","Train loss 24814 0.553607 Grad Norm 1.897420 0.14s/it\n","Train loss 24815 0.440237 Grad Norm 1.324485 0.12s/it\n","Train loss 24816 0.529715 Grad Norm 0.765884 0.12s/it\n","Train loss 24817 0.538846 Grad Norm 0.861083 0.14s/it\n","Train loss 24818 0.454723 Grad Norm 0.850657 0.11s/it\n","Train loss 24819 0.566641 Grad Norm 1.273024 0.13s/it\n","Train loss 24820 0.646840 Grad Norm 1.791394 0.11s/it\n","Train loss 24821 0.500416 Grad Norm 1.689512 0.14s/it\n","Train loss 24822 0.726453 Grad Norm 2.354631 0.11s/it\n","Train loss 24823 0.534654 Grad Norm 1.826191 0.13s/it\n","Train loss 24824 0.709681 Grad Norm 1.260041 0.11s/it\n","Train loss 24825 0.615349 Grad Norm 1.544274 0.11s/it\n","Train loss 24826 0.457153 Grad Norm 0.919725 0.15s/it\n","Train loss 24827 0.502702 Grad Norm 1.514078 0.11s/it\n","Train loss 24828 0.444642 Grad Norm 0.787843 0.15s/it\n","Train loss 24829 0.650010 Grad Norm 1.014586 0.12s/it\n","Train loss 24830 0.624934 Grad Norm 1.531909 0.12s/it\n","Train loss 24831 0.635730 Grad Norm 1.912615 0.12s/it\n","Train loss 24832 0.350410 Grad Norm 0.840303 0.14s/it\n","Train loss 24833 0.522695 Grad Norm 3.043557 0.14s/it\n","Train loss 24834 0.656638 Grad Norm 2.225839 0.10s/it\n","Train loss 24835 0.489800 Grad Norm 0.820933 0.13s/it\n","Train loss 24836 0.448560 Grad Norm 0.783641 0.11s/it\n","Train loss 24837 0.394207 Grad Norm 1.115096 0.11s/it\n","Train loss 24838 0.375807 Grad Norm 0.988291 0.11s/it\n","Train loss 24839 0.359067 Grad Norm 0.560186 0.12s/it\n","Train loss 24840 0.529311 Grad Norm 1.999421 0.13s/it\n","Train loss 24841 0.478924 Grad Norm 1.421245 0.14s/it\n","Train loss 24842 0.412656 Grad Norm 1.050798 0.14s/it\n","Train loss 24843 0.487085 Grad Norm 0.900165 0.11s/it\n","Train loss 24844 0.484974 Grad Norm 1.414091 0.11s/it\n","Train loss 24845 0.408965 Grad Norm 0.610155 0.14s/it\n","Train loss 24846 0.487698 Grad Norm 0.699480 0.13s/it\n","Train loss 24847 0.354738 Grad Norm 1.544422 0.12s/it\n","Train loss 24848 0.552927 Grad Norm 3.272993 0.11s/it\n","Train loss 24849 0.618506 Grad Norm 3.802864 0.10s/it\n","Train loss 24850 0.651360 Grad Norm 1.452486 0.11s/it\n","Train loss 24851 0.572040 Grad Norm 2.089796 0.12s/it\n","Train loss 24852 0.544842 Grad Norm 2.354306 0.14s/it\n","Train loss 24853 0.383702 Grad Norm 0.726210 0.12s/it\n","Train loss 24854 0.693445 Grad Norm 1.276208 0.12s/it\n","Train loss 24855 0.635285 Grad Norm 1.425590 0.12s/it\n","Train loss 24856 0.506748 Grad Norm 2.109061 0.13s/it\n","Train loss 24857 0.475990 Grad Norm 2.239661 0.11s/it\n","Train loss 24858 0.524980 Grad Norm 1.587398 0.12s/it\n","Train loss 24859 0.894299 Grad Norm 1.594491 0.12s/it\n","Train loss 24860 0.887782 Grad Norm 3.364356 0.12s/it\n","Train loss 24861 0.476630 Grad Norm 1.655534 0.12s/it\n","Train loss 24862 0.468887 Grad Norm 1.682086 0.12s/it\n","Train loss 24863 0.393963 Grad Norm 0.606233 0.13s/it\n","Train loss 24864 0.473923 Grad Norm 1.075539 0.12s/it\n","Train loss 24865 0.561645 Grad Norm 1.007394 0.11s/it\n","Train loss 24866 0.627117 Grad Norm 1.601796 0.11s/it\n","Train loss 24867 0.639442 Grad Norm 1.990423 0.14s/it\n","Train loss 24868 0.426105 Grad Norm 1.378480 0.13s/it\n","Train loss 24869 0.461784 Grad Norm 1.491106 0.13s/it\n","Train loss 24870 0.609698 Grad Norm 2.923767 0.12s/it\n","Train loss 24871 0.679917 Grad Norm 1.550161 0.13s/it\n","Train loss 24872 0.576447 Grad Norm 1.686881 0.13s/it\n","Train loss 24873 0.441549 Grad Norm 0.947429 0.13s/it\n","Train loss 24874 0.445951 Grad Norm 1.015437 0.13s/it\n","Train loss 24875 0.676868 Grad Norm 1.470263 0.12s/it\n","Train loss 24876 0.373414 Grad Norm 1.668458 0.12s/it\n","Train loss 24877 0.588493 Grad Norm 0.998738 0.12s/it\n","Train loss 24878 0.334895 Grad Norm 1.097869 0.13s/it\n","Train loss 24879 0.405154 Grad Norm 1.641472 0.14s/it\n","Train loss 24880 0.522893 Grad Norm 1.138683 0.12s/it\n","Train loss 24881 0.431979 Grad Norm 0.850774 0.11s/it\n","Train loss 24882 0.432491 Grad Norm 0.965467 0.11s/it\n","Train loss 24883 0.334663 Grad Norm 0.511330 0.12s/it\n","Train loss 24884 0.490411 Grad Norm 4.633510 0.11s/it\n","Train loss 24885 0.621813 Grad Norm 3.667886 0.11s/it\n","Train loss 24886 0.393919 Grad Norm 1.117698 0.15s/it\n","Train loss 24887 0.484254 Grad Norm 0.763562 0.13s/it\n","Train loss 24888 0.658682 Grad Norm 1.371480 0.11s/it\n","Train loss 24889 0.902606 Grad Norm 3.071987 0.13s/it\n","Train loss 24890 0.779309 Grad Norm 3.604792 0.12s/it\n","Train loss 24891 0.787421 Grad Norm 1.329568 0.11s/it\n","Train loss 24892 0.481512 Grad Norm 2.868748 0.13s/it\n","Train loss 24893 0.641485 Grad Norm 2.696766 0.12s/it\n","Train loss 24894 0.285247 Grad Norm 0.659968 0.12s/it\n","Train loss 24895 0.520810 Grad Norm 0.842491 0.13s/it\n","Train loss 24896 0.350668 Grad Norm 0.637926 0.15s/it\n","Train loss 24897 0.402778 Grad Norm 1.235812 0.14s/it\n","Train loss 24898 0.441602 Grad Norm 0.722878 0.14s/it\n","Train loss 24899 0.617952 Grad Norm 2.169303 0.11s/it\n","Train loss 24900 0.541792 Grad Norm 1.307420 0.13s/it\n","Train loss 24901 0.446796 Grad Norm 1.815493 0.12s/it\n","Train loss 24902 0.636572 Grad Norm 1.545629 0.15s/it\n","Train loss 24903 0.307091 Grad Norm 0.415551 0.12s/it\n","Train loss 24904 0.692902 Grad Norm 1.786607 0.11s/it\n","Train loss 24905 0.387373 Grad Norm 0.477685 0.14s/it\n","Train loss 24906 0.333133 Grad Norm 0.603777 0.11s/it\n","Train loss 24907 0.544891 Grad Norm 3.566326 0.10s/it\n","Train loss 24908 0.444633 Grad Norm 1.611899 0.11s/it\n","Train loss 24909 0.363342 Grad Norm 0.719200 0.13s/it\n","Train loss 24910 0.545511 Grad Norm 1.174845 0.12s/it\n","Train loss 24911 0.438372 Grad Norm 0.868604 0.11s/it\n","Train loss 24912 0.523537 Grad Norm 1.024345 0.14s/it\n","Train loss 24913 0.585550 Grad Norm 1.004259 0.14s/it\n","Train loss 24914 0.519761 Grad Norm 1.195641 0.12s/it\n","Train loss 24915 0.617208 Grad Norm 1.978629 0.13s/it\n","Train loss 24916 0.565920 Grad Norm 1.926005 0.11s/it\n","Train loss 24917 0.578396 Grad Norm 5.355932 0.12s/it\n","Train loss 24918 0.477739 Grad Norm 1.475640 0.14s/it\n","Train loss 24919 0.630193 Grad Norm 2.502131 0.12s/it\n","Train loss 24920 0.585148 Grad Norm 1.503157 0.15s/it\n","Train loss 24921 0.545585 Grad Norm 1.202645 0.13s/it\n","Train loss 24922 0.411294 Grad Norm 1.566734 0.15s/it\n","Train loss 24923 0.961902 Grad Norm 2.531510 0.12s/it\n","Train loss 24924 0.871846 Grad Norm 2.341172 0.13s/it\n","Train loss 24925 0.215117 Grad Norm 0.447694 0.14s/it\n","Train loss 24926 0.497235 Grad Norm 3.186654 0.13s/it\n","Train loss 24927 0.624251 Grad Norm 2.916452 0.11s/it\n","Train loss 24928 0.630907 Grad Norm 1.372642 0.11s/it\n","Train loss 24929 0.578798 Grad Norm 1.792244 0.11s/it\n","Train loss 24930 0.335119 Grad Norm 1.061738 0.15s/it\n","Train loss 24931 0.638301 Grad Norm 1.217045 0.14s/it\n","Train loss 24932 0.457458 Grad Norm 1.122427 0.12s/it\n","Train loss 24933 0.301131 Grad Norm 0.744162 0.23s/it\n","Train loss 24934 0.543144 Grad Norm 1.695156 0.16s/it\n","Train loss 24935 0.492762 Grad Norm 1.223752 0.14s/it\n","Train loss 24936 0.641613 Grad Norm 1.986096 0.12s/it\n","Train loss 24937 0.861727 Grad Norm 3.385090 0.11s/it\n","Train loss 24938 0.628735 Grad Norm 6.190006 0.11s/it\n","Train loss 24939 0.513082 Grad Norm 1.111124 0.12s/it\n","Train loss 24940 0.492812 Grad Norm 2.235993 0.10s/it\n","Train loss 24941 0.634128 Grad Norm 1.457134 0.13s/it\n","Train loss 24942 0.600819 Grad Norm 1.712607 0.11s/it\n","Train loss 24943 0.376937 Grad Norm 1.716180 0.12s/it\n","Train loss 24944 0.505118 Grad Norm 1.145328 0.13s/it\n","Train loss 24945 0.347124 Grad Norm 0.675821 0.11s/it\n","Train loss 24946 0.433753 Grad Norm 0.684339 0.17s/it\n","Train loss 24947 0.477373 Grad Norm 0.975891 0.16s/it\n","Train loss 24948 0.276809 Grad Norm 0.458058 0.13s/it\n","Train loss 24949 0.437678 Grad Norm 2.380347 0.13s/it\n","Train loss 24950 0.452039 Grad Norm 2.097314 0.11s/it\n","Train loss 24951 0.483613 Grad Norm 0.965328 0.12s/it\n","Train loss 24952 0.470622 Grad Norm 0.860635 0.11s/it\n","Train loss 24953 0.825449 Grad Norm 5.751497 0.11s/it\n","Train loss 24954 0.496074 Grad Norm 3.056859 0.11s/it\n","Train loss 24955 0.405512 Grad Norm 1.136102 0.13s/it\n","Train loss 24956 0.638664 Grad Norm 3.112848 0.14s/it\n","Train loss 24957 0.578259 Grad Norm 2.613397 0.11s/it\n","Train loss 24958 0.455900 Grad Norm 1.927817 0.12s/it\n","Train loss 24959 0.372426 Grad Norm 1.520945 0.13s/it\n","Train loss 24960 0.587236 Grad Norm 1.610448 0.10s/it\n","Train loss 24961 0.592289 Grad Norm 2.568483 0.12s/it\n","Train loss 24962 0.306028 Grad Norm 0.600261 0.14s/it\n","Train loss 24963 0.463807 Grad Norm 1.138827 0.11s/it\n","Train loss 24964 0.489388 Grad Norm 3.507446 0.14s/it\n","Train loss 24965 0.637761 Grad Norm 2.814262 0.15s/it\n","Train loss 24966 0.753215 Grad Norm 2.484003 0.13s/it\n","Train loss 24967 0.343315 Grad Norm 0.708320 0.14s/it\n","Train loss 24968 0.621104 Grad Norm 1.848540 0.15s/it\n","Train loss 24969 0.311632 Grad Norm 3.948213 0.13s/it\n","Train loss 24970 0.535440 Grad Norm 2.128628 0.12s/it\n","Train loss 24971 0.456949 Grad Norm 1.212323 0.10s/it\n","Train loss 24972 0.472971 Grad Norm 0.813300 0.16s/it\n","Train loss 24973 0.379176 Grad Norm 0.965717 0.15s/it\n","Train loss 24974 0.484357 Grad Norm 0.995104 0.16s/it\n","Train loss 24975 0.414076 Grad Norm 2.849829 0.13s/it\n","Train loss 24976 0.392518 Grad Norm 1.381613 0.13s/it\n","Train loss 24977 0.477948 Grad Norm 1.088127 0.13s/it\n","Train loss 24978 0.502593 Grad Norm 0.837368 0.11s/it\n","Train loss 24979 0.710579 Grad Norm 3.449989 0.13s/it\n","Train loss 24980 0.567157 Grad Norm 1.684734 0.15s/it\n","Train loss 24981 0.911833 Grad Norm 1.895715 0.13s/it\n","Train loss 24982 0.408630 Grad Norm 1.331657 0.11s/it\n","Train loss 24983 0.563663 Grad Norm 1.231110 0.11s/it\n","Train loss 24984 0.552107 Grad Norm 2.728019 0.14s/it\n","Train loss 24985 0.714884 Grad Norm 2.104208 0.13s/it\n","Train loss 24986 0.490864 Grad Norm 1.448044 0.11s/it\n","Train loss 24987 0.637149 Grad Norm 2.281279 0.12s/it\n","Train loss 24988 0.417578 Grad Norm 1.718593 0.10s/it\n","Train loss 24989 0.476858 Grad Norm 1.868901 0.11s/it\n","Train loss 24990 0.511211 Grad Norm 1.007507 0.13s/it\n","Train loss 24991 0.737034 Grad Norm 1.925961 0.14s/it\n","Train loss 24992 0.475257 Grad Norm 0.980513 0.12s/it\n","Train loss 24993 0.390897 Grad Norm 1.123932 0.14s/it\n","Train loss 24994 0.408151 Grad Norm 0.904119 0.10s/it\n","Train loss 24995 0.671713 Grad Norm 1.691191 0.12s/it\n","Train loss 24996 0.616903 Grad Norm 1.314185 0.11s/it\n","Train loss 24997 0.417935 Grad Norm 0.853017 0.16s/it\n","Train loss 24998 0.581189 Grad Norm 1.382932 0.12s/it\n","Train loss 24999 0.379540 Grad Norm 1.037197 0.12s/it\n","Train loss 25000 0.437575 Grad Norm 1.022421 0.15s/it\n","Validation loss 25000: 0.398832\n","Saving model and optimizer state at iteration 25000 to checkpoint_25000\n","Train loss 25001 0.520841 Grad Norm 1.078893 0.15s/it\n","Train loss 25002 0.608919 Grad Norm 1.124650 0.12s/it\n","Train loss 25003 0.494123 Grad Norm 1.460847 0.14s/it\n","Train loss 25004 0.535390 Grad Norm 1.150356 0.10s/it\n","Train loss 25005 0.496426 Grad Norm 1.654209 0.15s/it\n","Train loss 25006 0.504243 Grad Norm 0.835589 0.11s/it\n","Train loss 25007 0.536767 Grad Norm 1.697839 0.12s/it\n","Train loss 25008 0.425373 Grad Norm 0.888339 0.13s/it\n","Train loss 25009 0.570482 Grad Norm 1.839153 0.12s/it\n","Train loss 25010 0.586348 Grad Norm 0.864123 0.12s/it\n","Train loss 25011 0.618378 Grad Norm 1.400467 0.13s/it\n","Train loss 25012 0.631837 Grad Norm 1.653775 0.15s/it\n","Train loss 25013 0.243389 Grad Norm 0.441278 0.14s/it\n","Train loss 25014 0.699717 Grad Norm 1.640885 0.11s/it\n","Train loss 25015 0.420490 Grad Norm 1.193327 0.10s/it\n","Train loss 25016 0.505443 Grad Norm 0.510435 0.11s/it\n","Train loss 25017 0.421005 Grad Norm 0.922441 0.15s/it\n","Train loss 25018 0.455417 Grad Norm 1.666585 0.15s/it\n","Train loss 25019 0.337904 Grad Norm 1.671858 0.14s/it\n","Train loss 25020 0.350149 Grad Norm 0.465519 0.15s/it\n","Train loss 25021 0.511814 Grad Norm 2.157317 0.13s/it\n","Train loss 25022 0.366196 Grad Norm 0.795003 0.12s/it\n","Train loss 25023 0.529450 Grad Norm 1.380045 0.12s/it\n","Train loss 25024 0.778231 Grad Norm 2.641107 0.11s/it\n","Train loss 25025 0.490496 Grad Norm 0.995633 0.12s/it\n","Train loss 25026 0.503469 Grad Norm 1.612658 0.11s/it\n","Train loss 25027 0.526719 Grad Norm 1.079407 0.13s/it\n","Train loss 25028 0.426860 Grad Norm 1.588404 0.11s/it\n","Train loss 25029 0.679128 Grad Norm 2.288753 0.12s/it\n","Train loss 25030 0.423023 Grad Norm 2.216712 0.11s/it\n","Train loss 25031 0.417729 Grad Norm 1.702299 0.14s/it\n","Train loss 25032 0.724475 Grad Norm 2.608972 0.12s/it\n","Train loss 25033 0.531485 Grad Norm 0.935969 0.15s/it\n","Train loss 25034 0.494395 Grad Norm 1.866246 0.13s/it\n","Train loss 25035 0.517131 Grad Norm 1.425633 0.12s/it\n","Train loss 25036 0.444948 Grad Norm 1.012304 0.14s/it\n","Train loss 25037 0.707396 Grad Norm 1.736177 0.14s/it\n","Train loss 25038 0.390466 Grad Norm 1.463823 0.11s/it\n","Train loss 25039 0.494312 Grad Norm 1.152849 0.13s/it\n","Train loss 25040 0.687158 Grad Norm 1.512879 0.12s/it\n","Train loss 25041 0.909984 Grad Norm 2.592451 0.13s/it\n","Train loss 25042 0.572680 Grad Norm 2.496143 0.14s/it\n","Train loss 25043 0.405196 Grad Norm 0.760432 0.14s/it\n","Train loss 25044 0.389169 Grad Norm 0.591650 0.14s/it\n","Train loss 25045 0.480844 Grad Norm 1.240343 0.13s/it\n","Train loss 25046 0.513902 Grad Norm 0.974823 0.11s/it\n","Train loss 25047 0.372145 Grad Norm 1.668101 0.14s/it\n","Train loss 25048 0.435271 Grad Norm 0.920267 0.13s/it\n","Train loss 25049 0.552260 Grad Norm 1.263165 0.11s/it\n","Train loss 25050 0.433149 Grad Norm 1.114549 0.11s/it\n","Train loss 25051 0.517779 Grad Norm 1.128443 0.12s/it\n","Train loss 25052 0.516912 Grad Norm 1.265567 0.13s/it\n","Train loss 25053 0.436077 Grad Norm 0.971326 0.13s/it\n","Train loss 25054 0.810820 Grad Norm 1.610099 0.12s/it\n","Train loss 25055 0.707056 Grad Norm 1.282443 0.13s/it\n","Train loss 25056 0.536554 Grad Norm 0.883073 0.15s/it\n","Train loss 25057 0.705485 Grad Norm 1.830995 0.12s/it\n","Train loss 25058 0.512812 Grad Norm 1.128714 0.15s/it\n","Train loss 25059 0.506922 Grad Norm 0.830041 0.10s/it\n","Train loss 25060 0.264515 Grad Norm 1.098311 0.14s/it\n","Train loss 25061 0.582771 Grad Norm 2.651032 0.12s/it\n","Train loss 25062 0.845982 Grad Norm 1.483665 0.10s/it\n","Train loss 25063 0.829249 Grad Norm 1.107684 0.14s/it\n","Train loss 25064 0.428009 Grad Norm 1.327091 0.10s/it\n","Train loss 25065 0.696484 Grad Norm 1.814929 0.10s/it\n","Train loss 25066 0.431885 Grad Norm 0.673433 0.16s/it\n","Train loss 25067 0.617978 Grad Norm 1.373183 0.15s/it\n","Train loss 25068 0.573160 Grad Norm 0.834040 0.13s/it\n","Train loss 25069 0.402908 Grad Norm 0.898293 0.10s/it\n","Train loss 25070 0.523896 Grad Norm 1.507845 0.14s/it\n","Train loss 25071 0.548044 Grad Norm 1.303445 0.11s/it\n","Train loss 25072 0.665926 Grad Norm 3.109409 0.10s/it\n","Train loss 25073 0.528616 Grad Norm 1.281865 0.13s/it\n","Train loss 25074 0.408463 Grad Norm 1.502268 0.13s/it\n","Train loss 25075 0.785000 Grad Norm 1.140623 0.12s/it\n","Train loss 25076 0.305024 Grad Norm 0.302469 0.12s/it\n","Train loss 25077 0.441455 Grad Norm 1.434849 0.13s/it\n","Train loss 25078 0.418308 Grad Norm 0.726411 0.14s/it\n","Train loss 25079 0.442630 Grad Norm 1.219059 0.14s/it\n","Train loss 25080 0.524229 Grad Norm 1.263695 0.11s/it\n","Train loss 25081 0.400146 Grad Norm 0.980663 0.13s/it\n","Train loss 25082 0.388850 Grad Norm 1.257746 0.12s/it\n","Train loss 25083 0.545254 Grad Norm 1.571376 0.10s/it\n","Train loss 25084 0.480740 Grad Norm 0.778764 0.12s/it\n","Train loss 25085 0.742992 Grad Norm 1.473694 0.13s/it\n","Train loss 25086 0.767226 Grad Norm 2.833461 0.12s/it\n","Train loss 25087 0.443869 Grad Norm 1.268858 0.12s/it\n","Train loss 25088 0.633626 Grad Norm 1.205971 0.11s/it\n","Train loss 25089 0.513207 Grad Norm 1.743893 0.11s/it\n","Train loss 25090 0.624590 Grad Norm 1.470462 0.11s/it\n","Train loss 25091 0.422576 Grad Norm 1.212630 0.13s/it\n","Train loss 25092 0.460885 Grad Norm 2.441177 0.15s/it\n","Train loss 25093 0.508136 Grad Norm 1.185154 0.16s/it\n","Train loss 25094 0.396991 Grad Norm 1.423378 0.12s/it\n","Train loss 25095 0.644147 Grad Norm 3.433080 0.12s/it\n","Train loss 25096 0.622487 Grad Norm 1.977666 0.13s/it\n","Train loss 25097 0.475536 Grad Norm 0.988344 0.12s/it\n","Train loss 25098 0.459663 Grad Norm 0.615752 0.15s/it\n","Train loss 25099 0.488966 Grad Norm 0.801428 0.12s/it\n","Train loss 25100 0.365562 Grad Norm 1.302163 0.14s/it\n","Train loss 25101 0.432016 Grad Norm 0.677607 0.17s/it\n","Train loss 25102 0.531801 Grad Norm 2.531994 0.13s/it\n","Train loss 25103 0.552311 Grad Norm 0.994694 0.12s/it\n","Train loss 25104 0.380926 Grad Norm 0.596368 0.13s/it\n","Train loss 25105 0.418793 Grad Norm 0.625577 0.14s/it\n","Train loss 25106 0.892333 Grad Norm 3.792779 0.12s/it\n","Train loss 25107 0.445066 Grad Norm 1.242456 0.12s/it\n","Train loss 25108 0.623219 Grad Norm 1.164900 0.11s/it\n","Train loss 25109 0.414326 Grad Norm 1.274425 0.12s/it\n","Train loss 25110 0.793081 Grad Norm 2.254411 0.12s/it\n","Train loss 25111 0.466946 Grad Norm 1.451849 0.10s/it\n","Train loss 25112 0.402277 Grad Norm 2.004828 0.12s/it\n","Train loss 25113 0.627838 Grad Norm 2.102053 0.11s/it\n","Train loss 25114 0.589011 Grad Norm 1.156588 0.14s/it\n","Train loss 25115 0.583981 Grad Norm 1.716355 0.11s/it\n","Train loss 25116 0.571818 Grad Norm 2.263349 0.11s/it\n","Train loss 25117 0.567373 Grad Norm 3.097219 0.13s/it\n","Train loss 25118 0.631961 Grad Norm 1.690470 0.13s/it\n","Train loss 25119 0.657327 Grad Norm 1.196366 0.14s/it\n","Train loss 25120 0.514262 Grad Norm 1.180586 0.14s/it\n","Train loss 25121 0.353700 Grad Norm 1.230205 0.14s/it\n","Train loss 25122 0.501306 Grad Norm 1.336203 0.11s/it\n","Train loss 25123 0.453315 Grad Norm 1.547027 0.10s/it\n","Train loss 25124 0.739652 Grad Norm 2.863022 0.10s/it\n","Train loss 25125 0.505323 Grad Norm 0.958771 0.16s/it\n","Train loss 25126 0.657544 Grad Norm 1.612976 0.10s/it\n","Train loss 25127 0.586198 Grad Norm 2.414318 0.12s/it\n","Train loss 25128 0.437570 Grad Norm 3.114700 0.12s/it\n","Train loss 25129 0.625076 Grad Norm 1.874545 0.10s/it\n","Train loss 25130 0.506117 Grad Norm 1.724796 0.13s/it\n","Train loss 25131 0.424076 Grad Norm 0.781824 0.14s/it\n","Train loss 25132 0.495252 Grad Norm 1.592986 0.15s/it\n","Train loss 25133 0.414228 Grad Norm 0.899735 0.11s/it\n","Train loss 25134 0.392948 Grad Norm 1.155438 0.12s/it\n","Train loss 25135 0.393558 Grad Norm 0.782187 0.16s/it\n","Train loss 25136 0.507415 Grad Norm 2.246922 0.12s/it\n","Train loss 25137 0.531464 Grad Norm 1.305469 0.12s/it\n","Train loss 25138 0.455139 Grad Norm 1.143448 0.13s/it\n","Train loss 25139 0.627637 Grad Norm 1.483202 0.10s/it\n","Train loss 25140 0.567102 Grad Norm 2.840581 0.11s/it\n","Train loss 25141 0.510743 Grad Norm 1.411160 0.13s/it\n","Train loss 25142 0.761216 Grad Norm 1.124538 0.12s/it\n","Train loss 25143 0.868411 Grad Norm 2.247208 0.13s/it\n","Train loss 25144 0.608080 Grad Norm 1.592625 0.12s/it\n","Train loss 25145 0.548126 Grad Norm 1.824276 0.13s/it\n","Train loss 25146 0.694939 Grad Norm 2.951921 0.13s/it\n","Train loss 25147 0.429750 Grad Norm 1.401095 0.12s/it\n","Train loss 25148 0.428915 Grad Norm 0.856163 0.12s/it\n","Train loss 25149 0.498864 Grad Norm 2.336672 0.11s/it\n","Train loss 25150 0.435941 Grad Norm 1.406555 0.15s/it\n","Train loss 25151 0.639905 Grad Norm 1.410726 0.14s/it\n","Train loss 25152 0.737859 Grad Norm 2.633281 0.10s/it\n","Train loss 25153 0.545274 Grad Norm 1.135872 0.13s/it\n","Train loss 25154 0.642077 Grad Norm 1.491042 0.14s/it\n","Train loss 25155 0.368151 Grad Norm 0.779724 0.18s/it\n","Train loss 25156 0.438400 Grad Norm 0.880591 0.11s/it\n","Train loss 25157 0.804439 Grad Norm 2.208719 0.12s/it\n","Train loss 25158 0.522225 Grad Norm 0.956033 0.12s/it\n","Train loss 25159 0.462970 Grad Norm 1.075751 0.13s/it\n","Train loss 25160 0.565345 Grad Norm 2.274265 0.10s/it\n","Train loss 25161 0.474181 Grad Norm 1.124174 0.14s/it\n","Train loss 25162 0.686907 Grad Norm 2.630110 0.11s/it\n","Train loss 25163 0.462279 Grad Norm 1.127225 0.14s/it\n","Train loss 25164 0.605819 Grad Norm 2.034654 0.11s/it\n","Train loss 25165 0.588531 Grad Norm 1.387163 0.12s/it\n","Train loss 25166 0.564771 Grad Norm 1.358244 0.13s/it\n","Train loss 25167 0.734003 Grad Norm 1.460120 0.13s/it\n","Train loss 25168 0.596829 Grad Norm 2.534455 0.11s/it\n","Train loss 25169 0.583819 Grad Norm 2.592264 0.13s/it\n","Train loss 25170 0.345122 Grad Norm 1.464493 0.12s/it\n","Train loss 25171 0.451704 Grad Norm 1.361710 0.13s/it\n","Train loss 25172 0.405273 Grad Norm 1.119185 0.12s/it\n","Train loss 25173 0.320243 Grad Norm 0.633766 0.12s/it\n","Train loss 25174 0.748569 Grad Norm 2.924270 0.12s/it\n","Train loss 25175 0.457136 Grad Norm 0.953880 0.12s/it\n","Train loss 25176 0.985606 Grad Norm 2.522257 0.13s/it\n","Train loss 25177 0.690915 Grad Norm 2.311546 0.13s/it\n","Train loss 25178 0.464470 Grad Norm 0.898202 0.14s/it\n","Train loss 25179 0.469481 Grad Norm 1.374098 0.15s/it\n","Train loss 25180 0.736766 Grad Norm 1.995724 0.13s/it\n","Train loss 25181 0.344537 Grad Norm 1.540711 0.11s/it\n","Train loss 25182 0.575815 Grad Norm 0.775052 0.14s/it\n","Train loss 25183 0.482200 Grad Norm 1.232115 0.11s/it\n","Train loss 25184 0.574231 Grad Norm 1.126097 0.14s/it\n","Train loss 25185 0.622504 Grad Norm 3.512550 0.11s/it\n","Train loss 25186 0.502461 Grad Norm 0.639322 0.10s/it\n","Train loss 25187 0.509643 Grad Norm 1.150550 0.12s/it\n","Train loss 25188 0.699113 Grad Norm 1.682769 0.15s/it\n","Train loss 25189 0.517510 Grad Norm 1.315462 0.15s/it\n","Train loss 25190 0.403486 Grad Norm 0.768520 0.12s/it\n","Train loss 25191 0.518714 Grad Norm 0.742947 0.14s/it\n","Train loss 25192 0.598710 Grad Norm 0.976238 0.12s/it\n","Train loss 25193 0.385892 Grad Norm 1.289883 0.14s/it\n","Train loss 25194 0.775448 Grad Norm 3.289532 0.12s/it\n","Train loss 25195 0.409478 Grad Norm 0.636774 0.12s/it\n","Train loss 25196 0.351142 Grad Norm 0.946927 0.16s/it\n","Train loss 25197 0.456616 Grad Norm 0.941435 0.15s/it\n","Train loss 25198 0.857961 Grad Norm 2.096424 0.11s/it\n","Train loss 25199 0.399280 Grad Norm 1.613470 0.12s/it\n","Train loss 25200 0.560084 Grad Norm 1.372848 0.11s/it\n","Train loss 25201 0.919822 Grad Norm 1.619796 0.12s/it\n","Train loss 25202 0.389819 Grad Norm 0.758092 0.13s/it\n","Train loss 25203 0.644944 Grad Norm 1.090553 0.12s/it\n","Train loss 25204 0.446221 Grad Norm 1.515974 0.12s/it\n","Train loss 25205 0.493118 Grad Norm 1.299998 0.12s/it\n","Train loss 25206 0.785314 Grad Norm 1.671949 0.13s/it\n","Train loss 25207 0.245733 Grad Norm 0.421784 0.13s/it\n","Train loss 25208 0.636217 Grad Norm 1.270171 0.12s/it\n","Train loss 25209 0.540713 Grad Norm 1.502821 0.13s/it\n","Train loss 25210 0.667197 Grad Norm 1.976882 0.13s/it\n","Train loss 25211 0.418720 Grad Norm 0.813482 0.11s/it\n","Train loss 25212 0.611785 Grad Norm 3.258870 0.12s/it\n","Train loss 25213 0.458988 Grad Norm 1.482030 0.16s/it\n","Train loss 25214 0.892280 Grad Norm 2.893854 0.10s/it\n","Train loss 25215 0.555459 Grad Norm 1.281446 0.13s/it\n","Train loss 25216 0.432987 Grad Norm 0.964175 0.11s/it\n","Train loss 25217 0.657517 Grad Norm 1.803326 0.10s/it\n","Train loss 25218 0.508786 Grad Norm 0.895522 0.14s/it\n","Train loss 25219 0.428935 Grad Norm 1.900041 0.15s/it\n","Train loss 25220 0.625862 Grad Norm 1.883585 0.15s/it\n","Train loss 25221 0.376770 Grad Norm 0.823173 0.13s/it\n","Train loss 25222 0.500395 Grad Norm 1.024689 0.13s/it\n","Train loss 25223 0.502046 Grad Norm 2.192757 0.13s/it\n","Train loss 25224 0.713632 Grad Norm 2.784959 0.13s/it\n","Train loss 25225 0.469886 Grad Norm 1.329298 0.12s/it\n","Train loss 25226 0.546583 Grad Norm 1.461178 0.12s/it\n","Train loss 25227 0.431781 Grad Norm 0.757617 0.14s/it\n","Train loss 25228 0.399304 Grad Norm 1.702657 0.12s/it\n","Train loss 25229 0.793581 Grad Norm 2.682163 0.13s/it\n","Train loss 25230 0.462277 Grad Norm 1.326708 0.14s/it\n","Train loss 25231 0.624748 Grad Norm 1.827860 0.12s/it\n","Train loss 25232 0.586738 Grad Norm 1.307651 0.11s/it\n","Train loss 25233 0.473747 Grad Norm 0.775340 0.10s/it\n","Train loss 25234 0.730834 Grad Norm 3.434703 0.14s/it\n","Train loss 25235 0.545966 Grad Norm 1.406473 0.16s/it\n","Train loss 25236 0.484648 Grad Norm 0.771583 0.15s/it\n","Train loss 25237 0.584066 Grad Norm 1.105641 0.14s/it\n","Train loss 25238 0.344744 Grad Norm 0.781789 0.13s/it\n","Train loss 25239 0.369572 Grad Norm 0.927746 0.12s/it\n","Train loss 25240 0.462559 Grad Norm 0.568486 0.14s/it\n","Train loss 25241 0.382470 Grad Norm 0.580253 0.12s/it\n","Train loss 25242 0.564175 Grad Norm 1.942878 0.13s/it\n","Train loss 25243 0.613937 Grad Norm 1.661040 0.12s/it\n","Train loss 25244 0.518840 Grad Norm 0.932081 0.12s/it\n","Train loss 25245 0.329003 Grad Norm 0.979503 0.12s/it\n","Train loss 25246 0.553876 Grad Norm 2.112948 0.11s/it\n","Train loss 25247 0.903768 Grad Norm 2.583935 0.14s/it\n","Train loss 25248 0.638506 Grad Norm 1.902099 0.15s/it\n","Train loss 25249 0.861346 Grad Norm 2.304121 0.12s/it\n","Train loss 25250 0.647827 Grad Norm 0.920995 0.13s/it\n","Train loss 25251 0.698532 Grad Norm 2.096924 0.13s/it\n","Train loss 25252 0.387602 Grad Norm 1.132938 0.16s/it\n","Train loss 25253 0.601039 Grad Norm 2.556727 0.13s/it\n","Train loss 25254 0.605037 Grad Norm 1.932690 0.11s/it\n","Train loss 25255 0.437222 Grad Norm 1.311771 0.14s/it\n","Train loss 25256 0.479034 Grad Norm 1.836616 0.11s/it\n","Train loss 25257 0.505286 Grad Norm 1.001047 0.12s/it\n","Train loss 25258 0.478783 Grad Norm 0.957112 0.12s/it\n","Train loss 25259 0.395644 Grad Norm 2.335719 0.11s/it\n","Train loss 25260 0.456706 Grad Norm 2.084716 0.10s/it\n","Train loss 25261 0.423802 Grad Norm 1.019718 0.12s/it\n","Train loss 25262 0.507171 Grad Norm 2.686262 0.13s/it\n","Train loss 25263 0.433649 Grad Norm 0.805921 0.11s/it\n","Train loss 25264 0.542958 Grad Norm 2.671061 0.12s/it\n","Train loss 25265 0.477567 Grad Norm 0.948543 0.12s/it\n","Train loss 25266 0.409289 Grad Norm 4.542224 0.14s/it\n","Train loss 25267 0.658983 Grad Norm 2.076157 0.11s/it\n","Train loss 25268 0.455946 Grad Norm 1.089512 0.15s/it\n","Train loss 25269 0.551866 Grad Norm 2.468216 0.11s/it\n","Train loss 25270 0.913119 Grad Norm 3.038597 0.13s/it\n","Train loss 25271 0.875038 Grad Norm 1.740108 0.13s/it\n","Train loss 25272 0.354302 Grad Norm 0.738675 0.15s/it\n","Train loss 25273 0.724795 Grad Norm 1.085606 0.11s/it\n","Train loss 25274 0.418416 Grad Norm 1.385471 0.13s/it\n","Train loss 25275 0.426459 Grad Norm 0.926547 0.12s/it\n","Train loss 25276 0.528892 Grad Norm 1.004760 0.10s/it\n","Train loss 25277 0.635694 Grad Norm 1.357729 0.09s/it\n","Train loss 25278 0.573201 Grad Norm 2.651790 0.12s/it\n","Train loss 25279 0.296348 Grad Norm 0.819763 0.11s/it\n","Train loss 25280 0.479045 Grad Norm 0.651222 0.12s/it\n","Train loss 25281 0.686447 Grad Norm 1.577969 0.12s/it\n","Train loss 25282 0.399352 Grad Norm 1.012280 0.14s/it\n","Train loss 25283 0.639421 Grad Norm 2.194108 0.12s/it\n","Train loss 25284 0.420307 Grad Norm 1.011133 0.12s/it\n","Train loss 25285 0.633389 Grad Norm 2.357533 0.12s/it\n","Train loss 25286 0.734741 Grad Norm 2.555753 0.11s/it\n","Train loss 25287 0.445787 Grad Norm 0.907876 0.13s/it\n","Train loss 25288 0.401138 Grad Norm 1.194939 0.13s/it\n","Train loss 25289 0.525157 Grad Norm 1.421302 0.13s/it\n","Train loss 25290 0.777923 Grad Norm 1.997222 0.13s/it\n","Train loss 25291 0.467057 Grad Norm 1.095018 0.12s/it\n","Train loss 25292 0.511828 Grad Norm 0.489647 0.14s/it\n","Train loss 25293 0.722895 Grad Norm 1.619673 0.12s/it\n","Train loss 25294 0.407410 Grad Norm 0.835687 0.11s/it\n","Train loss 25295 0.700594 Grad Norm 1.298218 0.14s/it\n","Train loss 25296 0.580400 Grad Norm 1.581491 0.10s/it\n","Train loss 25297 0.611967 Grad Norm 1.785062 0.10s/it\n","Train loss 25298 0.804070 Grad Norm 2.349947 0.11s/it\n","Train loss 25299 0.745194 Grad Norm 1.555292 0.13s/it\n","Train loss 25300 0.610039 Grad Norm 1.814588 0.12s/it\n","Train loss 25301 0.381073 Grad Norm 2.538287 0.12s/it\n","Train loss 25302 0.714862 Grad Norm 2.248095 0.12s/it\n","Train loss 25303 0.866938 Grad Norm 2.466805 0.11s/it\n","Train loss 25304 0.502823 Grad Norm 5.026075 0.12s/it\n","Train loss 25305 0.308281 Grad Norm 0.609982 0.12s/it\n","Train loss 25306 0.593599 Grad Norm 1.659054 0.14s/it\n","Train loss 25307 0.635582 Grad Norm 1.742131 0.13s/it\n","Train loss 25308 0.399274 Grad Norm 0.825310 0.15s/it\n","Train loss 25309 0.429872 Grad Norm 1.738697 0.11s/it\n","Train loss 25310 0.571319 Grad Norm 0.934492 0.13s/it\n","Train loss 25311 0.892132 Grad Norm 2.362602 0.14s/it\n","Train loss 25312 0.519350 Grad Norm 1.211429 0.15s/it\n","Train loss 25313 0.570470 Grad Norm 1.655430 0.13s/it\n","Train loss 25314 0.809180 Grad Norm 2.616475 0.14s/it\n","Train loss 25315 0.400060 Grad Norm 0.640321 0.14s/it\n","Train loss 25316 0.521946 Grad Norm 0.937592 0.11s/it\n","Train loss 25317 0.568092 Grad Norm 1.047773 0.14s/it\n","Train loss 25318 0.753174 Grad Norm 2.873395 0.11s/it\n","Train loss 25319 0.836115 Grad Norm 1.313877 0.12s/it\n","Train loss 25320 0.354429 Grad Norm 0.909632 0.14s/it\n","Train loss 25321 0.283303 Grad Norm 0.920900 0.13s/it\n","Train loss 25322 0.507835 Grad Norm 0.690669 0.12s/it\n","Train loss 25323 0.544627 Grad Norm 3.291351 0.14s/it\n","Train loss 25324 0.603608 Grad Norm 1.096499 0.12s/it\n","Train loss 25325 0.578385 Grad Norm 1.127676 0.13s/it\n","Train loss 25326 0.455193 Grad Norm 1.205039 0.12s/it\n","Train loss 25327 0.702893 Grad Norm 2.381351 0.11s/it\n","Train loss 25328 0.477012 Grad Norm 1.094247 0.12s/it\n","Train loss 25329 0.579763 Grad Norm 1.984090 0.10s/it\n","Train loss 25330 0.599143 Grad Norm 1.243573 0.11s/it\n","Train loss 25331 0.478582 Grad Norm 1.309208 0.10s/it\n","Train loss 25332 0.485513 Grad Norm 2.795164 0.15s/it\n","Train loss 25333 0.622371 Grad Norm 2.728690 0.12s/it\n","Train loss 25334 0.690538 Grad Norm 2.454818 0.14s/it\n","Train loss 25335 0.502714 Grad Norm 1.873437 0.13s/it\n","Train loss 25336 0.571431 Grad Norm 3.891708 0.13s/it\n","Train loss 25337 0.533697 Grad Norm 1.495635 0.13s/it\n","Train loss 25338 0.398894 Grad Norm 0.580977 0.12s/it\n","Train loss 25339 0.288791 Grad Norm 0.471805 0.14s/it\n","Train loss 25340 0.448916 Grad Norm 2.532091 0.10s/it\n","Train loss 25341 0.502934 Grad Norm 2.050022 0.16s/it\n","Train loss 25342 0.496400 Grad Norm 1.067705 0.12s/it\n","Train loss 25343 0.468622 Grad Norm 1.998758 0.13s/it\n","Train loss 25344 0.555204 Grad Norm 2.580222 0.13s/it\n","Train loss 25345 0.574418 Grad Norm 1.567856 0.12s/it\n","Train loss 25346 0.659660 Grad Norm 2.771684 0.13s/it\n","Train loss 25347 0.448288 Grad Norm 2.836722 0.13s/it\n","Train loss 25348 0.683922 Grad Norm 1.988421 0.10s/it\n","Train loss 25349 0.511232 Grad Norm 0.707049 0.11s/it\n","Train loss 25350 0.355852 Grad Norm 1.493988 0.13s/it\n","Train loss 25351 0.584385 Grad Norm 2.398903 0.09s/it\n","Train loss 25352 0.359306 Grad Norm 1.017348 0.12s/it\n","Train loss 25353 0.496295 Grad Norm 1.175890 0.12s/it\n","Train loss 25354 0.514756 Grad Norm 1.225123 0.11s/it\n","Train loss 25355 0.332226 Grad Norm 1.237343 0.13s/it\n","Train loss 25356 0.742361 Grad Norm 2.191903 0.14s/it\n","Train loss 25357 0.632136 Grad Norm 2.465674 0.11s/it\n","Train loss 25358 0.479326 Grad Norm 1.337526 0.10s/it\n","Train loss 25359 0.504212 Grad Norm 1.214587 0.12s/it\n","Train loss 25360 0.576658 Grad Norm 1.332083 0.11s/it\n","Train loss 25361 0.578496 Grad Norm 1.079824 0.13s/it\n","Train loss 25362 0.560281 Grad Norm 1.007840 0.11s/it\n","Train loss 25363 0.501043 Grad Norm 4.539045 0.10s/it\n","Train loss 25364 0.587892 Grad Norm 1.019001 0.11s/it\n","Train loss 25365 0.473811 Grad Norm 1.794115 0.10s/it\n","Train loss 25366 0.480981 Grad Norm 1.316848 0.10s/it\n","Train loss 25367 0.570154 Grad Norm 3.275303 0.14s/it\n","Train loss 25368 0.476273 Grad Norm 2.882995 0.15s/it\n","Train loss 25369 0.730173 Grad Norm 1.209754 0.10s/it\n","Train loss 25370 0.452591 Grad Norm 3.544015 0.10s/it\n","Train loss 25371 0.459797 Grad Norm 1.575067 0.10s/it\n","Train loss 25372 0.547799 Grad Norm 1.485765 0.12s/it\n","Train loss 25373 0.613319 Grad Norm 2.296577 0.12s/it\n","Train loss 25374 0.571626 Grad Norm 1.194450 0.15s/it\n","Train loss 25375 0.523988 Grad Norm 1.117377 0.10s/it\n","Train loss 25376 0.438935 Grad Norm 4.875626 0.09s/it\n","Train loss 25377 0.420529 Grad Norm 0.434222 0.13s/it\n","Train loss 25378 0.685649 Grad Norm 2.042104 0.11s/it\n","Train loss 25379 0.563991 Grad Norm 2.231888 0.16s/it\n","Train loss 25380 0.633426 Grad Norm 1.822608 0.12s/it\n","Train loss 25381 0.433195 Grad Norm 1.152877 0.11s/it\n","Train loss 25382 0.474295 Grad Norm 1.441833 0.12s/it\n","Train loss 25383 0.483762 Grad Norm 1.352443 0.12s/it\n","Train loss 25384 0.308778 Grad Norm 1.251444 0.10s/it\n","Train loss 25385 0.612768 Grad Norm 1.469592 0.11s/it\n","Train loss 25386 0.508173 Grad Norm 1.061761 0.13s/it\n","Train loss 25387 0.649621 Grad Norm 0.958666 0.12s/it\n","Train loss 25388 0.570765 Grad Norm 2.392442 0.11s/it\n","Train loss 25389 0.502938 Grad Norm 1.994528 0.12s/it\n","Train loss 25390 0.447222 Grad Norm 1.465651 0.12s/it\n","Train loss 25391 0.627241 Grad Norm 1.115921 0.12s/it\n","Train loss 25392 0.451904 Grad Norm 1.110615 0.12s/it\n","Train loss 25393 0.592622 Grad Norm 1.692593 0.12s/it\n","Train loss 25394 0.624243 Grad Norm 1.082980 0.11s/it\n","Train loss 25395 0.661633 Grad Norm 1.964923 0.12s/it\n","Train loss 25396 0.418740 Grad Norm 1.398593 0.14s/it\n","Train loss 25397 0.685556 Grad Norm 2.189111 0.12s/it\n","Train loss 25398 0.544980 Grad Norm 0.929809 0.16s/it\n","Train loss 25399 0.706952 Grad Norm 2.859085 0.13s/it\n","Train loss 25400 0.526665 Grad Norm 1.857811 0.10s/it\n","Train loss 25401 0.416205 Grad Norm 0.878541 0.13s/it\n","Train loss 25402 0.623324 Grad Norm 1.529298 0.12s/it\n","Train loss 25403 0.622871 Grad Norm 1.751597 0.11s/it\n","Train loss 25404 0.496808 Grad Norm 0.865036 0.12s/it\n","Train loss 25405 0.581677 Grad Norm 1.833827 0.12s/it\n","Train loss 25406 0.385583 Grad Norm 0.691740 0.09s/it\n","Train loss 25407 0.645779 Grad Norm 3.155437 0.15s/it\n","Train loss 25408 0.775721 Grad Norm 3.792342 0.13s/it\n","Train loss 25409 0.758930 Grad Norm 2.759650 0.10s/it\n","Train loss 25410 0.779440 Grad Norm 5.719706 0.14s/it\n","Train loss 25411 0.571265 Grad Norm 1.576112 0.13s/it\n","Train loss 25412 0.572995 Grad Norm 1.022003 0.11s/it\n","Train loss 25413 0.404148 Grad Norm 1.288429 0.14s/it\n","Train loss 25414 0.526260 Grad Norm 1.437653 0.11s/it\n","Train loss 25415 0.468429 Grad Norm 1.582496 0.13s/it\n","Train loss 25416 0.686087 Grad Norm 2.631137 0.12s/it\n","Train loss 25417 0.587041 Grad Norm 0.798009 0.14s/it\n","Train loss 25418 0.516387 Grad Norm 2.882311 0.09s/it\n","Train loss 25419 0.392126 Grad Norm 1.016995 0.13s/it\n","Train loss 25420 0.552899 Grad Norm 1.395858 0.15s/it\n","Train loss 25421 0.387319 Grad Norm 0.796429 0.15s/it\n","Train loss 25422 0.502985 Grad Norm 1.659526 0.15s/it\n","Train loss 25423 0.469370 Grad Norm 1.271678 0.12s/it\n","Train loss 25424 0.370190 Grad Norm 0.447071 0.13s/it\n","Train loss 25425 0.501817 Grad Norm 3.093236 0.12s/it\n","Train loss 25426 0.489408 Grad Norm 1.813679 0.13s/it\n","Train loss 25427 0.485045 Grad Norm 9.387558 0.13s/it\n","Train loss 25428 0.693291 Grad Norm 1.543080 0.15s/it\n","Train loss 25429 0.553327 Grad Norm 2.050076 0.10s/it\n","Train loss 25430 0.679868 Grad Norm 1.670828 0.12s/it\n","Train loss 25431 0.293298 Grad Norm 0.332536 0.13s/it\n","Train loss 25432 0.633157 Grad Norm 1.687964 0.10s/it\n","Train loss 25433 0.746069 Grad Norm 3.611045 0.12s/it\n","Train loss 25434 0.492212 Grad Norm 1.778939 0.12s/it\n","Train loss 25435 0.510983 Grad Norm 1.178037 0.12s/it\n","Train loss 25436 0.459985 Grad Norm 1.045734 0.12s/it\n","Train loss 25437 0.494561 Grad Norm 1.179407 0.12s/it\n","Train loss 25438 0.495799 Grad Norm 1.659670 0.12s/it\n","Train loss 25439 0.349084 Grad Norm 1.099578 0.13s/it\n","Train loss 25440 0.628466 Grad Norm 1.108872 0.16s/it\n","Train loss 25441 0.521654 Grad Norm 1.964314 0.13s/it\n","Train loss 25442 0.348956 Grad Norm 0.613223 0.12s/it\n","Train loss 25443 0.369336 Grad Norm 2.060930 0.14s/it\n","Train loss 25444 0.492264 Grad Norm 2.636740 0.12s/it\n","Train loss 25445 0.411958 Grad Norm 0.997248 0.13s/it\n","Train loss 25446 0.344795 Grad Norm 0.578592 0.12s/it\n","Train loss 25447 0.649061 Grad Norm 2.256617 0.13s/it\n","Train loss 25448 0.565842 Grad Norm 1.336274 0.12s/it\n","Train loss 25449 0.422708 Grad Norm 1.081109 0.11s/it\n","Train loss 25450 0.696557 Grad Norm 1.453946 0.14s/it\n","Train loss 25451 0.663713 Grad Norm 1.655401 0.12s/it\n","Train loss 25452 0.651346 Grad Norm 2.087019 0.12s/it\n","Train loss 25453 0.464766 Grad Norm 0.930629 0.12s/it\n","Train loss 25454 0.461405 Grad Norm 0.878901 0.12s/it\n","Train loss 25455 0.473296 Grad Norm 1.707919 0.12s/it\n","Train loss 25456 0.574096 Grad Norm 3.326861 0.12s/it\n","Train loss 25457 0.747275 Grad Norm 1.272207 0.13s/it\n","Train loss 25458 0.553736 Grad Norm 1.537248 0.13s/it\n","Train loss 25459 0.517126 Grad Norm 0.825726 0.13s/it\n","Train loss 25460 0.564294 Grad Norm 1.802940 0.12s/it\n","Train loss 25461 0.586952 Grad Norm 1.495666 0.12s/it\n","Train loss 25462 0.496951 Grad Norm 1.348579 0.13s/it\n","Train loss 25463 0.538733 Grad Norm 1.194503 0.12s/it\n","Train loss 25464 0.504146 Grad Norm 0.879117 0.12s/it\n","Train loss 25465 0.472788 Grad Norm 0.737175 0.12s/it\n","Train loss 25466 0.384150 Grad Norm 0.583877 0.14s/it\n","Train loss 25467 0.629249 Grad Norm 1.267732 0.13s/it\n","Train loss 25468 0.374695 Grad Norm 0.820878 0.11s/it\n","Train loss 25469 0.691433 Grad Norm 1.585130 0.12s/it\n","Train loss 25470 0.638826 Grad Norm 1.133508 0.11s/it\n","Train loss 25471 0.988698 Grad Norm 3.016144 0.11s/it\n","Train loss 25472 0.657735 Grad Norm 3.745876 0.12s/it\n","Train loss 25473 0.379813 Grad Norm 0.660385 0.13s/it\n","Train loss 25474 0.343985 Grad Norm 0.728630 0.13s/it\n","Train loss 25475 0.582324 Grad Norm 1.125610 0.13s/it\n","Train loss 25476 0.415412 Grad Norm 1.032115 0.14s/it\n","Train loss 25477 0.456297 Grad Norm 2.109343 0.11s/it\n","Train loss 25478 0.447867 Grad Norm 1.165670 0.13s/it\n","Train loss 25479 0.391444 Grad Norm 0.975872 0.13s/it\n","Train loss 25480 1.029873 Grad Norm 1.979080 0.11s/it\n","Train loss 25481 0.653328 Grad Norm 0.945972 0.11s/it\n","Train loss 25482 0.516027 Grad Norm 2.248675 0.12s/it\n","Train loss 25483 0.285661 Grad Norm 0.440229 0.14s/it\n","Train loss 25484 0.479031 Grad Norm 0.913604 0.14s/it\n","Train loss 25485 0.658763 Grad Norm 1.569442 0.13s/it\n","Train loss 25486 0.636932 Grad Norm 1.132324 0.12s/it\n","Train loss 25487 0.456735 Grad Norm 1.217813 0.11s/it\n","Train loss 25488 0.288181 Grad Norm 0.502644 0.10s/it\n","Train loss 25489 0.370296 Grad Norm 1.002860 0.14s/it\n","Train loss 25490 0.366209 Grad Norm 0.419174 0.15s/it\n","Train loss 25491 0.650061 Grad Norm 1.528578 0.11s/it\n","Train loss 25492 0.382158 Grad Norm 0.569401 0.12s/it\n","Train loss 25493 0.534707 Grad Norm 3.204220 0.13s/it\n","Train loss 25494 0.736565 Grad Norm 1.794593 0.15s/it\n","Train loss 25495 0.423119 Grad Norm 0.957492 0.14s/it\n","Train loss 25496 0.694089 Grad Norm 1.280414 0.11s/it\n","Train loss 25497 0.606406 Grad Norm 2.273196 0.13s/it\n","Train loss 25498 0.856374 Grad Norm 1.251606 0.13s/it\n","Train loss 25499 0.634651 Grad Norm 1.380766 0.13s/it\n","Train loss 25500 0.677289 Grad Norm 4.252273 0.11s/it\n","Train loss 25501 0.587588 Grad Norm 3.955465 0.13s/it\n","Train loss 25502 0.351459 Grad Norm 2.466202 0.13s/it\n","Train loss 25503 0.478793 Grad Norm 0.938151 0.12s/it\n","Train loss 25504 0.564718 Grad Norm 1.557268 0.14s/it\n","Train loss 25505 0.645743 Grad Norm 1.637222 0.14s/it\n","Train loss 25506 0.548891 Grad Norm 1.567736 0.12s/it\n","Train loss 25507 0.469237 Grad Norm 1.105012 0.14s/it\n","Train loss 25508 0.561809 Grad Norm 1.125819 0.12s/it\n","Train loss 25509 0.490300 Grad Norm 1.224378 0.11s/it\n","Train loss 25510 0.373179 Grad Norm 0.524851 0.11s/it\n","Train loss 25511 0.543051 Grad Norm 2.636300 0.12s/it\n","Train loss 25512 0.506076 Grad Norm 1.732687 0.14s/it\n","Train loss 25513 0.702104 Grad Norm 0.911661 0.14s/it\n","Train loss 25514 0.760658 Grad Norm 2.590387 0.11s/it\n","Train loss 25515 0.390816 Grad Norm 0.777286 0.14s/it\n","Train loss 25516 0.552202 Grad Norm 2.257983 0.10s/it\n","Train loss 25517 0.410548 Grad Norm 2.695473 0.12s/it\n","Train loss 25518 0.717798 Grad Norm 1.308123 0.12s/it\n","Train loss 25519 0.516250 Grad Norm 2.346685 0.12s/it\n","Train loss 25520 0.334163 Grad Norm 0.776441 0.14s/it\n","Train loss 25521 0.625598 Grad Norm 5.316586 0.13s/it\n","Train loss 25522 0.517016 Grad Norm 1.433185 0.14s/it\n","Train loss 25523 0.540316 Grad Norm 1.415430 0.13s/it\n","Train loss 25524 0.913874 Grad Norm 1.904579 0.12s/it\n","Train loss 25525 0.626073 Grad Norm 1.510214 0.13s/it\n","Train loss 25526 0.754496 Grad Norm 2.787334 0.12s/it\n","Train loss 25527 0.480377 Grad Norm 4.684458 0.13s/it\n","Train loss 25528 0.479629 Grad Norm 1.412936 0.14s/it\n","Train loss 25529 0.727230 Grad Norm 1.807031 0.11s/it\n","Train loss 25530 0.787865 Grad Norm 1.416514 0.13s/it\n","Train loss 25531 0.549227 Grad Norm 0.697324 0.14s/it\n","Train loss 25532 0.312408 Grad Norm 0.513692 0.11s/it\n","Train loss 25533 0.511082 Grad Norm 1.440044 0.13s/it\n","Train loss 25534 0.635145 Grad Norm 2.585567 0.11s/it\n","Train loss 25535 0.899414 Grad Norm 1.599011 0.11s/it\n","Train loss 25536 0.473395 Grad Norm 1.562892 0.12s/it\n","Train loss 25537 0.832002 Grad Norm 1.271147 0.12s/it\n","Train loss 25538 0.401657 Grad Norm 0.813694 0.10s/it\n","Train loss 25539 1.044562 Grad Norm 2.692303 0.10s/it\n","Train loss 25540 0.701257 Grad Norm 0.948552 0.11s/it\n","Train loss 25541 0.342459 Grad Norm 1.129764 0.13s/it\n","Train loss 25542 0.320044 Grad Norm 0.817376 0.10s/it\n","Train loss 25543 0.456678 Grad Norm 0.946657 0.11s/it\n","Train loss 25544 0.647285 Grad Norm 0.798543 0.13s/it\n","Train loss 25545 0.512623 Grad Norm 1.301267 0.11s/it\n","Train loss 25546 0.632567 Grad Norm 1.888003 0.11s/it\n","Train loss 25547 0.455621 Grad Norm 1.183254 0.14s/it\n","Train loss 25548 0.440552 Grad Norm 0.902005 0.11s/it\n","Train loss 25549 0.976323 Grad Norm 3.258761 0.14s/it\n","Train loss 25550 0.420966 Grad Norm 1.926053 0.11s/it\n","Train loss 25551 0.422945 Grad Norm 0.787621 0.14s/it\n","Train loss 25552 0.405409 Grad Norm 1.063931 0.11s/it\n","Train loss 25553 0.515126 Grad Norm 1.359523 0.12s/it\n","Train loss 25554 0.481187 Grad Norm 0.778959 0.12s/it\n","Train loss 25555 0.365539 Grad Norm 4.341671 0.11s/it\n","Train loss 25556 0.574071 Grad Norm 2.956351 0.11s/it\n","Train loss 25557 0.467317 Grad Norm 0.767188 0.13s/it\n","Train loss 25558 1.066447 Grad Norm 5.343274 0.12s/it\n","Train loss 25559 0.551031 Grad Norm 0.779790 0.11s/it\n","Train loss 25560 0.375456 Grad Norm 1.750076 0.15s/it\n","Train loss 25561 0.691014 Grad Norm 6.544260 0.13s/it\n","Train loss 25562 0.528307 Grad Norm 1.605784 0.12s/it\n","Train loss 25563 0.810049 Grad Norm 2.218630 0.11s/it\n","Train loss 25564 0.559239 Grad Norm 1.288105 0.15s/it\n","Train loss 25565 0.447901 Grad Norm 1.402943 0.10s/it\n","Train loss 25566 0.527919 Grad Norm 1.109472 0.11s/it\n","Train loss 25567 0.397820 Grad Norm 0.599189 0.12s/it\n","Train loss 25568 0.506628 Grad Norm 1.943085 0.11s/it\n","Train loss 25569 0.450414 Grad Norm 1.054086 0.11s/it\n","Train loss 25570 0.683393 Grad Norm 1.240948 0.12s/it\n","Train loss 25571 0.627867 Grad Norm 3.000016 0.13s/it\n","Train loss 25572 0.695292 Grad Norm 5.544669 0.14s/it\n","Train loss 25573 0.513511 Grad Norm 1.734895 0.12s/it\n","Train loss 25574 0.553219 Grad Norm 3.502637 0.14s/it\n","Train loss 25575 0.631713 Grad Norm 1.926969 0.14s/it\n","Train loss 25576 0.580679 Grad Norm 1.368392 0.15s/it\n","Train loss 25577 0.609700 Grad Norm 2.573560 0.10s/it\n","Train loss 25578 0.618957 Grad Norm 1.392199 0.13s/it\n","Train loss 25579 0.303956 Grad Norm 0.907217 0.16s/it\n","Train loss 25580 0.365412 Grad Norm 1.687063 0.13s/it\n","Train loss 25581 0.659277 Grad Norm 1.189885 0.13s/it\n","Train loss 25582 0.552607 Grad Norm 1.660624 0.10s/it\n","Train loss 25583 0.387664 Grad Norm 1.876141 0.11s/it\n","Train loss 25584 0.349939 Grad Norm 0.652160 0.14s/it\n","Train loss 25585 0.313522 Grad Norm 0.582534 0.12s/it\n","Train loss 25586 0.595261 Grad Norm 1.384398 0.12s/it\n","Train loss 25587 0.455930 Grad Norm 0.802135 0.14s/it\n","Train loss 25588 0.569595 Grad Norm 1.809430 0.15s/it\n","Train loss 25589 0.388848 Grad Norm 0.511260 0.11s/it\n","Train loss 25590 0.440765 Grad Norm 1.837382 0.13s/it\n","Train loss 25591 0.416991 Grad Norm 2.392473 0.13s/it\n","Train loss 25592 0.488067 Grad Norm 0.747537 0.15s/it\n","Train loss 25593 0.403653 Grad Norm 1.883233 0.12s/it\n","Train loss 25594 0.621921 Grad Norm 0.909936 0.16s/it\n","Train loss 25595 0.452289 Grad Norm 1.247790 0.13s/it\n","Train loss 25596 0.517381 Grad Norm 0.965823 0.12s/it\n","Train loss 25597 0.742121 Grad Norm 2.539948 0.13s/it\n","Train loss 25598 0.435439 Grad Norm 1.078536 0.12s/it\n","Train loss 25599 0.558801 Grad Norm 1.179495 0.12s/it\n","Train loss 25600 0.468903 Grad Norm 0.825533 0.13s/it\n","Train loss 25601 0.363121 Grad Norm 1.890300 0.14s/it\n","Train loss 25602 0.777201 Grad Norm 1.422203 0.12s/it\n","Train loss 25603 0.835139 Grad Norm 3.433971 0.10s/it\n","Train loss 25604 0.874049 Grad Norm 1.471827 0.13s/it\n","Train loss 25605 0.574758 Grad Norm 3.393442 0.14s/it\n","Train loss 25606 0.671915 Grad Norm 1.871023 0.12s/it\n","Train loss 25607 0.355341 Grad Norm 0.908444 0.15s/it\n","Train loss 25608 0.889880 Grad Norm 2.048096 0.12s/it\n","Train loss 25609 0.476868 Grad Norm 0.628423 0.11s/it\n","Train loss 25610 0.623882 Grad Norm 2.014833 0.11s/it\n","Train loss 25611 0.410255 Grad Norm 1.074543 0.16s/it\n","Train loss 25612 0.500900 Grad Norm 1.916160 0.12s/it\n","Train loss 25613 0.581325 Grad Norm 1.719041 0.12s/it\n","Train loss 25614 0.417274 Grad Norm 1.389225 0.13s/it\n","Train loss 25615 0.662247 Grad Norm 1.427848 0.12s/it\n","Train loss 25616 0.735836 Grad Norm 2.208587 0.14s/it\n","Train loss 25617 0.392844 Grad Norm 1.734955 0.10s/it\n","Train loss 25618 0.450980 Grad Norm 0.962148 0.11s/it\n","Train loss 25619 0.510614 Grad Norm 1.207168 0.11s/it\n","Train loss 25620 0.462651 Grad Norm 1.538148 0.15s/it\n","Train loss 25621 0.535301 Grad Norm 1.141414 0.15s/it\n","Train loss 25622 0.500955 Grad Norm 1.290327 0.13s/it\n","Train loss 25623 0.486793 Grad Norm 0.859519 0.15s/it\n","Train loss 25624 0.738471 Grad Norm 1.980378 0.14s/it\n","Train loss 25625 0.574978 Grad Norm 6.047133 0.10s/it\n","Train loss 25626 0.694185 Grad Norm 1.451002 0.14s/it\n","Train loss 25627 0.471683 Grad Norm 1.163742 0.11s/it\n","Train loss 25628 0.600288 Grad Norm 1.493279 0.16s/it\n","Train loss 25629 0.491604 Grad Norm 1.169102 0.12s/it\n","Train loss 25630 0.325160 Grad Norm 0.519265 0.11s/it\n","Train loss 25631 0.608412 Grad Norm 1.649860 0.10s/it\n","Train loss 25632 0.781206 Grad Norm 1.136393 0.12s/it\n","Train loss 25633 0.441786 Grad Norm 1.403523 0.13s/it\n","Train loss 25634 0.541645 Grad Norm 1.122697 0.13s/it\n","Train loss 25635 0.550899 Grad Norm 2.709986 0.11s/it\n","Train loss 25636 0.460362 Grad Norm 0.726399 0.16s/it\n","Train loss 25637 0.564315 Grad Norm 1.113960 0.11s/it\n","Train loss 25638 0.310352 Grad Norm 1.268530 0.11s/it\n","Train loss 25639 0.727624 Grad Norm 3.281690 0.15s/it\n","Train loss 25640 0.644613 Grad Norm 1.978467 0.12s/it\n","Train loss 25641 0.512833 Grad Norm 0.901595 0.12s/it\n","Train loss 25642 0.755415 Grad Norm 1.579290 0.11s/it\n","Train loss 25643 0.712099 Grad Norm 1.495255 0.14s/it\n","Train loss 25644 0.505872 Grad Norm 1.205893 0.11s/it\n","Train loss 25645 0.557729 Grad Norm 1.558752 0.14s/it\n","Train loss 25646 0.518278 Grad Norm 1.536013 0.11s/it\n","Train loss 25647 0.489620 Grad Norm 1.110791 0.17s/it\n","Train loss 25648 0.278890 Grad Norm 0.359670 0.10s/it\n","Train loss 25649 0.670083 Grad Norm 1.422669 0.13s/it\n","Train loss 25650 0.433496 Grad Norm 2.568013 0.15s/it\n","Train loss 25651 0.477783 Grad Norm 0.678170 0.14s/it\n","Train loss 25652 0.464638 Grad Norm 0.863331 0.11s/it\n","Train loss 25653 0.568646 Grad Norm 1.158776 0.12s/it\n","Train loss 25654 0.583336 Grad Norm 1.231195 0.15s/it\n","Train loss 25655 0.579740 Grad Norm 2.062202 0.11s/it\n","Train loss 25656 0.821758 Grad Norm 2.524494 0.11s/it\n","Train loss 25657 0.744193 Grad Norm 1.864928 0.12s/it\n","Train loss 25658 0.677791 Grad Norm 0.663488 0.14s/it\n","Train loss 25659 0.521681 Grad Norm 0.871929 0.12s/it\n","Train loss 25660 0.578966 Grad Norm 1.713761 0.11s/it\n","Train loss 25661 0.505539 Grad Norm 1.819433 0.13s/it\n","Train loss 25662 0.321338 Grad Norm 0.602900 0.12s/it\n","Train loss 25663 0.585822 Grad Norm 2.226120 0.14s/it\n","Train loss 25664 0.650329 Grad Norm 2.042517 0.12s/it\n","Train loss 25665 0.444714 Grad Norm 0.538005 0.14s/it\n","Train loss 25666 0.541535 Grad Norm 1.079550 0.13s/it\n","Train loss 25667 0.394214 Grad Norm 0.918060 0.10s/it\n","Train loss 25668 0.505102 Grad Norm 1.744872 0.10s/it\n","Train loss 25669 0.536392 Grad Norm 3.366934 0.13s/it\n","Train loss 25670 0.516020 Grad Norm 1.527122 0.15s/it\n","Train loss 25671 0.565959 Grad Norm 1.117097 0.12s/it\n","Train loss 25672 0.430923 Grad Norm 0.556790 0.13s/it\n","Train loss 25673 0.529656 Grad Norm 0.946049 0.11s/it\n","Train loss 25674 0.456359 Grad Norm 0.711453 0.12s/it\n","Train loss 25675 0.642362 Grad Norm 2.514730 0.13s/it\n","Train loss 25676 0.431753 Grad Norm 1.389906 0.11s/it\n","Train loss 25677 0.572875 Grad Norm 1.446242 0.11s/it\n","Train loss 25678 0.666061 Grad Norm 2.113106 0.11s/it\n","Train loss 25679 0.719124 Grad Norm 1.751249 0.11s/it\n","Train loss 25680 0.434428 Grad Norm 0.732038 0.13s/it\n","Train loss 25681 0.418460 Grad Norm 2.294688 0.14s/it\n","Train loss 25682 0.341400 Grad Norm 0.632223 0.13s/it\n","Train loss 25683 0.329211 Grad Norm 0.504005 0.15s/it\n","Train loss 25684 0.730294 Grad Norm 1.737008 0.11s/it\n","Train loss 25685 0.602535 Grad Norm 1.465849 0.12s/it\n","Train loss 25686 0.609349 Grad Norm 0.634888 0.15s/it\n","Train loss 25687 0.500741 Grad Norm 1.549387 0.15s/it\n","Train loss 25688 0.550445 Grad Norm 1.458994 0.14s/it\n","Train loss 25689 0.638362 Grad Norm 1.437746 0.11s/it\n","Train loss 25690 0.766695 Grad Norm 2.239799 0.11s/it\n","Train loss 25691 0.618768 Grad Norm 0.779427 0.14s/it\n","Train loss 25692 1.121516 Grad Norm 3.039792 0.11s/it\n","Train loss 25693 0.349763 Grad Norm 0.562546 0.10s/it\n","Train loss 25694 0.376764 Grad Norm 0.633761 0.14s/it\n","Train loss 25695 0.733064 Grad Norm 1.437103 0.13s/it\n","Train loss 25696 0.309351 Grad Norm 0.390744 0.14s/it\n","Train loss 25697 0.524013 Grad Norm 1.689483 0.13s/it\n","Train loss 25698 0.456273 Grad Norm 0.988823 0.13s/it\n","Train loss 25699 0.573869 Grad Norm 0.731448 0.16s/it\n","Train loss 25700 0.574699 Grad Norm 1.912105 0.12s/it\n","Train loss 25701 0.597628 Grad Norm 1.489750 0.14s/it\n","Train loss 25702 0.675255 Grad Norm 1.378628 0.11s/it\n","Train loss 25703 0.639384 Grad Norm 1.649627 0.11s/it\n","Train loss 25704 0.596006 Grad Norm 0.923303 0.14s/it\n","Train loss 25705 0.427884 Grad Norm 1.136399 0.11s/it\n","Train loss 25706 0.496330 Grad Norm 1.760502 0.14s/it\n","Train loss 25707 0.817038 Grad Norm 1.385398 0.13s/it\n","Train loss 25708 0.362524 Grad Norm 0.517657 0.11s/it\n","Train loss 25709 0.657036 Grad Norm 2.731791 0.11s/it\n","Train loss 25710 0.741670 Grad Norm 3.620221 0.11s/it\n","Train loss 25711 0.445308 Grad Norm 1.017523 0.13s/it\n","Train loss 25712 0.528521 Grad Norm 0.807431 0.12s/it\n","Train loss 25713 0.502040 Grad Norm 2.427557 0.12s/it\n","Train loss 25714 0.625154 Grad Norm 1.598878 0.10s/it\n","Train loss 25715 0.566697 Grad Norm 1.320860 0.13s/it\n","Train loss 25716 0.369099 Grad Norm 0.742555 0.10s/it\n","Train loss 25717 0.548998 Grad Norm 1.553823 0.10s/it\n","Train loss 25718 0.683475 Grad Norm 1.446542 0.11s/it\n","Train loss 25719 0.478576 Grad Norm 0.724952 0.10s/it\n","Train loss 25720 0.523279 Grad Norm 1.496188 0.11s/it\n","Train loss 25721 0.751261 Grad Norm 1.977799 0.11s/it\n","Train loss 25722 0.613070 Grad Norm 1.834431 0.12s/it\n","Train loss 25723 0.383925 Grad Norm 0.660572 0.11s/it\n","Train loss 25724 0.473925 Grad Norm 0.905179 0.13s/it\n","Train loss 25725 0.869116 Grad Norm 3.154015 0.12s/it\n","Train loss 25726 0.552492 Grad Norm 1.401570 0.12s/it\n","Train loss 25727 0.633630 Grad Norm 0.933564 0.11s/it\n","Train loss 25728 0.467293 Grad Norm 0.527673 0.14s/it\n","Train loss 25729 0.310049 Grad Norm 1.143590 0.10s/it\n","Train loss 25730 0.587846 Grad Norm 1.401884 0.10s/it\n","Train loss 25731 0.483294 Grad Norm 1.357370 0.14s/it\n","Train loss 25732 0.452703 Grad Norm 0.790629 0.12s/it\n","Train loss 25733 0.675787 Grad Norm 2.649305 0.14s/it\n","Train loss 25734 0.493891 Grad Norm 1.030639 0.11s/it\n","Train loss 25735 0.605173 Grad Norm 1.429710 0.12s/it\n","Train loss 25736 0.529703 Grad Norm 2.799485 0.12s/it\n","Train loss 25737 0.564968 Grad Norm 2.375866 0.12s/it\n","Train loss 25738 0.598796 Grad Norm 2.311834 0.11s/it\n","Train loss 25739 0.570933 Grad Norm 2.162897 0.11s/it\n","Train loss 25740 0.734279 Grad Norm 2.819770 0.11s/it\n","Train loss 25741 0.401173 Grad Norm 1.096594 0.15s/it\n","Train loss 25742 0.598182 Grad Norm 2.573042 0.14s/it\n","Train loss 25743 0.490631 Grad Norm 2.167184 0.12s/it\n","Train loss 25744 0.657864 Grad Norm 2.030439 0.13s/it\n","Train loss 25745 0.717756 Grad Norm 3.882762 0.11s/it\n","Train loss 25746 0.568371 Grad Norm 3.394226 0.14s/it\n","Train loss 25747 0.609324 Grad Norm 1.049420 0.13s/it\n","Train loss 25748 0.301378 Grad Norm 0.576284 0.11s/it\n","Train loss 25749 0.667871 Grad Norm 1.321540 0.13s/it\n","Train loss 25750 0.347379 Grad Norm 0.597682 0.15s/it\n","Train loss 25751 0.756356 Grad Norm 2.192297 0.13s/it\n","Train loss 25752 0.715910 Grad Norm 1.304231 0.13s/it\n","Train loss 25753 0.467046 Grad Norm 2.946853 0.10s/it\n","Train loss 25754 0.671396 Grad Norm 1.529905 0.15s/it\n","Train loss 25755 0.416493 Grad Norm 1.199689 0.13s/it\n","Train loss 25756 0.556482 Grad Norm 1.248994 0.13s/it\n","Train loss 25757 0.455885 Grad Norm 1.289489 0.11s/it\n","Train loss 25758 0.456191 Grad Norm 0.902405 0.12s/it\n","Train loss 25759 0.706744 Grad Norm 1.809602 0.12s/it\n","Train loss 25760 0.442297 Grad Norm 0.977032 0.13s/it\n","Train loss 25761 0.420076 Grad Norm 1.905804 0.13s/it\n","Train loss 25762 0.964075 Grad Norm 2.608555 0.12s/it\n","Train loss 25763 0.556431 Grad Norm 1.175988 0.12s/it\n","Train loss 25764 0.369799 Grad Norm 1.280010 0.15s/it\n","Train loss 25765 0.633137 Grad Norm 1.077052 0.11s/it\n","Train loss 25766 0.530523 Grad Norm 1.653161 0.14s/it\n","Train loss 25767 0.517464 Grad Norm 0.948395 0.14s/it\n","Train loss 25768 0.534836 Grad Norm 1.951974 0.14s/it\n","Train loss 25769 0.321327 Grad Norm 0.788794 0.13s/it\n","Train loss 25770 0.469397 Grad Norm 1.191754 0.11s/it\n","Train loss 25771 0.506494 Grad Norm 0.798066 0.13s/it\n","Train loss 25772 0.459824 Grad Norm 1.194431 0.12s/it\n","Train loss 25773 0.457975 Grad Norm 1.523299 0.11s/it\n","Train loss 25774 0.321737 Grad Norm 0.967497 0.10s/it\n","Train loss 25775 0.882827 Grad Norm 0.943278 0.13s/it\n","Train loss 25776 0.600217 Grad Norm 1.896053 0.12s/it\n","Train loss 25777 0.564539 Grad Norm 2.926240 0.14s/it\n","Train loss 25778 0.425756 Grad Norm 0.889371 0.13s/it\n","Train loss 25779 0.495341 Grad Norm 0.615662 0.14s/it\n","Train loss 25780 0.598140 Grad Norm 0.713219 0.15s/it\n","Train loss 25781 0.602154 Grad Norm 1.612908 0.13s/it\n","Train loss 25782 0.416488 Grad Norm 1.174993 0.10s/it\n","Train loss 25783 0.420815 Grad Norm 0.673929 0.12s/it\n","Train loss 25784 0.664088 Grad Norm 3.963749 0.10s/it\n","Train loss 25785 0.449108 Grad Norm 1.205374 0.14s/it\n","Train loss 25786 0.375821 Grad Norm 0.535961 0.15s/it\n","Train loss 25787 0.551055 Grad Norm 1.577075 0.13s/it\n","Train loss 25788 0.628983 Grad Norm 2.717641 0.11s/it\n","Train loss 25789 0.691728 Grad Norm 0.925778 0.11s/it\n","Train loss 25790 0.584710 Grad Norm 2.631606 0.11s/it\n","Train loss 25791 0.574828 Grad Norm 1.203080 0.14s/it\n","Train loss 25792 0.512215 Grad Norm 0.979802 0.11s/it\n","Train loss 25793 0.542349 Grad Norm 1.305966 0.13s/it\n","Train loss 25794 0.469138 Grad Norm 1.530100 0.12s/it\n","Train loss 25795 0.353510 Grad Norm 0.395918 0.13s/it\n","Train loss 25796 0.526714 Grad Norm 0.966034 0.14s/it\n","Train loss 25797 0.492028 Grad Norm 2.658320 0.11s/it\n","Train loss 25798 0.506310 Grad Norm 1.717832 0.13s/it\n","Train loss 25799 0.574397 Grad Norm 1.979673 0.14s/it\n","Train loss 25800 0.495977 Grad Norm 0.732682 0.13s/it\n","Train loss 25801 0.312780 Grad Norm 1.407746 0.14s/it\n","Train loss 25802 0.793894 Grad Norm 1.216786 0.14s/it\n","Train loss 25803 0.427405 Grad Norm 0.979499 0.11s/it\n","Train loss 25804 0.460653 Grad Norm 0.635127 0.12s/it\n","Train loss 25805 0.586452 Grad Norm 0.861214 0.13s/it\n","Train loss 25806 0.643999 Grad Norm 1.269515 0.14s/it\n","Train loss 25807 0.553651 Grad Norm 1.139065 0.12s/it\n","Train loss 25808 0.546503 Grad Norm 1.455114 0.13s/it\n","Train loss 25809 0.335177 Grad Norm 1.162458 0.17s/it\n","Train loss 25810 0.439277 Grad Norm 2.311363 0.10s/it\n","Train loss 25811 0.956845 Grad Norm 3.399437 0.11s/it\n","Train loss 25812 0.410966 Grad Norm 0.990294 0.16s/it\n","Train loss 25813 0.800314 Grad Norm 1.716726 0.11s/it\n","Train loss 25814 0.592315 Grad Norm 0.942213 0.15s/it\n","Train loss 25815 0.406626 Grad Norm 1.195722 0.13s/it\n","Train loss 25816 0.859301 Grad Norm 3.470418 0.11s/it\n","Train loss 25817 0.661392 Grad Norm 2.421945 0.11s/it\n","Train loss 25818 0.571506 Grad Norm 1.320008 0.10s/it\n","Train loss 25819 0.487524 Grad Norm 1.322822 0.17s/it\n","Train loss 25820 0.501944 Grad Norm 1.391321 0.12s/it\n","Train loss 25821 0.391751 Grad Norm 0.799612 0.14s/it\n","Train loss 25822 0.405420 Grad Norm 0.913103 0.11s/it\n","Train loss 25823 0.406767 Grad Norm 1.762282 0.12s/it\n","Train loss 25824 0.325718 Grad Norm 1.015997 0.14s/it\n","Train loss 25825 0.456585 Grad Norm 2.760191 0.10s/it\n","Train loss 25826 0.515586 Grad Norm 0.895071 0.12s/it\n","Train loss 25827 0.465771 Grad Norm 0.595766 0.13s/it\n","Train loss 25828 0.433643 Grad Norm 0.791836 0.12s/it\n","Train loss 25829 0.628631 Grad Norm 1.956712 0.12s/it\n","Train loss 25830 0.493348 Grad Norm 1.397675 0.12s/it\n","Train loss 25831 0.234525 Grad Norm 0.824534 0.14s/it\n","Train loss 25832 0.454586 Grad Norm 0.940030 0.14s/it\n","Train loss 25833 0.589316 Grad Norm 2.198235 0.14s/it\n","Train loss 25834 0.623832 Grad Norm 1.771819 0.11s/it\n","Train loss 25835 0.649570 Grad Norm 1.347949 0.11s/it\n","Train loss 25836 0.371669 Grad Norm 0.751770 0.14s/it\n","Train loss 25837 0.554079 Grad Norm 1.083221 0.13s/it\n","Train loss 25838 0.576048 Grad Norm 1.159423 0.12s/it\n","Train loss 25839 0.404193 Grad Norm 3.803667 0.11s/it\n","Train loss 25840 0.911997 Grad Norm 3.659376 0.13s/it\n","Train loss 25841 0.905105 Grad Norm 2.280764 0.12s/it\n","Train loss 25842 0.614241 Grad Norm 1.682470 0.14s/it\n","Train loss 25843 0.571907 Grad Norm 0.932083 0.12s/it\n","Train loss 25844 0.555838 Grad Norm 1.157313 0.12s/it\n","Train loss 25845 0.574062 Grad Norm 1.664170 0.13s/it\n","Train loss 25846 0.716378 Grad Norm 1.482395 0.11s/it\n","Train loss 25847 0.748991 Grad Norm 1.677687 0.13s/it\n","Train loss 25848 0.689527 Grad Norm 0.779867 0.12s/it\n","Train loss 25849 0.611672 Grad Norm 1.695671 0.16s/it\n","Train loss 25850 0.431226 Grad Norm 0.928555 0.12s/it\n","Train loss 25851 0.843875 Grad Norm 1.800519 0.14s/it\n","Train loss 25852 0.786076 Grad Norm 3.686541 0.12s/it\n","Train loss 25853 0.444797 Grad Norm 0.570964 0.12s/it\n","Train loss 25854 0.413899 Grad Norm 0.785589 0.11s/it\n","Train loss 25855 0.690657 Grad Norm 1.678634 0.11s/it\n","Train loss 25856 0.506027 Grad Norm 2.786803 0.11s/it\n","Train loss 25857 0.738366 Grad Norm 2.945474 0.11s/it\n","Train loss 25858 0.521670 Grad Norm 0.745699 0.13s/it\n","Train loss 25859 0.571565 Grad Norm 1.491283 0.12s/it\n","Train loss 25860 0.579109 Grad Norm 1.248682 0.13s/it\n","Train loss 25861 0.785570 Grad Norm 1.734506 0.11s/it\n","Train loss 25862 0.760681 Grad Norm 1.841474 0.14s/it\n","Train loss 25863 0.485242 Grad Norm 1.026969 0.11s/it\n","Train loss 25864 0.492325 Grad Norm 1.134660 0.12s/it\n","Train loss 25865 0.653407 Grad Norm 1.695263 0.14s/it\n","Train loss 25866 0.529560 Grad Norm 2.050237 0.13s/it\n","Train loss 25867 0.331074 Grad Norm 1.031897 0.13s/it\n","Train loss 25868 0.589026 Grad Norm 1.210355 0.14s/it\n","Train loss 25869 0.425545 Grad Norm 2.135898 0.11s/it\n","Train loss 25870 0.754064 Grad Norm 1.423096 0.12s/it\n","Train loss 25871 0.651482 Grad Norm 1.398028 0.13s/it\n","Train loss 25872 0.451180 Grad Norm 1.470049 0.13s/it\n","Train loss 25873 0.634652 Grad Norm 3.119040 0.12s/it\n","Train loss 25874 0.433937 Grad Norm 2.494010 0.13s/it\n","Train loss 25875 0.495468 Grad Norm 1.018926 0.13s/it\n","Train loss 25876 0.770385 Grad Norm 1.175789 0.11s/it\n","Train loss 25877 0.666621 Grad Norm 1.281936 0.10s/it\n","Train loss 25878 0.485783 Grad Norm 1.319027 0.14s/it\n","Train loss 25879 0.516097 Grad Norm 1.547154 0.12s/it\n","Train loss 25880 0.550712 Grad Norm 1.787704 0.11s/it\n","Train loss 25881 0.432749 Grad Norm 0.903228 0.12s/it\n","Train loss 25882 0.683275 Grad Norm 1.477932 0.13s/it\n","Train loss 25883 0.461756 Grad Norm 0.648870 0.14s/it\n","Train loss 25884 0.796410 Grad Norm 1.205153 0.11s/it\n","Train loss 25885 0.835287 Grad Norm 1.361137 0.11s/it\n","Train loss 25886 0.513362 Grad Norm 2.335946 0.13s/it\n","Train loss 25887 0.812910 Grad Norm 2.782458 0.11s/it\n","Train loss 25888 0.510696 Grad Norm 0.863632 0.13s/it\n","Train loss 25889 0.651706 Grad Norm 1.111310 0.13s/it\n","Train loss 25890 0.326429 Grad Norm 0.444441 0.17s/it\n","Train loss 25891 0.625396 Grad Norm 1.194140 0.12s/it\n","Train loss 25892 0.515493 Grad Norm 1.764736 0.14s/it\n","Train loss 25893 0.453385 Grad Norm 1.096346 0.11s/it\n","Train loss 25894 0.622913 Grad Norm 1.626476 0.14s/it\n","Train loss 25895 0.624643 Grad Norm 2.199378 0.13s/it\n","Train loss 25896 0.552043 Grad Norm 1.984333 0.12s/it\n","Train loss 25897 0.666331 Grad Norm 1.456669 0.12s/it\n","Train loss 25898 0.633488 Grad Norm 1.711770 0.12s/it\n","Train loss 25899 0.662752 Grad Norm 1.579492 0.12s/it\n","Train loss 25900 0.439582 Grad Norm 0.611222 0.11s/it\n","Train loss 25901 0.518281 Grad Norm 3.614640 0.11s/it\n","Train loss 25902 0.440405 Grad Norm 1.399076 0.13s/it\n","Train loss 25903 0.753433 Grad Norm 1.205509 0.12s/it\n","Train loss 25904 0.412788 Grad Norm 1.043744 0.16s/it\n","Train loss 25905 0.448890 Grad Norm 1.223245 0.12s/it\n","Train loss 25906 0.439915 Grad Norm 0.577589 0.13s/it\n","Train loss 25907 0.383091 Grad Norm 0.835505 0.12s/it\n","Train loss 25908 0.617993 Grad Norm 0.974120 0.12s/it\n","Train loss 25909 0.516817 Grad Norm 1.683681 0.11s/it\n","Train loss 25910 0.525972 Grad Norm 3.963083 0.10s/it\n","Train loss 25911 0.439832 Grad Norm 0.784908 0.12s/it\n","Train loss 25912 0.662923 Grad Norm 1.225057 0.11s/it\n","Train loss 25913 0.720122 Grad Norm 3.210963 0.14s/it\n","Train loss 25914 0.461485 Grad Norm 0.971955 0.14s/it\n","Train loss 25915 0.506389 Grad Norm 1.175995 0.13s/it\n","Train loss 25916 0.632727 Grad Norm 2.442848 0.13s/it\n","Train loss 25917 0.489468 Grad Norm 2.449157 0.12s/it\n","Train loss 25918 0.947872 Grad Norm 3.137587 0.10s/it\n","Train loss 25919 0.389713 Grad Norm 1.141036 0.16s/it\n","Train loss 25920 0.403728 Grad Norm 0.678958 0.14s/it\n","Train loss 25921 0.429522 Grad Norm 0.733972 0.13s/it\n","Train loss 25922 0.607954 Grad Norm 1.197359 0.11s/it\n","Train loss 25923 0.458420 Grad Norm 0.845197 0.14s/it\n","Train loss 25924 0.320669 Grad Norm 0.719504 0.10s/it\n","Train loss 25925 0.564121 Grad Norm 1.465198 0.10s/it\n","Train loss 25926 0.421748 Grad Norm 1.180071 0.11s/it\n","Train loss 25927 0.607591 Grad Norm 1.912246 0.13s/it\n","Train loss 25928 0.507289 Grad Norm 1.493143 0.13s/it\n","Train loss 25929 0.373126 Grad Norm 0.596636 0.14s/it\n","Train loss 25930 0.378241 Grad Norm 1.122974 0.14s/it\n","Train loss 25931 0.877119 Grad Norm 2.283720 0.11s/it\n","Train loss 25932 0.507041 Grad Norm 0.640524 0.12s/it\n","Train loss 25933 0.417631 Grad Norm 1.133860 0.14s/it\n","Train loss 25934 0.812597 Grad Norm 2.135000 0.12s/it\n","Train loss 25935 0.579806 Grad Norm 1.575052 0.12s/it\n","Train loss 25936 0.579107 Grad Norm 1.166622 0.13s/it\n","Train loss 25937 0.315090 Grad Norm 0.875458 0.14s/it\n","Train loss 25938 0.713588 Grad Norm 4.108459 0.10s/it\n","Train loss 25939 0.362232 Grad Norm 0.705743 0.13s/it\n","Train loss 25940 0.527714 Grad Norm 2.038579 0.10s/it\n","Train loss 25941 0.620146 Grad Norm 1.397101 0.13s/it\n","Train loss 25942 0.665523 Grad Norm 3.263443 0.13s/it\n","Train loss 25943 0.556946 Grad Norm 1.600872 0.11s/it\n","Train loss 25944 0.594412 Grad Norm 1.690279 0.12s/it\n","Train loss 25945 0.458402 Grad Norm 0.989643 0.14s/it\n","Train loss 25946 0.452350 Grad Norm 0.623413 0.17s/it\n","Train loss 25947 0.439857 Grad Norm 1.055210 0.12s/it\n","Train loss 25948 0.523887 Grad Norm 0.926927 0.12s/it\n","Train loss 25949 0.573495 Grad Norm 2.229657 0.11s/it\n","Train loss 25950 0.747678 Grad Norm 1.783504 0.12s/it\n","Train loss 25951 0.653937 Grad Norm 1.564270 0.11s/it\n","Train loss 25952 0.546884 Grad Norm 1.485564 0.14s/it\n","Train loss 25953 0.590648 Grad Norm 1.647832 0.13s/it\n","Train loss 25954 0.657999 Grad Norm 2.369269 0.12s/it\n","Train loss 25955 0.320157 Grad Norm 0.625840 0.14s/it\n","Train loss 25956 0.425502 Grad Norm 0.605083 0.14s/it\n","Train loss 25957 0.857970 Grad Norm 3.229781 0.12s/it\n","Train loss 25958 0.541232 Grad Norm 1.753871 0.14s/it\n","Train loss 25959 0.597725 Grad Norm 1.136507 0.12s/it\n","Train loss 25960 0.576145 Grad Norm 1.052442 0.10s/it\n","Train loss 25961 0.659589 Grad Norm 1.440489 0.14s/it\n","Train loss 25962 0.486304 Grad Norm 1.056396 0.12s/it\n","Train loss 25963 0.511935 Grad Norm 2.340955 0.12s/it\n","Train loss 25964 0.748839 Grad Norm 2.413807 0.11s/it\n","Train loss 25965 0.683635 Grad Norm 1.458261 0.11s/it\n","Train loss 25966 0.467631 Grad Norm 1.030255 0.12s/it\n","Train loss 25967 0.677325 Grad Norm 1.892429 0.11s/it\n","Train loss 25968 0.551342 Grad Norm 0.920227 0.11s/it\n","Train loss 25969 0.567432 Grad Norm 1.182110 0.12s/it\n","Train loss 25970 0.586715 Grad Norm 1.457242 0.12s/it\n","Train loss 25971 0.702402 Grad Norm 1.986656 0.10s/it\n","Train loss 25972 0.744083 Grad Norm 2.139745 0.11s/it\n","Train loss 25973 0.526359 Grad Norm 2.315413 0.13s/it\n","Train loss 25974 0.508564 Grad Norm 1.150857 0.17s/it\n","Train loss 25975 0.477419 Grad Norm 1.346519 0.13s/it\n","Train loss 25976 0.327283 Grad Norm 2.505073 0.14s/it\n","Train loss 25977 0.539022 Grad Norm 0.974059 0.15s/it\n","Train loss 25978 0.467685 Grad Norm 0.929324 0.12s/it\n","Train loss 25979 0.613015 Grad Norm 0.866947 0.14s/it\n","Train loss 25980 0.557573 Grad Norm 1.556368 0.11s/it\n","Train loss 25981 0.516933 Grad Norm 1.343062 0.12s/it\n","Train loss 25982 0.670806 Grad Norm 2.154684 0.12s/it\n","Train loss 25983 0.548487 Grad Norm 2.132728 0.11s/it\n","Train loss 25984 0.749690 Grad Norm 1.242134 0.11s/it\n","Train loss 25985 0.504145 Grad Norm 2.339066 0.12s/it\n","Train loss 25986 0.450953 Grad Norm 1.053652 0.12s/it\n","Train loss 25987 0.410694 Grad Norm 0.622410 0.14s/it\n","Train loss 25988 0.467572 Grad Norm 1.029849 0.11s/it\n","Train loss 25989 0.516808 Grad Norm 1.459572 0.13s/it\n","Train loss 25990 0.668711 Grad Norm 2.485412 0.13s/it\n","Train loss 25991 0.598319 Grad Norm 2.065421 0.12s/it\n","Train loss 25992 0.899084 Grad Norm 1.343319 0.13s/it\n","Train loss 25993 0.632093 Grad Norm 1.819508 0.13s/it\n","Train loss 25994 0.578821 Grad Norm 1.132688 0.14s/it\n","Train loss 25995 0.551826 Grad Norm 0.783184 0.17s/it\n","Train loss 25996 0.975578 Grad Norm 2.059793 0.12s/it\n","Train loss 25997 0.566938 Grad Norm 2.073063 0.11s/it\n","Train loss 25998 0.613092 Grad Norm 1.503542 0.12s/it\n","Train loss 25999 0.734080 Grad Norm 2.842575 0.12s/it\n","Train loss 26000 0.740901 Grad Norm 1.216527 0.11s/it\n","Validation loss 26000: 0.384985\n","Saving model and optimizer state at iteration 26000 to checkpoint_26000\n","Train loss 26001 0.554362 Grad Norm 0.833586 0.10s/it\n","Train loss 26002 0.297964 Grad Norm 0.316543 0.11s/it\n","Train loss 26003 0.319328 Grad Norm 0.556624 0.14s/it\n","Train loss 26004 0.456799 Grad Norm 2.485756 0.12s/it\n","Train loss 26005 0.669504 Grad Norm 2.849567 0.12s/it\n","Train loss 26006 0.603996 Grad Norm 3.074821 0.12s/it\n","Train loss 26007 0.544376 Grad Norm 1.532885 0.12s/it\n","Train loss 26008 0.694016 Grad Norm 1.689286 0.11s/it\n","Train loss 26009 0.598369 Grad Norm 1.891274 0.14s/it\n","Train loss 26010 0.583799 Grad Norm 2.104091 0.12s/it\n","Train loss 26011 0.443748 Grad Norm 1.419221 0.12s/it\n","Train loss 26012 0.655438 Grad Norm 1.501017 0.12s/it\n","Train loss 26013 0.467277 Grad Norm 1.164202 0.15s/it\n","Train loss 26014 0.619165 Grad Norm 1.101376 0.13s/it\n","Train loss 26015 0.685735 Grad Norm 2.717145 0.11s/it\n","Train loss 26016 0.430295 Grad Norm 1.010632 0.12s/it\n","Train loss 26017 0.499417 Grad Norm 1.612441 0.13s/it\n","Train loss 26018 0.574868 Grad Norm 1.736411 0.12s/it\n","Train loss 26019 0.360444 Grad Norm 0.480787 0.11s/it\n","Train loss 26020 0.556940 Grad Norm 1.766433 0.12s/it\n","Train loss 26021 0.582079 Grad Norm 1.334178 0.12s/it\n","Train loss 26022 0.598646 Grad Norm 1.395217 0.14s/it\n","Train loss 26023 0.408427 Grad Norm 1.392649 0.15s/it\n","Train loss 26024 0.462877 Grad Norm 1.057968 0.12s/it\n","Train loss 26025 0.562352 Grad Norm 1.579479 0.11s/it\n","Train loss 26026 0.291815 Grad Norm 0.859914 0.12s/it\n","Train loss 26027 0.498006 Grad Norm 1.065974 0.12s/it\n","Train loss 26028 0.342591 Grad Norm 1.574386 0.14s/it\n","Train loss 26029 0.514166 Grad Norm 1.503884 0.14s/it\n","Train loss 26030 0.427200 Grad Norm 2.270852 0.13s/it\n","Train loss 26031 0.363521 Grad Norm 0.621165 0.11s/it\n","Train loss 26032 0.478062 Grad Norm 1.456518 0.12s/it\n","Train loss 26033 0.946797 Grad Norm 4.236210 0.14s/it\n","Train loss 26034 0.361351 Grad Norm 0.665900 0.14s/it\n","Train loss 26035 0.547512 Grad Norm 1.433167 0.10s/it\n","Train loss 26036 0.586240 Grad Norm 5.661270 0.10s/it\n","Train loss 26037 0.593683 Grad Norm 1.824521 0.11s/it\n","Train loss 26038 0.746257 Grad Norm 2.588408 0.12s/it\n","Train loss 26039 0.438784 Grad Norm 0.562905 0.14s/it\n","Train loss 26040 0.461011 Grad Norm 1.356983 0.12s/it\n","Train loss 26041 0.306503 Grad Norm 0.835360 0.10s/it\n","Train loss 26042 0.850914 Grad Norm 2.185440 0.13s/it\n","Train loss 26043 0.606389 Grad Norm 1.597273 0.12s/it\n","Train loss 26044 1.070091 Grad Norm 6.541708 0.12s/it\n","Train loss 26045 0.489789 Grad Norm 1.978449 0.14s/it\n","Train loss 26046 0.694541 Grad Norm 3.129542 0.13s/it\n","Train loss 26047 0.521025 Grad Norm 1.367777 0.13s/it\n","Train loss 26048 0.408346 Grad Norm 2.918727 0.14s/it\n","Train loss 26049 0.729897 Grad Norm 2.266261 0.12s/it\n","Train loss 26050 0.743768 Grad Norm 3.101979 0.12s/it\n","Train loss 26051 0.597662 Grad Norm 2.130969 0.12s/it\n","Train loss 26052 0.710233 Grad Norm 1.473775 0.13s/it\n","Train loss 26053 0.445543 Grad Norm 1.703410 0.13s/it\n","Train loss 26054 0.527342 Grad Norm 1.549186 0.14s/it\n","Train loss 26055 0.626615 Grad Norm 3.269071 0.13s/it\n","Train loss 26056 0.346378 Grad Norm 0.679971 0.10s/it\n","Train loss 26057 0.361862 Grad Norm 0.607634 0.13s/it\n","Train loss 26058 0.427056 Grad Norm 0.973509 0.14s/it\n","Train loss 26059 0.508763 Grad Norm 1.375068 0.12s/it\n","Train loss 26060 0.501709 Grad Norm 1.015676 0.13s/it\n","Train loss 26061 0.353868 Grad Norm 1.329493 0.11s/it\n","Train loss 26062 0.378664 Grad Norm 0.858710 0.11s/it\n","Train loss 26063 0.454149 Grad Norm 1.100757 0.16s/it\n","Train loss 26064 0.472510 Grad Norm 1.450413 0.10s/it\n","Train loss 26065 0.671802 Grad Norm 2.245687 0.13s/it\n","Train loss 26066 0.492255 Grad Norm 1.153709 0.13s/it\n","Train loss 26067 0.571428 Grad Norm 1.356878 0.12s/it\n","Train loss 26068 0.478132 Grad Norm 1.153814 0.14s/it\n","Train loss 26069 0.536543 Grad Norm 1.047016 0.10s/it\n","Train loss 26070 0.508213 Grad Norm 1.013352 0.11s/it\n","Train loss 26071 0.386317 Grad Norm 1.214195 0.13s/it\n","Train loss 26072 0.525180 Grad Norm 3.182312 0.11s/it\n","Train loss 26073 0.580806 Grad Norm 1.476042 0.12s/it\n","Train loss 26074 0.315388 Grad Norm 1.769948 0.11s/it\n","Train loss 26075 0.521935 Grad Norm 0.848866 0.11s/it\n","Train loss 26076 0.693087 Grad Norm 2.568745 0.12s/it\n","Train loss 26077 0.485342 Grad Norm 1.056529 0.11s/it\n","Train loss 26078 0.381116 Grad Norm 0.620609 0.11s/it\n","Train loss 26079 0.242538 Grad Norm 0.263305 0.11s/it\n","Train loss 26080 0.557577 Grad Norm 1.201124 0.13s/it\n","Train loss 26081 0.632719 Grad Norm 2.012775 0.12s/it\n","Train loss 26082 0.799325 Grad Norm 2.115174 0.11s/it\n","Train loss 26083 0.589782 Grad Norm 2.302638 0.11s/it\n","Train loss 26084 0.578143 Grad Norm 1.673858 0.10s/it\n","Train loss 26085 0.814909 Grad Norm 2.869740 0.11s/it\n","Train loss 26086 0.406345 Grad Norm 0.814272 0.15s/it\n","Train loss 26087 0.744517 Grad Norm 2.681024 0.12s/it\n","Train loss 26088 0.407925 Grad Norm 0.744417 0.14s/it\n","Train loss 26089 0.591141 Grad Norm 1.403896 0.11s/it\n","Train loss 26090 0.509422 Grad Norm 1.237314 0.11s/it\n","Train loss 26091 0.425289 Grad Norm 2.807951 0.10s/it\n","Train loss 26092 0.598148 Grad Norm 4.953786 0.11s/it\n","Train loss 26093 0.470090 Grad Norm 2.864129 0.14s/it\n","Train loss 26094 0.309195 Grad Norm 1.080155 0.14s/it\n","Train loss 26095 0.568505 Grad Norm 1.364521 0.14s/it\n","Train loss 26096 0.420571 Grad Norm 1.720080 0.11s/it\n","Train loss 26097 0.542537 Grad Norm 0.900488 0.11s/it\n","Train loss 26098 0.680799 Grad Norm 8.052516 0.10s/it\n","Train loss 26099 0.583660 Grad Norm 1.870293 0.10s/it\n","Train loss 26100 0.596965 Grad Norm 0.919496 0.14s/it\n","Train loss 26101 0.821592 Grad Norm 1.927936 0.11s/it\n","Train loss 26102 0.616180 Grad Norm 2.398193 0.14s/it\n","Train loss 26103 0.530991 Grad Norm 0.476430 0.12s/it\n","Train loss 26104 0.238706 Grad Norm 0.337818 0.16s/it\n","Train loss 26105 0.444545 Grad Norm 1.499782 0.11s/it\n","Train loss 26106 0.769597 Grad Norm 1.326831 0.11s/it\n","Train loss 26107 0.389329 Grad Norm 1.443716 0.14s/it\n","Train loss 26108 0.640058 Grad Norm 1.364731 0.13s/it\n","Train loss 26109 0.486607 Grad Norm 1.008104 0.14s/it\n","Train loss 26110 0.445401 Grad Norm 0.789414 0.14s/it\n","Train loss 26111 0.520438 Grad Norm 1.313385 0.11s/it\n","Train loss 26112 0.441285 Grad Norm 0.412200 0.13s/it\n","Train loss 26113 0.557346 Grad Norm 1.735906 0.13s/it\n","Train loss 26114 0.572372 Grad Norm 1.367744 0.12s/it\n","Train loss 26115 0.436825 Grad Norm 1.017198 0.12s/it\n","Train loss 26116 0.473387 Grad Norm 1.126417 0.11s/it\n","Train loss 26117 0.335646 Grad Norm 0.741274 0.11s/it\n","Train loss 26118 0.663033 Grad Norm 2.027223 0.12s/it\n","Train loss 26119 0.677039 Grad Norm 1.868988 0.14s/it\n","Train loss 26120 0.944925 Grad Norm 3.788690 0.11s/it\n","Train loss 26121 0.914715 Grad Norm 2.324722 0.11s/it\n","Train loss 26122 0.439341 Grad Norm 1.514673 0.11s/it\n","Train loss 26123 0.678109 Grad Norm 1.649450 0.10s/it\n","Train loss 26124 0.691653 Grad Norm 1.527352 0.10s/it\n","Train loss 26125 0.583035 Grad Norm 2.144902 0.16s/it\n","Train loss 26126 0.500955 Grad Norm 1.409416 0.12s/it\n","Train loss 26127 0.581621 Grad Norm 2.119458 0.14s/it\n","Train loss 26128 0.520594 Grad Norm 1.221385 0.12s/it\n","Train loss 26129 0.535194 Grad Norm 1.048318 0.12s/it\n","Train loss 26130 0.574730 Grad Norm 1.291011 0.11s/it\n","Train loss 26131 0.828131 Grad Norm 2.117463 0.13s/it\n","Train loss 26132 0.481353 Grad Norm 0.987206 0.12s/it\n","Train loss 26133 0.518834 Grad Norm 0.814498 0.11s/it\n","Train loss 26134 0.321055 Grad Norm 0.704479 0.11s/it\n","Train loss 26135 0.608323 Grad Norm 2.951362 0.11s/it\n","Train loss 26136 0.560307 Grad Norm 1.644910 0.12s/it\n","Train loss 26137 0.680442 Grad Norm 1.944854 0.15s/it\n","Train loss 26138 0.472921 Grad Norm 1.007202 0.13s/it\n","Train loss 26139 0.584258 Grad Norm 1.361570 0.12s/it\n","Train loss 26140 0.381938 Grad Norm 1.985676 0.11s/it\n","Train loss 26141 0.601806 Grad Norm 1.163939 0.11s/it\n","Train loss 26142 0.692852 Grad Norm 4.444523 0.11s/it\n","Train loss 26143 0.436115 Grad Norm 1.600199 0.10s/it\n","Train loss 26144 0.403536 Grad Norm 1.720964 0.11s/it\n","Train loss 26145 0.473230 Grad Norm 1.228548 0.12s/it\n","Train loss 26146 0.585875 Grad Norm 2.380354 0.13s/it\n","Train loss 26147 0.380440 Grad Norm 0.752126 0.14s/it\n","Train loss 26148 0.480464 Grad Norm 1.504083 0.12s/it\n","Train loss 26149 0.417721 Grad Norm 0.743441 0.11s/it\n","Train loss 26150 0.381133 Grad Norm 1.035342 0.18s/it\n","Train loss 26151 0.563636 Grad Norm 0.978949 0.13s/it\n","Train loss 26152 0.422754 Grad Norm 1.837846 0.14s/it\n","Train loss 26153 0.374858 Grad Norm 0.962219 0.13s/it\n","Train loss 26154 0.273144 Grad Norm 0.439391 0.10s/it\n","Train loss 26155 0.445067 Grad Norm 2.605157 0.11s/it\n","Train loss 26156 0.739090 Grad Norm 3.793259 0.12s/it\n","Train loss 26157 0.496254 Grad Norm 0.849631 0.12s/it\n","Train loss 26158 0.612043 Grad Norm 1.397672 0.14s/it\n","Train loss 26159 0.392898 Grad Norm 0.771765 0.11s/it\n","Train loss 26160 0.481487 Grad Norm 1.717197 0.13s/it\n","Train loss 26161 0.735881 Grad Norm 2.371825 0.12s/it\n","Train loss 26162 0.581658 Grad Norm 1.051972 0.12s/it\n","Train loss 26163 0.464612 Grad Norm 1.514080 0.12s/it\n","Train loss 26164 0.351045 Grad Norm 1.090130 0.13s/it\n","Train loss 26165 0.303789 Grad Norm 0.778777 0.11s/it\n","Train loss 26166 0.786206 Grad Norm 6.408427 0.12s/it\n","Train loss 26167 0.523678 Grad Norm 3.356176 0.13s/it\n","Train loss 26168 0.663491 Grad Norm 1.933197 0.11s/it\n","Train loss 26169 0.491124 Grad Norm 1.147708 0.11s/it\n","Train loss 26170 0.425035 Grad Norm 2.027250 0.16s/it\n","Train loss 26171 0.550361 Grad Norm 1.872794 0.13s/it\n","Train loss 26172 0.758117 Grad Norm 2.172142 0.12s/it\n","Train loss 26173 0.503782 Grad Norm 1.148172 0.12s/it\n","Train loss 26174 0.497672 Grad Norm 0.761388 0.15s/it\n","Train loss 26175 0.541658 Grad Norm 1.459640 0.14s/it\n","Train loss 26176 0.731882 Grad Norm 1.435434 0.10s/it\n","Train loss 26177 0.579301 Grad Norm 2.309280 0.15s/it\n","Train loss 26178 0.554365 Grad Norm 2.583259 0.11s/it\n","Train loss 26179 0.435624 Grad Norm 2.117551 0.13s/it\n","Train loss 26180 0.474779 Grad Norm 1.267124 0.11s/it\n","Train loss 26181 1.048384 Grad Norm 2.190847 0.12s/it\n","Train loss 26182 0.531453 Grad Norm 0.977508 0.13s/it\n","Train loss 26183 0.602986 Grad Norm 1.033444 0.14s/it\n","Train loss 26184 0.440420 Grad Norm 1.032637 0.11s/it\n","Train loss 26185 0.622622 Grad Norm 3.371625 0.10s/it\n","Train loss 26186 0.605936 Grad Norm 2.610102 0.15s/it\n","Train loss 26187 0.484272 Grad Norm 1.780024 0.12s/it\n","Train loss 26188 0.638504 Grad Norm 1.644022 0.12s/it\n","Train loss 26189 0.362517 Grad Norm 2.495353 0.11s/it\n","Train loss 26190 0.565957 Grad Norm 1.164153 0.15s/it\n","Train loss 26191 0.560570 Grad Norm 1.261722 0.11s/it\n","Train loss 26192 0.374210 Grad Norm 0.978553 0.13s/it\n","Train loss 26193 0.368128 Grad Norm 0.982945 0.13s/it\n","Train loss 26194 0.624424 Grad Norm 1.130096 0.13s/it\n","Train loss 26195 0.327627 Grad Norm 0.638724 0.10s/it\n","Train loss 26196 0.600312 Grad Norm 2.137674 0.12s/it\n","Train loss 26197 0.373554 Grad Norm 0.765109 0.14s/it\n","Train loss 26198 0.812534 Grad Norm 1.813413 0.13s/it\n","Train loss 26199 0.651059 Grad Norm 3.021313 0.14s/it\n","Train loss 26200 0.510705 Grad Norm 1.287741 0.11s/it\n","Train loss 26201 0.511061 Grad Norm 1.183213 0.13s/it\n","Train loss 26202 0.453395 Grad Norm 1.926491 0.15s/it\n","Train loss 26203 0.390019 Grad Norm 0.539971 0.14s/it\n","Train loss 26204 0.656294 Grad Norm 1.452380 0.13s/it\n","Train loss 26205 0.492339 Grad Norm 0.912550 0.12s/it\n","Train loss 26206 0.691558 Grad Norm 2.568544 0.12s/it\n","Train loss 26207 0.577747 Grad Norm 3.246956 0.12s/it\n","Train loss 26208 0.407694 Grad Norm 1.226084 0.13s/it\n","Train loss 26209 0.262459 Grad Norm 0.464390 0.14s/it\n","Train loss 26210 0.502175 Grad Norm 1.194633 0.11s/it\n","Train loss 26211 0.499105 Grad Norm 1.058338 0.10s/it\n","Train loss 26212 0.334667 Grad Norm 0.867600 0.16s/it\n","Train loss 26213 0.413162 Grad Norm 1.041009 0.15s/it\n","Train loss 26214 0.607317 Grad Norm 1.534852 0.14s/it\n","Train loss 26215 0.598720 Grad Norm 2.481830 0.12s/it\n","Train loss 26216 0.726960 Grad Norm 1.988903 0.12s/it\n","Train loss 26217 0.318577 Grad Norm 1.017591 0.11s/it\n","Train loss 26218 0.470593 Grad Norm 1.599475 0.16s/it\n","Train loss 26219 0.542764 Grad Norm 2.948357 0.12s/it\n","Train loss 26220 0.754906 Grad Norm 2.888876 0.14s/it\n","Train loss 26221 0.301331 Grad Norm 0.511385 0.10s/it\n","Train loss 26222 0.527506 Grad Norm 1.952201 0.12s/it\n","Train loss 26223 0.707725 Grad Norm 1.169482 0.11s/it\n","Train loss 26224 0.517063 Grad Norm 1.032585 0.11s/it\n","Train loss 26225 0.408992 Grad Norm 0.971854 0.13s/it\n","Train loss 26226 0.388773 Grad Norm 0.897838 0.12s/it\n","Train loss 26227 0.507038 Grad Norm 0.874612 0.13s/it\n","Train loss 26228 0.521438 Grad Norm 3.894413 0.10s/it\n","Train loss 26229 0.559153 Grad Norm 1.063639 0.11s/it\n","Train loss 26230 0.292090 Grad Norm 0.432885 0.13s/it\n","Train loss 26231 0.467832 Grad Norm 0.978046 0.12s/it\n","Train loss 26232 0.635376 Grad Norm 2.839926 0.13s/it\n","Train loss 26233 0.404286 Grad Norm 0.793248 0.15s/it\n","Train loss 26234 0.748763 Grad Norm 1.653620 0.11s/it\n","Train loss 26235 0.647411 Grad Norm 1.350905 0.11s/it\n","Train loss 26236 0.447008 Grad Norm 2.224007 0.14s/it\n","Train loss 26237 0.583298 Grad Norm 2.972350 0.10s/it\n","Train loss 26238 0.581325 Grad Norm 2.982399 0.13s/it\n","Train loss 26239 0.398937 Grad Norm 0.899721 0.10s/it\n","Train loss 26240 0.574335 Grad Norm 2.975258 0.12s/it\n","Train loss 26241 0.483556 Grad Norm 1.820728 0.12s/it\n","Train loss 26242 0.491786 Grad Norm 0.714148 0.15s/it\n","Train loss 26243 0.636479 Grad Norm 1.260599 0.11s/it\n","Train loss 26244 0.554778 Grad Norm 1.903713 0.11s/it\n","Train loss 26245 0.477408 Grad Norm 0.937903 0.13s/it\n","Train loss 26246 0.224236 Grad Norm 1.262982 0.13s/it\n","Train loss 26247 0.472558 Grad Norm 0.782387 0.14s/it\n","Train loss 26248 0.495046 Grad Norm 1.094352 0.10s/it\n","Train loss 26249 0.513471 Grad Norm 0.718865 0.14s/it\n","Train loss 26250 0.463785 Grad Norm 0.892185 0.15s/it\n","Train loss 26251 0.907955 Grad Norm 5.614001 0.10s/it\n","Train loss 26252 0.471084 Grad Norm 1.138004 0.10s/it\n","Train loss 26253 0.475729 Grad Norm 0.766979 0.14s/it\n","Train loss 26254 0.504826 Grad Norm 0.864184 0.14s/it\n","Train loss 26255 0.433151 Grad Norm 0.868306 0.10s/it\n","Train loss 26256 0.402103 Grad Norm 1.164360 0.15s/it\n","Train loss 26257 0.369393 Grad Norm 0.880169 0.11s/it\n","Train loss 26258 0.691637 Grad Norm 1.263719 0.13s/it\n","Train loss 26259 0.655469 Grad Norm 1.130852 0.11s/it\n","Train loss 26260 0.444969 Grad Norm 1.731882 0.11s/it\n","Train loss 26261 0.706690 Grad Norm 0.817719 0.12s/it\n","Train loss 26262 0.718537 Grad Norm 1.536738 0.13s/it\n","Train loss 26263 0.485256 Grad Norm 1.235161 0.11s/it\n","Train loss 26264 0.567993 Grad Norm 1.334393 0.11s/it\n","Train loss 26265 0.539904 Grad Norm 1.400178 0.12s/it\n","Train loss 26266 0.619035 Grad Norm 1.310536 0.11s/it\n","Train loss 26267 0.531174 Grad Norm 0.942331 0.11s/it\n","Train loss 26268 0.453214 Grad Norm 1.471504 0.12s/it\n","Train loss 26269 0.484221 Grad Norm 1.517233 0.14s/it\n","Train loss 26270 0.443168 Grad Norm 0.621275 0.13s/it\n","Train loss 26271 0.500994 Grad Norm 1.332023 0.12s/it\n","Train loss 26272 0.455619 Grad Norm 1.612615 0.14s/it\n","Train loss 26273 0.363462 Grad Norm 2.865407 0.14s/it\n","Train loss 26274 0.563701 Grad Norm 2.117392 0.12s/it\n","Train loss 26275 0.741745 Grad Norm 2.099318 0.13s/it\n","Train loss 26276 0.448999 Grad Norm 0.618933 0.12s/it\n","Train loss 26277 0.722120 Grad Norm 2.171785 0.13s/it\n","Train loss 26278 0.630237 Grad Norm 2.295675 0.15s/it\n","Train loss 26279 0.744838 Grad Norm 1.887799 0.14s/it\n","Train loss 26280 0.494293 Grad Norm 0.707878 0.13s/it\n","Train loss 26281 0.748986 Grad Norm 1.576684 0.11s/it\n","Train loss 26282 0.488094 Grad Norm 1.167802 0.12s/it\n","Train loss 26283 0.426405 Grad Norm 1.881935 0.13s/it\n","Train loss 26284 0.436561 Grad Norm 0.997335 0.14s/it\n","Train loss 26285 0.783006 Grad Norm 1.896377 0.12s/it\n","Train loss 26286 0.392436 Grad Norm 0.496399 0.11s/it\n","Train loss 26287 0.428966 Grad Norm 1.373896 0.13s/it\n","Train loss 26288 0.596830 Grad Norm 3.948667 0.13s/it\n","Train loss 26289 0.609511 Grad Norm 1.198228 0.13s/it\n","Train loss 26290 0.489629 Grad Norm 0.968144 0.15s/it\n","Train loss 26291 0.469701 Grad Norm 1.083135 0.12s/it\n","Train loss 26292 0.316776 Grad Norm 1.049847 0.12s/it\n","Train loss 26293 0.500871 Grad Norm 1.401846 0.12s/it\n","Train loss 26294 0.386386 Grad Norm 0.888368 0.10s/it\n","Train loss 26295 0.560585 Grad Norm 0.846061 0.10s/it\n","Train loss 26296 0.557665 Grad Norm 1.865852 0.12s/it\n","Train loss 26297 0.609624 Grad Norm 2.228038 0.11s/it\n","Train loss 26298 0.339774 Grad Norm 0.569362 0.11s/it\n","Train loss 26299 0.550014 Grad Norm 1.659363 0.14s/it\n","Train loss 26300 0.300657 Grad Norm 0.606380 0.14s/it\n","Train loss 26301 0.240964 Grad Norm 0.314112 0.10s/it\n","Train loss 26302 0.491851 Grad Norm 3.338746 0.13s/it\n","Train loss 26303 0.540326 Grad Norm 1.305720 0.15s/it\n","Train loss 26304 0.412496 Grad Norm 0.659493 0.13s/it\n","Train loss 26305 0.372790 Grad Norm 1.006552 0.10s/it\n","Train loss 26306 0.359545 Grad Norm 0.700458 0.12s/it\n","Train loss 26307 0.458802 Grad Norm 1.074655 0.14s/it\n","Train loss 26308 0.653802 Grad Norm 1.559195 0.15s/it\n","Train loss 26309 0.471421 Grad Norm 1.901017 0.10s/it\n","Train loss 26310 0.546710 Grad Norm 0.991476 0.11s/it\n","Train loss 26311 0.586873 Grad Norm 2.079798 0.14s/it\n","Train loss 26312 0.492192 Grad Norm 5.669299 0.11s/it\n","Train loss 26313 0.429273 Grad Norm 0.508760 0.10s/it\n","Train loss 26314 0.714935 Grad Norm 1.656114 0.11s/it\n","Train loss 26315 0.832645 Grad Norm 1.604155 0.13s/it\n","Train loss 26316 0.559900 Grad Norm 3.057140 0.11s/it\n","Train loss 26317 0.491946 Grad Norm 0.955622 0.14s/it\n","Train loss 26318 0.445052 Grad Norm 1.394083 0.13s/it\n","Train loss 26319 0.570530 Grad Norm 1.080647 0.11s/it\n","Train loss 26320 0.392623 Grad Norm 1.235751 0.14s/it\n","Train loss 26321 0.645921 Grad Norm 1.422935 0.13s/it\n","Train loss 26322 0.542910 Grad Norm 3.809195 0.13s/it\n","Train loss 26323 0.578782 Grad Norm 5.128320 0.11s/it\n","Train loss 26324 0.767428 Grad Norm 5.856946 0.10s/it\n","Train loss 26325 0.622557 Grad Norm 1.776840 0.10s/it\n","Train loss 26326 0.477173 Grad Norm 2.253991 0.13s/it\n","Train loss 26327 0.726197 Grad Norm 2.037024 0.11s/it\n","Train loss 26328 0.543910 Grad Norm 1.431421 0.12s/it\n","Train loss 26329 0.567480 Grad Norm 1.123488 0.14s/it\n","Train loss 26330 0.575120 Grad Norm 3.100971 0.13s/it\n","Train loss 26331 0.756472 Grad Norm 1.238761 0.13s/it\n","Train loss 26332 0.446069 Grad Norm 1.511945 0.09s/it\n","Train loss 26333 0.586984 Grad Norm 0.946458 0.13s/it\n","Train loss 26334 0.523093 Grad Norm 1.048976 0.15s/it\n","Train loss 26335 0.507179 Grad Norm 1.113881 0.13s/it\n","Train loss 26336 0.534836 Grad Norm 2.037320 0.12s/it\n","Train loss 26337 0.450355 Grad Norm 0.948285 0.12s/it\n","Train loss 26338 0.453209 Grad Norm 2.290346 0.10s/it\n","Train loss 26339 0.541351 Grad Norm 0.987723 0.12s/it\n","Train loss 26340 0.555797 Grad Norm 2.395290 0.11s/it\n","Train loss 26341 0.559758 Grad Norm 1.363308 0.13s/it\n","Train loss 26342 0.529200 Grad Norm 1.298310 0.12s/it\n","Train loss 26343 0.294473 Grad Norm 0.456738 0.14s/it\n","Train loss 26344 0.621312 Grad Norm 1.767620 0.11s/it\n","Train loss 26345 0.548308 Grad Norm 1.924100 0.12s/it\n","Train loss 26346 0.696121 Grad Norm 1.828845 0.13s/it\n","Train loss 26347 0.618466 Grad Norm 1.347645 0.10s/it\n","Train loss 26348 0.557725 Grad Norm 1.345554 0.10s/it\n","Train loss 26349 0.776014 Grad Norm 2.046653 0.11s/it\n","Train loss 26350 0.702702 Grad Norm 1.842790 0.12s/it\n","Train loss 26351 0.613847 Grad Norm 0.754809 0.11s/it\n","Train loss 26352 0.610639 Grad Norm 1.125318 0.10s/it\n","Train loss 26353 0.637199 Grad Norm 1.200982 0.13s/it\n","Train loss 26354 0.507842 Grad Norm 0.782904 0.13s/it\n","Train loss 26355 0.514490 Grad Norm 1.923314 0.11s/it\n","Train loss 26356 0.354555 Grad Norm 1.206850 0.10s/it\n","Train loss 26357 0.803182 Grad Norm 2.891757 0.10s/it\n","Train loss 26358 0.592609 Grad Norm 1.160256 0.13s/it\n","Train loss 26359 0.336629 Grad Norm 1.064489 0.14s/it\n","Train loss 26360 0.540597 Grad Norm 1.487414 0.14s/it\n","Train loss 26361 0.385922 Grad Norm 0.981053 0.13s/it\n","Train loss 26362 0.656358 Grad Norm 1.100814 0.11s/it\n","Train loss 26363 0.401572 Grad Norm 0.924653 0.11s/it\n","Train loss 26364 0.570641 Grad Norm 1.937384 0.11s/it\n","Train loss 26365 0.626061 Grad Norm 2.902615 0.11s/it\n","Train loss 26366 0.687021 Grad Norm 1.962761 0.11s/it\n","Train loss 26367 0.581931 Grad Norm 2.054761 0.12s/it\n","Train loss 26368 0.364382 Grad Norm 1.553190 0.14s/it\n","Train loss 26369 0.530211 Grad Norm 1.351059 0.14s/it\n","Train loss 26370 0.812156 Grad Norm 2.095410 0.13s/it\n","Train loss 26371 0.675749 Grad Norm 1.095853 0.11s/it\n","Train loss 26372 0.516177 Grad Norm 1.795585 0.13s/it\n","Train loss 26373 0.386806 Grad Norm 1.293359 0.14s/it\n","Train loss 26374 0.805048 Grad Norm 3.088444 0.12s/it\n","Train loss 26375 0.416032 Grad Norm 0.849285 0.12s/it\n","Train loss 26376 0.663875 Grad Norm 3.408103 0.11s/it\n","Train loss 26377 0.782838 Grad Norm 2.542303 0.12s/it\n","Train loss 26378 0.777090 Grad Norm 3.423789 0.11s/it\n","Train loss 26379 0.570533 Grad Norm 0.827168 0.12s/it\n","Train loss 26380 0.439392 Grad Norm 1.218193 0.12s/it\n","Train loss 26381 0.389760 Grad Norm 0.739967 0.11s/it\n","Train loss 26382 0.668031 Grad Norm 1.388197 0.10s/it\n","Train loss 26383 0.457665 Grad Norm 0.930619 0.12s/it\n","Train loss 26384 0.631074 Grad Norm 1.964525 0.15s/it\n","Train loss 26385 0.593549 Grad Norm 1.779288 0.12s/it\n","Train loss 26386 0.497254 Grad Norm 1.063130 0.16s/it\n","Train loss 26387 0.779994 Grad Norm 2.366207 0.13s/it\n","Train loss 26388 0.548344 Grad Norm 2.146170 0.11s/it\n","Train loss 26389 0.597548 Grad Norm 0.902318 0.15s/it\n","Train loss 26390 0.561378 Grad Norm 2.632724 0.10s/it\n","Train loss 26391 0.443218 Grad Norm 1.892680 0.13s/it\n","Train loss 26392 0.866378 Grad Norm 2.800655 0.11s/it\n","Train loss 26393 0.803056 Grad Norm 2.817959 0.13s/it\n","Train loss 26394 0.374460 Grad Norm 0.968829 0.14s/it\n","Train loss 26395 0.692236 Grad Norm 1.378279 0.11s/it\n","Train loss 26396 0.476663 Grad Norm 1.069136 0.11s/it\n","Train loss 26397 0.793466 Grad Norm 1.556647 0.11s/it\n","Train loss 26398 0.650832 Grad Norm 1.772641 0.10s/it\n","Train loss 26399 0.440167 Grad Norm 1.114772 0.13s/it\n","Train loss 26400 0.443446 Grad Norm 0.649860 0.12s/it\n","Train loss 26401 0.402043 Grad Norm 0.997191 0.15s/it\n","Train loss 26402 0.705202 Grad Norm 0.943809 0.13s/it\n","Train loss 26403 0.481192 Grad Norm 4.496308 0.13s/it\n","Train loss 26404 0.558705 Grad Norm 1.648119 0.14s/it\n","Train loss 26405 0.453105 Grad Norm 2.144737 0.11s/it\n","Train loss 26406 0.629473 Grad Norm 1.855726 0.13s/it\n","Train loss 26407 0.380221 Grad Norm 0.460687 0.13s/it\n","Train loss 26408 0.410681 Grad Norm 1.118555 0.14s/it\n","Train loss 26409 0.387694 Grad Norm 1.320412 0.11s/it\n","Train loss 26410 0.620365 Grad Norm 2.386138 0.11s/it\n","Train loss 26411 0.907493 Grad Norm 2.101884 0.12s/it\n","Train loss 26412 0.505641 Grad Norm 1.220699 0.12s/it\n","Train loss 26413 0.690450 Grad Norm 1.973545 0.12s/it\n","Train loss 26414 0.528797 Grad Norm 0.731569 0.12s/it\n","Train loss 26415 0.475718 Grad Norm 0.663154 0.12s/it\n","Train loss 26416 0.519875 Grad Norm 1.556073 0.16s/it\n","Train loss 26417 0.457453 Grad Norm 0.892235 0.11s/it\n","Train loss 26418 0.536006 Grad Norm 1.578384 0.13s/it\n","Train loss 26419 0.406985 Grad Norm 0.997736 0.15s/it\n","Train loss 26420 0.449698 Grad Norm 1.095098 0.15s/it\n","Train loss 26421 0.783409 Grad Norm 3.260125 0.12s/it\n","Train loss 26422 0.474459 Grad Norm 0.949642 0.13s/it\n","Train loss 26423 0.693946 Grad Norm 1.323228 0.13s/it\n","Train loss 26424 0.507645 Grad Norm 1.593081 0.12s/it\n","Train loss 26425 0.508865 Grad Norm 1.500543 0.12s/it\n","Train loss 26426 0.446664 Grad Norm 1.604529 0.13s/it\n","Train loss 26427 0.793419 Grad Norm 1.117436 0.11s/it\n","Train loss 26428 0.464348 Grad Norm 0.990882 0.15s/it\n","Train loss 26429 0.527896 Grad Norm 1.432522 0.13s/it\n","Train loss 26430 0.527813 Grad Norm 1.094112 0.13s/it\n","Train loss 26431 0.362634 Grad Norm 1.500516 0.09s/it\n","Train loss 26432 0.417874 Grad Norm 0.854047 0.14s/it\n","Train loss 26433 0.764572 Grad Norm 1.132244 0.11s/it\n","Train loss 26434 0.641157 Grad Norm 1.233582 0.12s/it\n","Train loss 26435 0.365591 Grad Norm 0.436609 0.12s/it\n","Train loss 26436 0.712966 Grad Norm 3.571059 0.13s/it\n","Train loss 26437 0.335409 Grad Norm 0.824780 0.16s/it\n","Train loss 26438 0.573309 Grad Norm 1.791769 0.14s/it\n","Train loss 26439 0.475730 Grad Norm 1.959732 0.11s/it\n","Train loss 26440 0.810811 Grad Norm 1.593832 0.11s/it\n","Train loss 26441 0.407183 Grad Norm 1.103669 0.11s/it\n","Train loss 26442 0.566853 Grad Norm 1.724525 0.10s/it\n","Train loss 26443 0.649801 Grad Norm 1.558185 0.12s/it\n","Train loss 26444 0.485492 Grad Norm 0.639276 0.14s/it\n","Train loss 26445 0.636159 Grad Norm 1.051566 0.13s/it\n","Train loss 26446 0.501157 Grad Norm 0.758485 0.13s/it\n","Train loss 26447 0.718802 Grad Norm 3.475359 0.13s/it\n","Train loss 26448 0.432479 Grad Norm 1.399590 0.12s/it\n","Train loss 26449 0.534803 Grad Norm 3.662222 0.10s/it\n","Train loss 26450 0.652172 Grad Norm 2.063607 0.14s/it\n","Train loss 26451 0.357085 Grad Norm 1.456577 0.15s/it\n","Train loss 26452 0.470926 Grad Norm 0.884529 0.14s/it\n","Train loss 26453 0.541149 Grad Norm 3.598320 0.13s/it\n","Train loss 26454 0.644818 Grad Norm 4.855481 0.11s/it\n","Train loss 26455 0.514392 Grad Norm 1.393324 0.12s/it\n","Train loss 26456 0.460682 Grad Norm 1.012822 0.12s/it\n","Train loss 26457 0.778704 Grad Norm 2.423542 0.10s/it\n","Train loss 26458 0.697132 Grad Norm 1.967543 0.11s/it\n","Train loss 26459 0.510608 Grad Norm 0.733568 0.10s/it\n","Train loss 26460 0.479170 Grad Norm 1.306566 0.17s/it\n","Train loss 26461 0.654479 Grad Norm 1.406941 0.14s/it\n","Train loss 26462 0.340450 Grad Norm 0.450806 0.12s/it\n","Train loss 26463 0.572691 Grad Norm 2.879755 0.13s/it\n","Train loss 26464 0.662676 Grad Norm 1.686394 0.12s/it\n","Train loss 26465 0.512489 Grad Norm 1.029734 0.12s/it\n","Train loss 26466 0.638107 Grad Norm 3.888177 0.11s/it\n","Train loss 26467 0.765847 Grad Norm 2.229088 0.13s/it\n","Train loss 26468 0.598390 Grad Norm 1.179587 0.13s/it\n","Train loss 26469 0.478237 Grad Norm 1.043482 0.13s/it\n","Train loss 26470 0.661241 Grad Norm 2.318069 0.11s/it\n","Train loss 26471 0.446100 Grad Norm 1.554554 0.14s/it\n","Train loss 26472 0.565421 Grad Norm 1.056881 0.11s/it\n","Train loss 26473 0.776465 Grad Norm 4.161097 0.12s/it\n","Train loss 26474 0.431932 Grad Norm 0.784861 0.15s/it\n","Train loss 26475 0.597518 Grad Norm 1.390337 0.12s/it\n","Train loss 26476 0.529452 Grad Norm 2.170386 0.13s/it\n","Train loss 26477 0.323518 Grad Norm 0.598392 0.11s/it\n","Train loss 26478 0.501190 Grad Norm 1.529666 0.10s/it\n","Train loss 26479 0.486165 Grad Norm 0.876716 0.14s/it\n","Train loss 26480 0.441544 Grad Norm 0.767210 0.14s/it\n","Train loss 26481 0.458446 Grad Norm 2.208837 0.11s/it\n","Train loss 26482 0.609588 Grad Norm 0.980188 0.16s/it\n","Train loss 26483 0.867609 Grad Norm 1.751544 0.13s/it\n","Train loss 26484 0.368450 Grad Norm 1.603428 0.15s/it\n","Train loss 26485 0.476674 Grad Norm 1.020023 0.10s/it\n","Train loss 26486 0.571047 Grad Norm 0.650425 0.13s/it\n","Train loss 26487 0.403343 Grad Norm 1.001971 0.11s/it\n","Train loss 26488 0.649284 Grad Norm 2.185991 0.10s/it\n","Train loss 26489 0.466172 Grad Norm 0.897184 0.12s/it\n","Train loss 26490 0.461125 Grad Norm 0.960740 0.11s/it\n","Train loss 26491 0.708898 Grad Norm 1.351322 0.11s/it\n","Train loss 26492 0.646363 Grad Norm 1.356766 0.14s/it\n","Train loss 26493 0.758666 Grad Norm 1.269353 0.12s/it\n","Train loss 26494 0.416921 Grad Norm 0.775529 0.10s/it\n","Train loss 26495 0.538955 Grad Norm 1.131284 0.11s/it\n","Train loss 26496 0.495104 Grad Norm 0.978903 0.13s/it\n","Train loss 26497 0.701507 Grad Norm 1.771156 0.12s/it\n","Train loss 26498 0.623096 Grad Norm 1.112784 0.12s/it\n","Train loss 26499 0.472939 Grad Norm 0.773330 0.14s/it\n","Train loss 26500 0.285570 Grad Norm 0.436873 0.12s/it\n","Train loss 26501 0.635538 Grad Norm 2.094396 0.11s/it\n","Train loss 26502 0.423396 Grad Norm 0.750089 0.11s/it\n","Train loss 26503 0.485557 Grad Norm 1.251373 0.11s/it\n","Train loss 26504 0.769368 Grad Norm 2.145572 0.12s/it\n","Train loss 26505 0.607665 Grad Norm 0.687794 0.15s/it\n","Train loss 26506 0.630003 Grad Norm 0.964189 0.14s/it\n","Train loss 26507 0.623578 Grad Norm 1.627126 0.13s/it\n","Train loss 26508 0.363059 Grad Norm 0.977108 0.13s/it\n","Train loss 26509 0.604467 Grad Norm 2.343520 0.12s/it\n","Train loss 26510 0.501405 Grad Norm 0.931830 0.10s/it\n","Train loss 26511 0.571899 Grad Norm 1.619457 0.11s/it\n","Train loss 26512 0.549654 Grad Norm 0.897145 0.12s/it\n","Train loss 26513 0.403312 Grad Norm 1.214213 0.15s/it\n","Train loss 26514 0.567755 Grad Norm 1.190387 0.11s/it\n","Train loss 26515 0.586718 Grad Norm 0.913466 0.12s/it\n","Train loss 26516 0.710484 Grad Norm 1.861190 0.12s/it\n","Train loss 26517 0.501842 Grad Norm 2.488664 0.11s/it\n","Train loss 26518 0.973057 Grad Norm 4.787536 0.11s/it\n","Train loss 26519 0.504494 Grad Norm 0.825122 0.13s/it\n","Train loss 26520 0.715650 Grad Norm 2.451336 0.11s/it\n","Train loss 26521 0.421161 Grad Norm 1.386761 0.13s/it\n","Train loss 26522 0.708454 Grad Norm 1.833042 0.13s/it\n","Train loss 26523 0.489293 Grad Norm 1.647513 0.13s/it\n","Train loss 26524 0.527842 Grad Norm 1.371946 0.14s/it\n","Train loss 26525 0.445731 Grad Norm 1.035027 0.12s/it\n","Train loss 26526 0.512327 Grad Norm 1.530747 0.14s/it\n","Train loss 26527 0.821915 Grad Norm 2.471524 0.13s/it\n","Train loss 26528 0.583870 Grad Norm 2.388833 0.13s/it\n","Train loss 26529 0.495512 Grad Norm 1.454447 0.12s/it\n","Train loss 26530 0.448464 Grad Norm 1.137980 0.13s/it\n","Train loss 26531 0.438563 Grad Norm 0.844516 0.10s/it\n","Train loss 26532 0.404396 Grad Norm 0.575515 0.13s/it\n","Train loss 26533 0.480102 Grad Norm 1.984730 0.11s/it\n","Train loss 26534 0.430764 Grad Norm 1.096668 0.13s/it\n","Train loss 26535 0.538087 Grad Norm 1.286514 0.11s/it\n","Train loss 26536 0.560277 Grad Norm 1.250859 0.12s/it\n","Train loss 26537 0.579007 Grad Norm 1.703558 0.10s/it\n","Train loss 26538 0.494784 Grad Norm 2.756985 0.11s/it\n","Train loss 26539 0.499042 Grad Norm 0.714340 0.11s/it\n","Train loss 26540 0.337361 Grad Norm 0.435099 0.10s/it\n","Train loss 26541 0.494598 Grad Norm 2.836096 0.15s/it\n","Train loss 26542 0.530089 Grad Norm 0.855814 0.15s/it\n","Train loss 26543 0.506806 Grad Norm 1.074909 0.13s/it\n","Train loss 26544 0.618376 Grad Norm 2.270319 0.12s/it\n","Train loss 26545 0.380496 Grad Norm 0.866514 0.09s/it\n","Train loss 26546 0.536649 Grad Norm 1.910229 0.12s/it\n","Train loss 26547 0.531973 Grad Norm 2.168217 0.14s/it\n","Train loss 26548 0.575840 Grad Norm 2.345978 0.12s/it\n","Train loss 26549 0.725253 Grad Norm 1.894619 0.12s/it\n","Train loss 26550 0.393738 Grad Norm 0.692469 0.12s/it\n","Train loss 26551 0.381904 Grad Norm 1.238253 0.10s/it\n","Train loss 26552 0.506131 Grad Norm 0.896358 0.11s/it\n","Train loss 26553 0.326425 Grad Norm 0.765174 0.14s/it\n","Train loss 26554 0.512514 Grad Norm 0.545527 0.15s/it\n","Train loss 26555 0.481707 Grad Norm 1.166937 0.13s/it\n","Train loss 26556 0.456669 Grad Norm 1.583706 0.13s/it\n","Train loss 26557 0.426116 Grad Norm 6.762393 0.11s/it\n","Train loss 26558 0.254970 Grad Norm 0.417811 0.12s/it\n","Train loss 26559 0.523882 Grad Norm 1.641595 0.14s/it\n","Train loss 26560 0.585177 Grad Norm 1.475900 0.12s/it\n","Train loss 26561 0.646263 Grad Norm 4.334345 0.11s/it\n","Train loss 26562 0.705306 Grad Norm 3.303255 0.12s/it\n","Train loss 26563 0.539661 Grad Norm 2.563617 0.12s/it\n","Train loss 26564 0.482189 Grad Norm 4.259871 0.11s/it\n","Train loss 26565 0.331494 Grad Norm 0.820866 0.14s/it\n","Train loss 26566 0.530326 Grad Norm 0.966225 0.13s/it\n","Train loss 26567 0.477001 Grad Norm 1.613242 0.12s/it\n","Train loss 26568 0.355104 Grad Norm 0.727365 0.11s/it\n","Train loss 26569 0.553938 Grad Norm 5.038140 0.11s/it\n","Train loss 26570 0.426043 Grad Norm 2.305419 0.10s/it\n","Train loss 26571 0.595407 Grad Norm 1.783279 0.11s/it\n","Train loss 26572 0.419297 Grad Norm 0.955701 0.13s/it\n","Train loss 26573 0.439797 Grad Norm 1.002612 0.13s/it\n","Train loss 26574 0.728306 Grad Norm 2.162164 0.11s/it\n","Train loss 26575 0.482893 Grad Norm 2.328552 0.10s/it\n","Train loss 26576 0.668163 Grad Norm 1.665988 0.10s/it\n","Train loss 26577 0.617472 Grad Norm 1.414553 0.13s/it\n","Train loss 26578 0.720194 Grad Norm 1.666977 0.14s/it\n","Train loss 26579 0.506733 Grad Norm 0.798902 0.14s/it\n","Train loss 26580 0.429144 Grad Norm 2.156070 0.13s/it\n","Train loss 26581 0.485717 Grad Norm 1.851104 0.10s/it\n","Train loss 26582 0.499216 Grad Norm 1.186864 0.10s/it\n","Train loss 26583 0.746895 Grad Norm 1.144066 0.13s/it\n","Train loss 26584 0.738622 Grad Norm 2.582565 0.12s/it\n","Train loss 26585 0.829926 Grad Norm 2.622685 0.12s/it\n","Train loss 26586 0.503424 Grad Norm 1.751538 0.15s/it\n","Train loss 26587 0.386128 Grad Norm 4.182691 0.11s/it\n","Train loss 26588 0.579662 Grad Norm 3.249308 0.12s/it\n","Train loss 26589 0.552748 Grad Norm 1.435017 0.12s/it\n","Train loss 26590 0.595287 Grad Norm 2.053052 0.11s/it\n","Train loss 26591 0.496856 Grad Norm 2.474693 0.11s/it\n","Train loss 26592 0.333091 Grad Norm 0.811271 0.12s/it\n","Train loss 26593 0.713224 Grad Norm 2.098229 0.10s/it\n","Train loss 26594 0.460465 Grad Norm 1.448084 0.12s/it\n","Train loss 26595 0.688446 Grad Norm 2.373395 0.11s/it\n","Train loss 26596 0.696160 Grad Norm 2.128518 0.10s/it\n","Train loss 26597 0.459659 Grad Norm 1.876948 0.12s/it\n","Train loss 26598 0.611870 Grad Norm 1.604027 0.11s/it\n","Train loss 26599 0.370298 Grad Norm 0.951352 0.14s/it\n","Train loss 26600 0.615310 Grad Norm 6.886948 0.11s/it\n","Train loss 26601 0.632286 Grad Norm 2.009876 0.13s/it\n","Train loss 26602 0.488308 Grad Norm 1.396372 0.14s/it\n","Train loss 26603 0.887143 Grad Norm 2.617719 0.11s/it\n","Train loss 26604 0.512975 Grad Norm 1.946805 0.13s/it\n","Train loss 26605 0.601759 Grad Norm 1.894274 0.13s/it\n","Train loss 26606 0.666370 Grad Norm 1.218729 0.13s/it\n","Train loss 26607 0.522193 Grad Norm 1.429476 0.12s/it\n","Train loss 26608 0.335714 Grad Norm 0.769295 0.14s/it\n","Train loss 26609 0.594560 Grad Norm 1.906137 0.12s/it\n","Train loss 26610 0.706167 Grad Norm 1.068065 0.11s/it\n","Train loss 26611 0.533394 Grad Norm 1.900689 0.14s/it\n","Train loss 26612 0.419213 Grad Norm 1.789920 0.12s/it\n","Train loss 26613 0.443002 Grad Norm 1.535312 0.13s/it\n","Train loss 26614 0.499930 Grad Norm 1.735980 0.13s/it\n","Train loss 26615 0.434281 Grad Norm 0.875141 0.13s/it\n","Train loss 26616 0.506914 Grad Norm 3.220526 0.16s/it\n","Train loss 26617 0.392554 Grad Norm 0.691621 0.15s/it\n","Train loss 26618 0.384793 Grad Norm 0.624851 0.11s/it\n","Train loss 26619 0.581635 Grad Norm 2.255925 0.11s/it\n","Train loss 26620 0.388550 Grad Norm 0.535531 0.11s/it\n","Train loss 26621 0.557226 Grad Norm 1.717023 0.12s/it\n","Train loss 26622 0.487836 Grad Norm 0.950147 0.15s/it\n","Train loss 26623 0.650263 Grad Norm 3.659791 0.14s/it\n","Train loss 26624 0.718186 Grad Norm 1.602827 0.12s/it\n","Train loss 26625 0.502468 Grad Norm 1.341325 0.12s/it\n","Train loss 26626 0.672285 Grad Norm 3.152640 0.12s/it\n","Train loss 26627 0.288544 Grad Norm 0.524494 0.12s/it\n","Train loss 26628 0.524342 Grad Norm 1.132583 0.13s/it\n","Train loss 26629 0.487555 Grad Norm 1.437307 0.13s/it\n","Train loss 26630 0.352313 Grad Norm 0.687140 0.12s/it\n","Train loss 26631 0.354435 Grad Norm 1.500232 0.15s/it\n","Train loss 26632 0.454606 Grad Norm 1.854690 0.11s/it\n","Train loss 26633 0.663393 Grad Norm 1.684217 0.14s/it\n","Train loss 26634 0.417086 Grad Norm 0.777151 0.11s/it\n","Train loss 26635 0.516555 Grad Norm 0.525251 0.10s/it\n","Train loss 26636 0.775120 Grad Norm 2.194834 0.12s/it\n","Train loss 26637 0.600555 Grad Norm 1.800514 0.11s/it\n","Train loss 26638 0.437914 Grad Norm 0.735184 0.12s/it\n","Train loss 26639 0.402972 Grad Norm 0.576174 0.15s/it\n","Train loss 26640 0.754649 Grad Norm 1.551298 0.12s/it\n","Train loss 26641 0.702357 Grad Norm 1.044135 0.11s/it\n","Train loss 26642 0.351264 Grad Norm 0.701947 0.15s/it\n","Train loss 26643 0.731252 Grad Norm 3.209841 0.10s/it\n","Train loss 26644 0.432119 Grad Norm 0.812143 0.10s/it\n","Train loss 26645 0.640752 Grad Norm 1.334773 0.15s/it\n","Train loss 26646 0.687320 Grad Norm 2.152781 0.11s/it\n","Train loss 26647 0.370948 Grad Norm 0.975850 0.13s/it\n","Train loss 26648 0.651241 Grad Norm 1.810862 0.13s/it\n","Train loss 26649 0.636080 Grad Norm 1.727835 0.16s/it\n","Train loss 26650 0.464540 Grad Norm 1.730280 0.13s/it\n","Train loss 26651 0.466372 Grad Norm 2.767720 0.11s/it\n","Train loss 26652 0.785551 Grad Norm 0.884601 0.13s/it\n","Train loss 26653 0.729948 Grad Norm 1.763246 0.11s/it\n","Train loss 26654 0.438401 Grad Norm 1.204056 0.11s/it\n","Train loss 26655 0.535723 Grad Norm 1.576780 0.12s/it\n","Train loss 26656 0.515404 Grad Norm 1.047428 0.12s/it\n","Train loss 26657 0.476391 Grad Norm 1.476268 0.13s/it\n","Train loss 26658 0.605250 Grad Norm 1.173147 0.13s/it\n","Train loss 26659 0.942443 Grad Norm 2.993430 0.14s/it\n","Train loss 26660 0.316554 Grad Norm 0.960837 0.11s/it\n","Train loss 26661 0.741157 Grad Norm 2.409829 0.11s/it\n","Train loss 26662 0.478004 Grad Norm 2.099997 0.13s/it\n","Train loss 26663 0.477313 Grad Norm 0.756463 0.11s/it\n","Train loss 26664 0.517739 Grad Norm 1.363491 0.12s/it\n","Train loss 26665 0.317411 Grad Norm 1.216038 0.15s/it\n","Train loss 26666 0.589611 Grad Norm 1.240386 0.11s/it\n","Train loss 26667 0.711029 Grad Norm 2.407157 0.14s/it\n","Train loss 26668 0.500384 Grad Norm 2.401369 0.13s/it\n","Train loss 26669 0.445343 Grad Norm 2.707116 0.12s/it\n","Train loss 26670 0.665692 Grad Norm 2.147903 0.13s/it\n","Train loss 26671 0.570813 Grad Norm 2.212126 0.12s/it\n","Train loss 26672 0.551447 Grad Norm 1.491082 0.12s/it\n","Train loss 26673 0.419775 Grad Norm 1.184814 0.11s/it\n","Train loss 26674 0.506868 Grad Norm 0.878274 0.13s/it\n","Train loss 26675 0.572355 Grad Norm 1.288180 0.14s/it\n","Train loss 26676 0.587938 Grad Norm 3.014821 0.10s/it\n","Train loss 26677 0.523757 Grad Norm 1.115413 0.13s/it\n","Train loss 26678 0.257886 Grad Norm 0.320009 0.11s/it\n","Train loss 26679 0.405521 Grad Norm 0.892795 0.10s/it\n","Train loss 26680 0.583618 Grad Norm 3.193396 0.11s/it\n","Train loss 26681 0.553413 Grad Norm 1.147129 0.12s/it\n","Train loss 26682 0.479179 Grad Norm 1.323900 0.13s/it\n","Train loss 26683 0.359459 Grad Norm 2.905581 0.14s/it\n","Train loss 26684 0.504253 Grad Norm 2.219736 0.12s/it\n","Train loss 26685 0.457661 Grad Norm 2.405798 0.12s/it\n","Train loss 26686 0.486472 Grad Norm 1.272916 0.14s/it\n","Train loss 26687 0.575576 Grad Norm 0.927338 0.15s/it\n","Train loss 26688 0.459338 Grad Norm 1.009218 0.13s/it\n","Train loss 26689 0.656231 Grad Norm 2.043318 0.10s/it\n","Train loss 26690 0.610678 Grad Norm 2.962431 0.10s/it\n","Train loss 26691 0.479481 Grad Norm 1.374851 0.12s/it\n","Train loss 26692 0.580370 Grad Norm 1.331825 0.12s/it\n","Train loss 26693 0.486135 Grad Norm 1.389579 0.11s/it\n","Train loss 26694 0.471816 Grad Norm 1.102835 0.13s/it\n","Train loss 26695 0.482803 Grad Norm 1.635611 0.17s/it\n","Train loss 26696 0.388264 Grad Norm 0.731883 0.13s/it\n","Train loss 26697 0.634023 Grad Norm 1.598065 0.11s/it\n","Train loss 26698 0.776923 Grad Norm 2.028752 0.11s/it\n","Train loss 26699 0.430617 Grad Norm 0.758782 0.13s/it\n","Train loss 26700 0.476585 Grad Norm 2.683675 0.13s/it\n","Train loss 26701 0.590655 Grad Norm 0.894527 0.14s/it\n","Train loss 26702 0.584705 Grad Norm 3.136154 0.13s/it\n","Train loss 26703 0.446873 Grad Norm 2.061737 0.13s/it\n","Train loss 26704 0.517616 Grad Norm 0.822266 0.11s/it\n","Train loss 26705 0.497622 Grad Norm 1.580216 0.12s/it\n","Train loss 26706 0.678469 Grad Norm 1.722345 0.14s/it\n","Train loss 26707 0.550476 Grad Norm 0.978105 0.12s/it\n","Train loss 26708 0.574046 Grad Norm 1.747711 0.12s/it\n","Train loss 26709 0.413578 Grad Norm 2.980227 0.14s/it\n","Train loss 26710 0.557801 Grad Norm 2.087935 0.13s/it\n","Train loss 26711 0.461101 Grad Norm 1.160216 0.12s/it\n","Train loss 26712 0.507533 Grad Norm 0.987774 0.12s/it\n","Train loss 26713 0.351724 Grad Norm 0.732077 0.10s/it\n","Train loss 26714 0.479288 Grad Norm 1.184709 0.11s/it\n","Train loss 26715 0.535508 Grad Norm 1.221195 0.11s/it\n","Train loss 26716 0.464421 Grad Norm 0.876525 0.12s/it\n","Train loss 26717 0.316862 Grad Norm 0.532719 0.10s/it\n","Train loss 26718 0.610072 Grad Norm 1.942067 0.13s/it\n","Train loss 26719 0.637033 Grad Norm 2.416678 0.15s/it\n","Train loss 26720 0.419828 Grad Norm 1.238393 0.14s/it\n","Train loss 26721 0.413865 Grad Norm 0.755199 0.14s/it\n","Train loss 26722 0.611536 Grad Norm 1.530558 0.13s/it\n","Train loss 26723 0.556222 Grad Norm 1.049168 0.10s/it\n","Train loss 26724 0.503791 Grad Norm 1.080818 0.10s/it\n","Train loss 26725 0.608845 Grad Norm 2.119226 0.11s/it\n","Train loss 26726 0.324864 Grad Norm 1.226008 0.18s/it\n","Train loss 26727 0.429796 Grad Norm 0.861159 0.10s/it\n","Train loss 26728 0.662976 Grad Norm 3.931604 0.12s/it\n","Train loss 26729 0.818335 Grad Norm 2.516248 0.12s/it\n","Train loss 26730 0.580427 Grad Norm 1.610830 0.16s/it\n","Train loss 26731 0.548542 Grad Norm 1.807328 0.11s/it\n","Train loss 26732 0.599127 Grad Norm 1.020297 0.11s/it\n","Train loss 26733 0.678249 Grad Norm 1.538950 0.14s/it\n","Train loss 26734 0.449233 Grad Norm 2.404820 0.11s/it\n","Train loss 26735 0.377961 Grad Norm 1.788304 0.14s/it\n","Train loss 26736 0.487945 Grad Norm 0.832129 0.15s/it\n","Train loss 26737 0.441840 Grad Norm 0.940344 0.12s/it\n","Train loss 26738 0.382960 Grad Norm 1.173643 0.13s/it\n","Train loss 26739 0.557117 Grad Norm 2.144861 0.11s/it\n","Train loss 26740 0.463441 Grad Norm 1.270551 0.12s/it\n","Train loss 26741 0.550535 Grad Norm 2.844405 0.13s/it\n","Train loss 26742 0.713802 Grad Norm 2.173198 0.11s/it\n","Train loss 26743 0.379772 Grad Norm 0.750360 0.13s/it\n","Train loss 26744 0.701678 Grad Norm 0.972155 0.12s/it\n","Train loss 26745 0.453196 Grad Norm 1.143458 0.14s/it\n","Train loss 26746 0.501868 Grad Norm 2.934923 0.12s/it\n","Train loss 26747 0.481779 Grad Norm 0.601594 0.15s/it\n","Train loss 26748 0.743037 Grad Norm 2.465986 0.15s/it\n","Train loss 26749 0.592324 Grad Norm 1.661391 0.12s/it\n","Train loss 26750 0.444689 Grad Norm 0.931846 0.12s/it\n","Train loss 26751 0.713231 Grad Norm 1.440983 0.14s/it\n","Train loss 26752 0.771162 Grad Norm 1.756255 0.12s/it\n","Train loss 26753 0.507744 Grad Norm 1.312991 0.13s/it\n","Train loss 26754 0.565121 Grad Norm 1.131729 0.11s/it\n","Train loss 26755 0.819240 Grad Norm 1.564675 0.10s/it\n","Train loss 26756 0.355898 Grad Norm 0.999016 0.15s/it\n","Train loss 26757 0.411305 Grad Norm 1.054422 0.15s/it\n","Train loss 26758 0.712406 Grad Norm 2.538466 0.14s/it\n","Train loss 26759 0.500849 Grad Norm 1.222723 0.13s/it\n","Train loss 26760 0.633820 Grad Norm 4.722233 0.13s/it\n","Train loss 26761 0.522921 Grad Norm 1.122029 0.14s/it\n","Train loss 26762 0.696854 Grad Norm 2.194748 0.12s/it\n","Train loss 26763 0.430904 Grad Norm 1.365847 0.10s/it\n","Train loss 26764 0.576599 Grad Norm 2.318019 0.12s/it\n","Train loss 26765 0.667252 Grad Norm 1.358699 0.13s/it\n","Train loss 26766 0.558620 Grad Norm 1.147372 0.12s/it\n","Train loss 26767 0.433590 Grad Norm 1.670833 0.17s/it\n","Train loss 26768 0.659668 Grad Norm 1.390751 0.13s/it\n","Train loss 26769 0.566364 Grad Norm 1.725721 0.11s/it\n","Train loss 26770 0.284946 Grad Norm 0.614128 0.11s/it\n","Train loss 26771 0.421838 Grad Norm 0.723489 0.19s/it\n","Train loss 26772 0.372319 Grad Norm 1.181537 0.13s/it\n","Train loss 26773 0.471680 Grad Norm 1.120856 0.15s/it\n","Train loss 26774 0.542873 Grad Norm 1.292805 0.14s/it\n","Train loss 26775 0.605134 Grad Norm 1.706007 0.15s/it\n","Train loss 26776 0.455087 Grad Norm 1.311517 0.11s/it\n","Train loss 26777 0.647252 Grad Norm 1.965023 0.11s/it\n","Train loss 26778 0.396381 Grad Norm 2.421959 0.12s/it\n","Train loss 26779 0.596346 Grad Norm 1.289593 0.14s/it\n","Train loss 26780 0.759924 Grad Norm 0.989426 0.13s/it\n","Train loss 26781 0.513155 Grad Norm 1.206171 0.13s/it\n","Train loss 26782 0.657751 Grad Norm 1.628851 0.13s/it\n","Train loss 26783 0.420574 Grad Norm 0.751570 0.15s/it\n","Train loss 26784 0.467240 Grad Norm 0.719692 0.10s/it\n","Train loss 26785 0.494445 Grad Norm 1.286147 0.14s/it\n","Train loss 26786 0.597157 Grad Norm 0.932607 0.15s/it\n","Train loss 26787 0.607389 Grad Norm 1.430659 0.12s/it\n","Train loss 26788 0.506751 Grad Norm 2.659759 0.13s/it\n","Train loss 26789 0.481766 Grad Norm 1.040546 0.12s/it\n","Train loss 26790 0.543915 Grad Norm 0.762782 0.13s/it\n","Train loss 26791 0.388507 Grad Norm 0.932526 0.13s/it\n","Train loss 26792 0.586880 Grad Norm 1.757472 0.12s/it\n","Train loss 26793 0.604032 Grad Norm 0.930968 0.13s/it\n","Train loss 26794 0.398932 Grad Norm 1.017515 0.14s/it\n","Train loss 26795 0.390380 Grad Norm 1.767007 0.13s/it\n","Train loss 26796 0.465815 Grad Norm 0.740920 0.15s/it\n","Train loss 26797 0.362139 Grad Norm 0.703932 0.13s/it\n","Train loss 26798 0.451355 Grad Norm 1.055804 0.13s/it\n","Train loss 26799 0.306806 Grad Norm 0.548464 0.11s/it\n","Train loss 26800 0.697608 Grad Norm 2.157455 0.12s/it\n","Train loss 26801 0.518065 Grad Norm 1.491250 0.14s/it\n","Train loss 26802 0.550485 Grad Norm 1.402343 0.11s/it\n","Train loss 26803 0.463199 Grad Norm 1.213473 0.15s/it\n","Train loss 26804 0.720258 Grad Norm 1.119651 0.12s/it\n","Train loss 26805 0.562537 Grad Norm 3.526489 0.13s/it\n","Train loss 26806 0.431891 Grad Norm 1.271681 0.12s/it\n","Train loss 26807 0.542894 Grad Norm 0.910793 0.12s/it\n","Train loss 26808 0.404964 Grad Norm 0.984619 0.11s/it\n","Train loss 26809 0.813752 Grad Norm 1.536004 0.13s/it\n","Train loss 26810 0.255368 Grad Norm 1.408367 0.13s/it\n","Train loss 26811 0.469227 Grad Norm 2.622690 0.13s/it\n","Train loss 26812 0.494518 Grad Norm 1.543386 0.12s/it\n","Train loss 26813 0.475490 Grad Norm 0.610345 0.12s/it\n","Train loss 26814 0.557139 Grad Norm 1.874388 0.10s/it\n","Train loss 26815 0.393934 Grad Norm 1.232673 0.14s/it\n","Train loss 26816 0.583602 Grad Norm 2.632229 0.10s/it\n","Train loss 26817 0.506456 Grad Norm 0.820448 0.10s/it\n","Train loss 26818 0.555942 Grad Norm 1.491305 0.13s/it\n","Train loss 26819 0.388411 Grad Norm 0.775370 0.14s/it\n","Train loss 26820 0.525313 Grad Norm 0.962827 0.11s/it\n","Train loss 26821 0.434064 Grad Norm 1.828461 0.14s/it\n","Train loss 26822 0.965892 Grad Norm 3.914992 0.12s/it\n","Train loss 26823 0.412283 Grad Norm 1.426069 0.14s/it\n","Train loss 26824 0.492251 Grad Norm 5.855461 0.10s/it\n","Train loss 26825 0.488136 Grad Norm 0.823876 0.12s/it\n","Train loss 26826 0.289260 Grad Norm 0.582676 0.14s/it\n","Train loss 26827 0.530436 Grad Norm 1.357012 0.12s/it\n","Train loss 26828 0.414718 Grad Norm 0.462474 0.10s/it\n","Train loss 26829 0.673121 Grad Norm 1.658108 0.12s/it\n","Train loss 26830 0.701432 Grad Norm 2.933947 0.12s/it\n","Train loss 26831 0.540818 Grad Norm 2.451121 0.11s/it\n","Train loss 26832 0.386308 Grad Norm 0.732107 0.13s/it\n","Train loss 26833 0.453027 Grad Norm 1.037982 0.10s/it\n","Train loss 26834 0.531667 Grad Norm 2.034126 0.14s/it\n","Train loss 26835 0.605103 Grad Norm 2.019860 0.13s/it\n","Train loss 26836 0.549655 Grad Norm 0.847861 0.12s/it\n","Train loss 26837 0.633471 Grad Norm 1.923891 0.10s/it\n","Train loss 26838 0.547020 Grad Norm 0.999359 0.14s/it\n","Train loss 26839 0.586553 Grad Norm 1.797186 0.11s/it\n","Train loss 26840 0.573153 Grad Norm 0.747839 0.15s/it\n","Train loss 26841 0.995924 Grad Norm 1.614532 0.11s/it\n","Train loss 26842 0.362562 Grad Norm 0.736763 0.15s/it\n","Train loss 26843 0.483869 Grad Norm 2.835594 0.11s/it\n","Train loss 26844 0.463794 Grad Norm 1.024335 0.11s/it\n","Train loss 26845 0.361912 Grad Norm 0.710413 0.10s/it\n","Train loss 26846 0.541639 Grad Norm 1.720138 0.13s/it\n","Train loss 26847 0.757320 Grad Norm 2.510117 0.11s/it\n","Train loss 26848 0.407123 Grad Norm 1.061180 0.11s/it\n","Train loss 26849 0.561192 Grad Norm 2.753742 0.12s/it\n","Train loss 26850 0.621822 Grad Norm 2.348993 0.12s/it\n","Train loss 26851 0.495861 Grad Norm 1.858100 0.12s/it\n","Train loss 26852 0.457510 Grad Norm 0.689994 0.14s/it\n","Train loss 26853 0.575569 Grad Norm 0.939225 0.13s/it\n","Train loss 26854 0.490150 Grad Norm 1.461997 0.14s/it\n","Train loss 26855 0.382999 Grad Norm 0.820031 0.11s/it\n","Train loss 26856 0.639952 Grad Norm 0.988012 0.13s/it\n","Train loss 26857 0.379870 Grad Norm 1.025203 0.15s/it\n","Train loss 26858 0.709337 Grad Norm 2.249890 0.12s/it\n","Train loss 26859 0.453319 Grad Norm 4.948446 0.12s/it\n","Train loss 26860 0.375124 Grad Norm 0.687771 0.14s/it\n","Train loss 26861 0.490352 Grad Norm 1.429642 0.12s/it\n","Train loss 26862 0.605237 Grad Norm 2.688634 0.11s/it\n","Train loss 26863 0.634560 Grad Norm 1.230348 0.11s/it\n","Train loss 26864 0.541513 Grad Norm 1.063545 0.12s/it\n","Train loss 26865 0.460643 Grad Norm 1.988231 0.13s/it\n","Train loss 26866 0.475550 Grad Norm 2.330139 0.14s/it\n","Train loss 26867 0.669032 Grad Norm 2.392129 0.10s/it\n","Train loss 26868 0.484395 Grad Norm 1.771101 0.11s/it\n","Train loss 26869 0.551563 Grad Norm 1.341480 0.11s/it\n","Train loss 26870 0.820915 Grad Norm 2.369929 0.13s/it\n","Train loss 26871 0.825246 Grad Norm 2.683013 0.12s/it\n","Train loss 26872 0.510248 Grad Norm 1.822088 0.16s/it\n","Train loss 26873 0.459355 Grad Norm 1.096030 0.11s/it\n","Train loss 26874 0.464031 Grad Norm 1.381272 0.11s/it\n","Train loss 26875 0.525337 Grad Norm 0.842429 0.11s/it\n","Train loss 26876 0.643227 Grad Norm 1.239485 0.11s/it\n","Train loss 26877 0.655272 Grad Norm 1.696006 0.13s/it\n","Train loss 26878 0.528302 Grad Norm 1.235829 0.13s/it\n","Train loss 26879 0.397783 Grad Norm 1.055874 0.12s/it\n","Train loss 26880 0.761263 Grad Norm 1.634408 0.12s/it\n","Train loss 26881 0.690703 Grad Norm 3.276921 0.11s/it\n","Train loss 26882 0.557770 Grad Norm 1.181585 0.14s/it\n","Train loss 26883 0.476323 Grad Norm 1.052584 0.15s/it\n","Train loss 26884 0.670206 Grad Norm 2.008820 0.12s/it\n","Train loss 26885 0.619079 Grad Norm 3.111457 0.10s/it\n","Train loss 26886 0.797773 Grad Norm 2.346477 0.12s/it\n","Train loss 26887 0.567284 Grad Norm 1.728905 0.11s/it\n","Train loss 26888 0.603399 Grad Norm 1.091115 0.10s/it\n","Train loss 26889 0.714806 Grad Norm 1.259047 0.10s/it\n","Train loss 26890 0.535698 Grad Norm 0.477189 0.11s/it\n","Train loss 26891 0.412715 Grad Norm 1.128944 0.13s/it\n","Train loss 26892 0.528183 Grad Norm 0.867456 0.15s/it\n","Train loss 26893 0.433276 Grad Norm 1.182766 0.11s/it\n","Train loss 26894 0.494322 Grad Norm 0.811525 0.14s/it\n","Train loss 26895 0.724774 Grad Norm 1.406176 0.12s/it\n","Train loss 26896 0.728916 Grad Norm 1.762591 0.12s/it\n","Train loss 26897 0.421765 Grad Norm 0.948623 0.11s/it\n","Train loss 26898 0.429573 Grad Norm 0.581845 0.13s/it\n","Train loss 26899 0.375696 Grad Norm 0.862534 0.12s/it\n","Train loss 26900 0.353617 Grad Norm 0.424599 0.12s/it\n","Train loss 26901 0.467084 Grad Norm 0.889514 0.13s/it\n","Train loss 26902 0.577174 Grad Norm 1.288936 0.11s/it\n","Train loss 26903 0.387388 Grad Norm 0.524939 0.14s/it\n","Train loss 26904 0.510315 Grad Norm 1.381339 0.14s/it\n","Train loss 26905 0.515373 Grad Norm 0.781837 0.14s/it\n","Train loss 26906 0.504917 Grad Norm 0.832048 0.11s/it\n","Train loss 26907 0.434250 Grad Norm 2.046200 0.11s/it\n","Train loss 26908 0.614804 Grad Norm 2.556172 0.11s/it\n","Train loss 26909 0.425695 Grad Norm 0.670534 0.14s/it\n","Train loss 26910 0.370618 Grad Norm 1.504748 0.12s/it\n","Train loss 26911 0.853788 Grad Norm 1.806177 0.12s/it\n","Train loss 26912 0.487618 Grad Norm 0.882450 0.11s/it\n","Train loss 26913 0.278516 Grad Norm 0.617400 0.14s/it\n","Train loss 26914 0.307302 Grad Norm 4.639983 0.09s/it\n","Train loss 26915 0.359017 Grad Norm 1.486103 0.12s/it\n","Train loss 26916 0.504031 Grad Norm 1.380613 0.12s/it\n","Train loss 26917 0.523402 Grad Norm 2.814236 0.11s/it\n","Train loss 26918 0.884330 Grad Norm 3.064228 0.12s/it\n","Train loss 26919 0.465758 Grad Norm 1.278663 0.14s/it\n","Train loss 26920 0.561816 Grad Norm 1.299962 0.15s/it\n","Train loss 26921 0.782972 Grad Norm 2.847140 0.11s/it\n","Train loss 26922 0.528262 Grad Norm 1.027507 0.13s/it\n","Train loss 26923 0.587987 Grad Norm 1.677005 0.12s/it\n","Train loss 26924 0.335954 Grad Norm 0.748096 0.15s/it\n","Train loss 26925 0.383374 Grad Norm 1.971454 0.12s/it\n","Train loss 26926 0.396514 Grad Norm 1.335943 0.12s/it\n","Train loss 26927 0.709186 Grad Norm 1.994586 0.14s/it\n","Train loss 26928 0.353630 Grad Norm 1.462886 0.12s/it\n","Train loss 26929 0.511766 Grad Norm 1.279515 0.16s/it\n","Train loss 26930 0.536509 Grad Norm 1.378766 0.11s/it\n","Train loss 26931 0.366916 Grad Norm 0.958956 0.10s/it\n","Train loss 26932 0.558902 Grad Norm 1.193107 0.12s/it\n","Train loss 26933 0.593533 Grad Norm 2.974754 0.10s/it\n","Train loss 26934 0.507092 Grad Norm 2.319507 0.13s/it\n","Train loss 26935 0.417541 Grad Norm 1.328842 0.14s/it\n","Train loss 26936 0.795401 Grad Norm 6.393266 0.13s/it\n","Train loss 26937 0.489718 Grad Norm 0.890013 0.13s/it\n","Train loss 26938 0.420461 Grad Norm 0.938802 0.11s/it\n","Train loss 26939 0.403452 Grad Norm 2.240827 0.15s/it\n","Train loss 26940 0.405714 Grad Norm 0.738308 0.16s/it\n","Train loss 26941 0.417964 Grad Norm 3.150103 0.13s/it\n","Train loss 26942 0.485726 Grad Norm 1.659551 0.11s/it\n","Train loss 26943 0.379777 Grad Norm 1.756557 0.12s/it\n","Train loss 26944 0.531383 Grad Norm 0.857693 0.15s/it\n","Train loss 26945 0.325993 Grad Norm 0.558093 0.14s/it\n","Train loss 26946 0.360362 Grad Norm 0.961723 0.15s/it\n","Train loss 26947 0.508553 Grad Norm 1.868886 0.12s/it\n","Train loss 26948 0.729761 Grad Norm 1.248142 0.12s/it\n","Train loss 26949 0.518023 Grad Norm 1.915167 0.12s/it\n","Train loss 26950 0.580124 Grad Norm 1.868238 0.13s/it\n","Train loss 26951 0.583511 Grad Norm 1.444904 0.11s/it\n","Train loss 26952 0.281959 Grad Norm 0.450463 0.13s/it\n","Train loss 26953 0.498752 Grad Norm 1.982988 0.12s/it\n","Train loss 26954 0.599786 Grad Norm 0.970488 0.12s/it\n","Train loss 26955 0.538964 Grad Norm 1.231028 0.12s/it\n","Train loss 26956 0.625183 Grad Norm 0.843517 0.13s/it\n","Train loss 26957 0.668830 Grad Norm 1.403114 0.12s/it\n","Train loss 26958 0.299649 Grad Norm 1.236689 0.13s/it\n","Train loss 26959 0.307142 Grad Norm 1.990567 0.10s/it\n","Train loss 26960 0.670443 Grad Norm 2.003392 0.11s/it\n","Train loss 26961 0.603868 Grad Norm 1.031040 0.11s/it\n","Train loss 26962 0.749011 Grad Norm 2.446513 0.12s/it\n","Train loss 26963 0.762196 Grad Norm 1.525640 0.12s/it\n","Train loss 26964 0.582352 Grad Norm 1.628919 0.14s/it\n","Train loss 26965 0.567091 Grad Norm 1.680105 0.11s/it\n","Train loss 26966 0.545774 Grad Norm 1.296096 0.11s/it\n","Train loss 26967 0.547137 Grad Norm 1.061930 0.11s/it\n","Train loss 26968 0.489135 Grad Norm 2.102021 0.13s/it\n","Train loss 26969 0.543968 Grad Norm 1.490726 0.14s/it\n","Train loss 26970 0.674705 Grad Norm 1.173444 0.14s/it\n","Train loss 26971 0.434143 Grad Norm 0.831975 0.10s/it\n","Train loss 26972 0.570061 Grad Norm 1.301436 0.12s/it\n","Train loss 26973 0.588689 Grad Norm 0.969310 0.14s/it\n","Train loss 26974 0.553700 Grad Norm 3.343140 0.12s/it\n","Train loss 26975 0.618248 Grad Norm 1.244210 0.12s/it\n","Train loss 26976 0.486804 Grad Norm 0.991098 0.15s/it\n","Train loss 26977 0.452424 Grad Norm 1.709984 0.17s/it\n","Train loss 26978 0.510352 Grad Norm 0.841785 0.10s/it\n","Train loss 26979 0.357644 Grad Norm 1.034207 0.13s/it\n","Train loss 26980 0.382043 Grad Norm 0.942953 0.15s/it\n","Train loss 26981 0.606299 Grad Norm 2.712055 0.11s/it\n","Train loss 26982 0.615326 Grad Norm 1.833471 0.12s/it\n","Train loss 26983 0.670007 Grad Norm 2.136082 0.15s/it\n","Train loss 26984 0.372705 Grad Norm 1.163678 0.12s/it\n","Train loss 26985 0.330016 Grad Norm 1.436049 0.13s/it\n","Train loss 26986 0.539061 Grad Norm 0.888215 0.14s/it\n","Train loss 26987 0.512331 Grad Norm 1.913001 0.13s/it\n","Train loss 26988 0.577518 Grad Norm 2.076428 0.12s/it\n","Train loss 26989 0.432577 Grad Norm 0.664857 0.13s/it\n","Train loss 26990 0.683803 Grad Norm 1.958491 0.11s/it\n","Train loss 26991 0.556320 Grad Norm 0.859707 0.11s/it\n","Train loss 26992 0.524370 Grad Norm 0.845821 0.13s/it\n","Train loss 26993 0.887011 Grad Norm 3.784750 0.12s/it\n","Train loss 26994 0.476042 Grad Norm 1.909027 0.11s/it\n","Train loss 26995 0.646063 Grad Norm 1.345102 0.10s/it\n","Train loss 26996 0.501309 Grad Norm 0.649993 0.13s/it\n","Train loss 26997 0.535962 Grad Norm 1.099467 0.11s/it\n","Train loss 26998 0.547879 Grad Norm 1.306058 0.10s/it\n","Train loss 26999 0.403904 Grad Norm 1.161103 0.11s/it\n","Train loss 27000 0.224163 Grad Norm 0.439562 0.11s/it\n"]}],"source":["learning_rate = 1e-3\n","\n","train(model, logger, learning_rate, optimizer, train_loader, collate_fn, valset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ERbUAKPN1aR"},"outputs":[],"source":["torch.save(model.state_dict(), f\"{dataset_path}/model_weights_21_08_25-4.pth\")"]},{"cell_type":"markdown","metadata":{"id":"nfYsBxtq_fFz"},"source":["## Voice Generation Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GcHvLucu3m2F"},"outputs":[],"source":["# model.load_state_dict(torch.load(f\"{dataset_path}/model_weights_21_08_25-2.pth\"))\n","# model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G15guLfNo8Rn"},"outputs":[],"source":["import torch\n","import numpy as np\n","\n","def prepare_mel_for_vocoder(\n","    mel_2d: torch.Tensor,\n","    *,\n","    mean: float | torch.Tensor | None = None,\n","    std: float  | torch.Tensor | None = None,\n","    hifigan_model=None,\n",") -> torch.Tensor:\n","    \"\"\"\n","    Converts your current mel (as returned by text_to_mel) to the format HiFi-GAN expects.\n","    - Input:  [T, 80] torch.FloatTensor   (no batch)\n","    - Output: [1, 80, T] torch.FloatTensor (batched, on hifigan device)\n","\n","    mean/std are OPTIONAL. Pass the SAME values you used during training normalization\n","    (if any). If you didn't normalize, leave them None.\n","    \"\"\"\n","    assert isinstance(mel_2d, torch.Tensor) and mel_2d.ndim == 2, \"expected [T, 80] torch tensor\"\n","\n","    x = mel_2d.detach().float()       # [T, 80]\n","\n","    # 1) (Optional) de-normalize back to the original scale you trained on\n","    if (mean is not None) and (std is not None):\n","        # mean/std can be scalars or shape-[80]; broadcast handles both\n","        if not torch.is_tensor(mean): mean = torch.tensor(mean, dtype=x.dtype, device=x.device)\n","        if not torch.is_tensor(std):  std  = torch.tensor(std,  dtype=x.dtype, device=x.device)\n","        x = x * std + mean            # still [T, 80]\n","\n","    # 2) Layout for HiFi-GAN: [T,80] -> [80,T] -> [1,80,T]\n","    x = x.transpose(0, 1).contiguous().unsqueeze(0)  # [1, 80, T]\n","\n","    # 3) Put on same device as vocoder\n","    if hifigan_model is not None:\n","        device = next(hifigan_model.parameters()).device\n","        x = x.to(device)\n","\n","    return x\n","\n","\n","@torch.no_grad()\n","def mel_to_audio_with_hifigan(\n","    mel_2d: torch.Tensor,\n","    *,\n","    mean: float | torch.Tensor | None = None,\n","    std: float  | torch.Tensor | None = None,\n",") -> np.ndarray:\n","    \"\"\"\n","    Convenience wrapper: takes your [T,80] mel, adapts it, and runs the vocoder.\n","    Returns: 1D np.float32 waveform.\n","    \"\"\"\n","    spec = prepare_mel_for_vocoder(mel_2d, mean=mean, std=std, hifigan_model=hifigan_model)  # [1,80,T]\n","    audio = hifigan_model.convert_spectrogram_to_audio(spec=spec)  # [1, samples]\n","    return audio[0].detach().cpu().float().numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oKcpeLkf4PJG"},"outputs":[],"source":["# Inference: generate mel from text, compare to dataset mel, and save both audios\n","import os\n","import re\n","import time\n","import numpy as np\n","import torch\n","\n","\n","def sanitize_filename(s: str, max_len: int = 32) -> str:\n","    s = re.sub(r\"[^a-zA-Z0-9-_]+\", \"_\", s).strip(\"_\")\n","    if len(s) == 0:\n","        s = \"text\"\n","    return s[:max_len]\n","\n","\n","def infer_and_compare(sample_index: int = 10, input_text: str | None = None, save_plots: bool = False):\n","    \"\"\"\n","    - If input_text is None: use dataset[sample_index] text ids for inference.\n","    - Compare predicted mel to the dataset target mel (L1/MSE, length-aligned).\n","    - Save two audios to audio_outputs_folder: target_*.wav and pred_*.wav\n","    \"\"\"\n","    model_device = next(model.parameters()).device\n","\n","    # Load dataset item\n","    text_ids, target_mel = dataset[sample_index]\n","    # Ensure tensor types and devices\n","    if input_text is None:\n","        seq = text_ids.long().unsqueeze(0).to(model_device)  # [1, T]\n","        name_tag = f\"idx{sample_index}\"\n","    else:\n","        seq_list = text_to_sequence(input_text)\n","        seq = torch.tensor(seq_list, dtype=torch.long, device=model_device).unsqueeze(0)\n","        name_tag = sanitize_filename(input_text)\n","\n","    # Run model inference\n","    model.eval()\n","    with torch.no_grad():\n","        mel_pred, mel_pred_post, _, alignments = model.inference(seq)\n","    # Choose postnet output\n","    mel_pred_2d = mel_pred_post[0].detach().cpu()  # [T_pred, 80]\n","\n","    # Prepare target mel [T, 80]\n","    target_mel_2d = target_mel.detach().cpu().float()\n","\n","    # Length align for metrics\n","    t_min = min(target_mel_2d.size(0), mel_pred_2d.size(0))\n","    tgt_crop = target_mel_2d[:t_min]\n","    pred_crop = mel_pred_2d[:t_min]\n","\n","    l1 = torch.mean(torch.abs(pred_crop - tgt_crop)).item()\n","    mse = torch.mean((pred_crop - tgt_crop) ** 2).item()\n","    print(f\"Comparison ({name_tag}): L1={l1:.6f}, MSE={mse:.6f}, T_target={target_mel_2d.size(0)}, T_pred={mel_pred_2d.size(0)})\")\n","\n","    # Optional visualization\n","    if save_plots:\n","        show_or_save_mel_spectrogram(target_mel_2d.numpy(), title=f\"Target Mel ({name_tag})\")\n","        show_or_save_mel_spectrogram(mel_pred_2d.numpy(), title=f\"Predicted Mel ({name_tag})\")\n","\n","    # Synthesize and save audios\n","    ts = time.strftime(\"%Y%m%d-%H%M%S\")\n","    target_path = os.path.join(audio_outputs_folder, f\"target_{name_tag}_{ts}.wav\")\n","    pred_path = os.path.join(audio_outputs_folder, f\"pred_{name_tag}_{ts}.wav\")\n","\n","    os.makedirs(audio_outputs_folder, exist_ok=True)\n","\n","    # target_audio = tensor_to_hifigan_audio(target_mel_2d)\n","    # pred_audio = tensor_to_hifigan_audio(mel_pred_2d)\n","    target_audio = mel_to_audio_with_hifigan(target_mel_2d)\n","    pred_audio = mel_to_audio_with_hifigan(mel_pred_2d)\n","\n","    sf.write(target_path, target_audio, 22050, format='WAV', subtype='PCM_16')\n","    sf.write(pred_path, pred_audio, 22050, format='WAV', subtype='PCM_16')\n","\n","    print(f\"Saved target audio -> {target_path}\")\n","    print(f\"Saved predicted audio -> {pred_path}\")\n","\n","    # Return artifacts for further use\n","    return {\n","        \"sample_index\": sample_index,\n","        \"name_tag\": name_tag,\n","        \"metrics\": {\"l1\": l1, \"mse\": mse},\n","        \"mel_target\": target_mel_2d,\n","        \"mel_pred\": mel_pred_2d,\n","        \"alignment\": alignments[0].detach().cpu() if alignments is not None else None,\n","        \"paths\": {\"target\": target_path, \"pred\": pred_path},\n","    }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vVS8ieS0kZ3H"},"outputs":[],"source":["# target_path = os.path.join(audio_outputs_folder, f\"target_hello.wav\")\n","\n","# os.makedirs(audio_outputs_folder, exist_ok=True)\n","\n","# target_mel_2d = text_to_mel(\"hello hello hello hello hello\")\n","\n","# target_audio = mel_to_audio_with_hifigan(target_mel_2d)\n","\n","# sf.write(target_path, target_audio, 22050, format='WAV', subtype='PCM_16')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QN8MBnex5fEC"},"outputs":[],"source":["for i in range(5):\n","  sample_index = random.randint(1, len(dataset))\n","  infer_and_compare(sample_index=sample_index, input_text=None)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["8NETblXi_pCu","xVEJaRsC_fFj","cfBvYq31_fFl","MeFjPLt-_fFm","oAjb0idQ_fFn","vhtHjS19_fFn","P6fN89ui_fFo","HU7JU3_M_fFo","t0e-tbsO_fFp","lfKCDEDa_fFp","__UxOCCm2St3","nfYsBxtq_fFz"],"gpuType":"A100","machine_shape":"hm","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}