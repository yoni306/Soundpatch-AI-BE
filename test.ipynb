{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model...\n",
      "âœ“ Model loaded successfully (876,851 parameters)\n",
      "âœ“ Model loaded successfully (876,851 parameters)\n",
      "âœ“ Model ready for inference\n",
      "âœ“ Model ready for inference\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ”„ LOAD TRAINED MODEL\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "print(\"Loading trained model...\")\n",
    "\n",
    "# Define custom objects\n",
    "def focal_loss_dynamic(gamma=2.0, eps=1e-7):\n",
    "    \"\"\"Advanced Focal Loss with Dynamic Class Weighting\"\"\"\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, eps, 1-eps)\n",
    "        freq_pos = tf.reduce_mean(y_true, axis=[0,1])\n",
    "        alpha = 1 - freq_pos\n",
    "        term1 = - alpha * y_true * tf.pow(1-y_pred, gamma) * tf.math.log(y_pred)\n",
    "        term2 = - (1-alpha) * (1-y_true) * tf.pow(y_pred, gamma) * tf.math.log(1-y_pred)\n",
    "        return tf.reduce_mean(term1+term2)\n",
    "    return loss_fn\n",
    "\n",
    "def f1_metric_05(y_true, y_pred):\n",
    "    \"\"\"F1 Score with 0.5 threshold\"\"\"\n",
    "    y_pred = tf.cast(y_pred>0.5, tf.float32)\n",
    "    tp = tf.reduce_sum(y_true*y_pred)\n",
    "    fp = tf.reduce_sum((1-y_true)*y_pred)\n",
    "    fn = tf.reduce_sum(y_true*(1-y_pred))\n",
    "    prec = tp/(tp+fp+1e-7)\n",
    "    rec = tp/(tp+fn+1e-7)\n",
    "    return 2*prec*rec/(prec+rec+1e-7)\n",
    "\n",
    "f1_metric_05.__name__ = \"f1_metric_05\"\n",
    "\n",
    "# Load model\n",
    "MODEL_DIR = \".\"  # ×ª×™×§×Ÿ ×œ×ª×™×§×™×™×” ×”× ×•×›×—×™×ª\n",
    "model_path = os.path.join(MODEL_DIR, \"final_model.h5\")\n",
    "\n",
    "custom_objects = {\n",
    "    'focal_loss_dynamic': focal_loss_dynamic,\n",
    "    'loss_fn': focal_loss_dynamic(),\n",
    "    'f1_metric_05': f1_metric_05\n",
    "}\n",
    "\n",
    "try:\n",
    "    model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n",
    "    print(f\"âœ“ Model loaded successfully ({model.count_params():,} parameters)\")\n",
    "    \n",
    "    # Quick test\n",
    "    test_input = np.random.random((1, 64, 100, 1)).astype(np.float32)\n",
    "    test_output = model.predict(test_input, verbose=0)\n",
    "    print(f\"âœ“ Model ready for inference\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error loading model: {e}\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydub'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, List\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39;00m\n\u001b[0;32m     17\u001b[0m WAV_DIR        \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDEPP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mthebest\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# ×§×‘×¦×™ ×”×˜×¡×˜\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pydub'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create FULL FILES with multiple noises - WHOLE FILE APPROACH\n",
    "-----------------------------------------------------------\n",
    "â€¢ ×›×œ ×§×•×‘×¥: 15 ×¨×¢×©×™× ×œ×¤×™ ×”×ª×¤×œ×’×•×ª ×§×™×™××ª\n",
    "â€¢ ×›×œ ×¨×¢×©: 3-4 ×©× ×™×•×ª\n",
    "â€¢ ×œ×™×™×‘×œ ××“×•×™×§: ×¨×©×•××” × ×¤×¨×“×ª ×œ×›×œ ×¨×¢×© ×¢× ×–×× ×™× ××“×•×™×§×™×\n",
    "â€¢ ×™×¦×•×:\n",
    "      test_dataset/data/*.wav (×§×‘×¦×™× ×©×œ××™× ×¢× ×¨×¢×©×™×)\n",
    "      test_dataset/labels.csv (×¤×•×¨××˜ ××©×•×¤×¨)\n",
    "\"\"\"\n",
    "import os, random, csv, uuid\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "WAV_DIR        = Path(r\"F:\\DEPP\\data2\\thebest\\test\\wav\")  # ×§×‘×¦×™ ×”×˜×¡×˜\n",
    "OUTPUT_DIR     = Path(\"test_dataset\")                      # test dataset folder\n",
    "MIN_NOISES_PER_FILE = 10                                   # ××™× ×™××•× ×¨×¢×©×™× ×œ×§×•×‘×¥\n",
    "MAX_NOISES_PER_FILE = 15                                   # ××§×¡×™××•× ×¨×¢×©×™× ×œ×§×•×‘×¥\n",
    "\n",
    "# ×›×œ ×¨×¢×© 3-4 ×©× ×™×•×ª (×‘×“×™×•×§ ×›××• ×‘××™××•×Ÿ!)\n",
    "NOISE_MIN, NOISE_MAX = 3.0, 4.0\n",
    "\n",
    "# ×”×ª×¤×œ×’×•×ª ×–×”×” ×œ××™××•×Ÿ\n",
    "MIX: Dict[str, float] = {           \n",
    "    \"compression_artifact\": 0.50,  \n",
    "    \"volume_drop\":          0.35,  \n",
    "    \"signal_loss\":          0.15,  \n",
    "}\n",
    "\n",
    "# ×”×¤×¨×©×™× ×‘×™×Ÿ ×¨×¢×©×™×\n",
    "MIN_NOISE_SPACING = 15.0  # 15 ×©× ×™×•×ª ××™× ×™××•× ×‘×™×Ÿ ×¨×¢×©×™×\n",
    "\n",
    "DATA_DIR  = OUTPUT_DIR / \"data\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LABEL_CSV = OUTPUT_DIR / \"labels.csv\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ NOISE OPERATIONS (×–×”×” ×œ××™××•×Ÿ!) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def apply_signal_loss(audio, start_s, end_s):\n",
    "    before = audio[:int(start_s*1000)]\n",
    "    target = AudioSegment.silent(duration=int((end_s-start_s)*1000))\n",
    "    after = audio[int(end_s*1000):]\n",
    "    return before + target + after\n",
    "\n",
    "def apply_volume_drop(audio, start_s, end_s):\n",
    "    before = audio[:int(start_s*1000)]\n",
    "    target = audio[int(start_s*1000):int(end_s*1000)]\n",
    "    fade_duration = min(300, len(target)//2)\n",
    "    target = target.fade_out(fade_duration).fade_in(fade_duration) - 23\n",
    "    after = audio[int(end_s*1000):]\n",
    "    return before + target + after\n",
    "\n",
    "def apply_compression_artifact(audio, start_s, end_s):\n",
    "    before = audio[:int(start_s*1000)]\n",
    "    target = audio[int(start_s*1000):int(end_s*1000)]\n",
    "    target = (target.set_sample_width(1)\n",
    "                   .set_frame_rate(5000)\n",
    "                   .low_pass_filter(2000) - 20)\n",
    "    after = audio[int(end_s*1000):]\n",
    "    return before + target + after\n",
    "\n",
    "NOISE_FUNCTIONS = {\n",
    "    \"signal_loss\":          apply_signal_loss,\n",
    "    \"volume_drop\":          apply_volume_drop,\n",
    "    \"compression_artifact\": apply_compression_artifact,\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ HELPER FUNCTIONS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def time_to_mmss(seconds):\n",
    "    \"\"\"×”××¨×ª ×©× ×™×•×ª ×œ×¤×•×¨××˜ MM:SS\"\"\"\n",
    "    mm = int(seconds // 60)\n",
    "    ss = int(seconds % 60)\n",
    "    return f\"{mm:02d}:{ss:02d}\"\n",
    "\n",
    "def generate_noise_events(audio_duration: float, num_noises: int) -> List[Dict]:\n",
    "    \"\"\"×™×•×¦×¨ ×¨×©×™××ª ××™×¨×•×¢×™ ×¨×¢×© ×œ×§×•×‘×¥ ×©×œ×\"\"\"\n",
    "    noise_types = list(MIX.keys())\n",
    "    noise_weights = list(MIX.values())\n",
    "    \n",
    "    noise_events = []\n",
    "    used_starts = []\n",
    "    \n",
    "    for _ in range(num_noises):\n",
    "        # × ×™×¡×™×•×Ÿ ×œ××¦×•× ××™×§×•× ××ª××™×\n",
    "        for attempt in range(100):  # ××§×¡×™××•× 100 × ×™×¡×™×•× ×•×ª\n",
    "            noise_duration = random.uniform(NOISE_MIN, NOISE_MAX)\n",
    "            \n",
    "            if noise_duration >= audio_duration:\n",
    "                continue\n",
    "                \n",
    "            start_time = random.uniform(0, audio_duration - noise_duration)\n",
    "            \n",
    "            # ×‘×“×™×§×” ×©×™×© ××¨×•×•×— ××¡×¤×™×§ ××¨×¢×©×™× ×§×™×™××™×\n",
    "            if all(abs(start_time - existing) >= MIN_NOISE_SPACING for existing in used_starts):\n",
    "                end_time = start_time + noise_duration\n",
    "                noise_type = random.choices(noise_types, weights=noise_weights, k=1)[0]\n",
    "                \n",
    "                noise_events.append({\n",
    "                    \"start_time\": round(start_time, 3),\n",
    "                    \"end_time\": round(end_time, 3),\n",
    "                    \"duration\": round(noise_duration, 3),\n",
    "                    \"noise_type\": noise_type\n",
    "                })\n",
    "                \n",
    "                used_starts.append(start_time)\n",
    "                break\n",
    "    \n",
    "    # ××™×•×Ÿ ×œ×¤×™ ×–××Ÿ ×”×ª×—×œ×”\n",
    "    noise_events.sort(key=lambda x: x[\"start_time\"])\n",
    "    return noise_events\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ MAIN PROCESSING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "sources = [p for p in WAV_DIR.iterdir() if p.suffix == \".wav\"]\n",
    "if not sources:\n",
    "    raise RuntimeError(f\"No WAV files found in {WAV_DIR}\")\n",
    "\n",
    "labels = []\n",
    "random.seed(42)  # ×œ××¢×Ÿ ×©×—×–×•×¨\n",
    "\n",
    "print(f\"ğŸ¯ Creating test files with 10-15 noises each...\")\n",
    "print(f\"â–¶ Processing {len(sources)} test WAV files from {WAV_DIR}\")\n",
    "print(f\"ğŸ“Š Noise distribution: {MIX}\")\n",
    "\n",
    "for src_idx, src in enumerate(sources):\n",
    "    print(f\"   ğŸ“ Processing file {src_idx+1}/{len(sources)}: {src.name}\")\n",
    "    \n",
    "    try:\n",
    "        # ×˜×¢×™× ×ª ×”×§×•×‘×¥ ×”××§×•×¨×™\n",
    "        audio = AudioSegment.from_file(src)\n",
    "        audio_duration = len(audio) / 1000.0  # seconds\n",
    "        \n",
    "        print(f\"      Duration: {audio_duration:.1f}s\")\n",
    "        \n",
    "        # ×§×‘×™×¢×ª ××¡×¤×¨ ×¨×¢×©×™× ×œ×§×•×‘×¥ ×”×–×”\n",
    "        num_noises = random.randint(MIN_NOISES_PER_FILE, MAX_NOISES_PER_FILE)\n",
    "        \n",
    "        # ×™×¦×™×¨×ª ××™×¨×•×¢×™ ×¨×¢×©\n",
    "        noise_events = generate_noise_events(audio_duration, num_noises)\n",
    "        \n",
    "        if len(noise_events) < 8:  # ×œ×¤×—×•×ª 8 ×¨×¢×©×™×\n",
    "            print(f\"   âš ï¸ Skipping {src.name} - only {len(noise_events)} noises generated\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"      Adding {len(noise_events)} noise events\")\n",
    "        \n",
    "        # ×™×™×©×•× ×”×¨×¢×©×™× ×¢×œ ×”×§×•×‘×¥\n",
    "        noisy_audio = audio\n",
    "        for event in noise_events:\n",
    "            start_s = event[\"start_time\"]\n",
    "            end_s = event[\"end_time\"]\n",
    "            noise_type = event[\"noise_type\"]\n",
    "            \n",
    "            noisy_audio = NOISE_FUNCTIONS[noise_type](noisy_audio, start_s, end_s)\n",
    "        \n",
    "        # ×©××™×¨×ª ×”×§×•×‘×¥ ×¢× ×”×¨×¢×©×™×\n",
    "        output_filename = f\"{src.stem}_with_noises.wav\"\n",
    "        output_path = DATA_DIR / output_filename\n",
    "        noisy_audio.export(output_path, format=\"wav\")\n",
    "        print(f\"      âœ… Saved: {output_filename}\")\n",
    "        \n",
    "        # ×”×•×¡×¤×ª ×œ×™×™×‘×œ×™× - ×¨×©×•××” × ×¤×¨×“×ª ×œ×›×œ ×¨×¢×©\n",
    "        for event in noise_events:\n",
    "            labels.append({\n",
    "                \"filename\": output_filename,\n",
    "                \"noise_type\": event[\"noise_type\"],\n",
    "                \"start_time\": event[\"start_time\"],\n",
    "                \"end_time\": event[\"end_time\"],\n",
    "                \"duration\": event[\"duration\"],\n",
    "                \"start_time_mmss\": time_to_mmss(event[\"start_time\"]),\n",
    "                \"end_time_mmss\": time_to_mmss(event[\"end_time\"])\n",
    "            })\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error processing {src.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ SAVE LABELS CSV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fieldnames = [\"filename\", \"noise_type\", \"start_time\", \"end_time\", \"duration\", \"start_time_mmss\", \"end_time_mmss\"]\n",
    "\n",
    "with open(LABEL_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    w.writeheader()\n",
    "    w.writerows(labels)\n",
    "\n",
    "print(f\"\\nâœ… Done! Test files with noises created:\")\n",
    "print(f\"   ğŸ“ Files dir: {DATA_DIR.resolve()}\")\n",
    "print(f\"   ğŸ“‹ Labels: {LABEL_CSV.resolve()}\")\n",
    "print(f\"   ğŸ“Š Total test files: {len(set(label['filename'] for label in labels))}\")\n",
    "print(f\"   ğŸ“Š Total noise instances: {len(labels)}\")\n",
    "if len(labels) > 0:\n",
    "    print(f\"   ğŸ“Š Average noises per file: {len(labels) / len(set(label['filename'] for label in labels)):.1f}\")\n",
    "else:\n",
    "    print(\"   âš ï¸ No labels generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Loading test labels and file list...\n",
      "ğŸ“Š Found 11 test audio files\n",
      "ğŸ“‹ 0 files already processed\n",
      "ğŸ¯ 11 files to process\n",
      "ğŸš€ Starting sequential processing of test files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:14<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ Test Processing Complete!\n",
      "   âœ… Successfully processed: 11\n",
      "   â­ï¸ Skipped (already done): 0\n",
      "   âŒ Errors: 0\n",
      "   ğŸ“ Output directory: f:\\DEPP\\data2\\thebest\\test\\preprocessed_test\n",
      "\n",
      "âœ… Test data ready for model evaluation!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ PATHS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "AUDIO_DIR   = \"test_dataset/data\"              # ×§×‘×¦×™ ×”×˜×¡×˜ ×¢× ×”×¨×¢×©×™×\n",
    "LABELS_PATH = \"test_dataset/labels.csv\"        # ×œ×™×™×‘×œ×™× ×©×œ ×”×˜×¡×˜\n",
    "OUTPUT_DIR  = \"preprocessed_test\"              # ×¤×œ×˜ ×œ×§×‘×¦×™ ×”×˜×¡×˜ ×”××¢×•×‘×“×™×\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ AUDIO PARAMS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SR         = 16000\n",
    "N_MELS     = 64\n",
    "HOP_LENGTH = 160\n",
    "N_FFT      = 400\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ NOISE MAPPING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "noise_to_idx = {\n",
    "    'signal_loss':          0,\n",
    "    'volume_drop':          1,\n",
    "    'compression_artifact': 2\n",
    "}\n",
    "\n",
    "print(\"ğŸ” Loading test labels and file list...\")\n",
    "labels_df = pd.read_csv(LABELS_PATH)\n",
    "\n",
    "file_list = sorted([f for f in os.listdir(AUDIO_DIR) if f.endswith(\".wav\")])\n",
    "total_files = len(file_list)\n",
    "\n",
    "# Check how many already exist\n",
    "existing = sum(1 for f in file_list \n",
    "               if os.path.exists(os.path.join(OUTPUT_DIR, f\"{os.path.splitext(f)[0]}_X.npy\")))\n",
    "\n",
    "print(f\"ğŸ“Š Found {total_files} test audio files\")\n",
    "print(f\"ğŸ“‹ {existing} files already processed\")\n",
    "print(f\"ğŸ¯ {total_files - existing} files to process\")\n",
    "\n",
    "if total_files == existing:\n",
    "    print(\"âœ… All test files already processed!\")\n",
    "else:\n",
    "    print(\"ğŸš€ Starting sequential processing of test files...\")\n",
    "    \n",
    "    successful = 0\n",
    "    skipped = 0\n",
    "    errors = []\n",
    "    \n",
    "    # Process files one by one with progress bar\n",
    "    for filename in tqdm(file_list, desc=\"Processing test files\"):\n",
    "        name = os.path.splitext(filename)[0]\n",
    "        x_path = os.path.join(OUTPUT_DIR, f\"{name}_X.npy\")\n",
    "        y_path = os.path.join(OUTPUT_DIR, f\"{name}_y.npy\")\n",
    "\n",
    "        # Skip if already exists\n",
    "        if os.path.exists(x_path) and os.path.exists(y_path):\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        path = os.path.join(AUDIO_DIR, filename)\n",
    "        \n",
    "        try:\n",
    "            # Load audio with optimized settings (same as training)\n",
    "            y_audio, _ = librosa.load(path, sr=SR, mono=True, dtype=np.float32)\n",
    "            \n",
    "            if len(y_audio) < N_FFT:\n",
    "                errors.append(f\"{filename}: too_short\")\n",
    "                continue\n",
    "\n",
    "            # Optimized spectrogram computation (exactly like training)\n",
    "            mel = librosa.feature.melspectrogram(\n",
    "                y=y_audio, sr=SR, n_fft=N_FFT,\n",
    "                hop_length=HOP_LENGTH, n_mels=N_MELS,\n",
    "                power=2.0  # Faster than default\n",
    "            )\n",
    "            \n",
    "            # Log conversion and normalization (same as training)\n",
    "            log_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "            log_mel = (log_mel + 80) / 80  # Fixed normalization [-80, 0] -> [0, 1]\n",
    "            log_mel = np.clip(log_mel, 0, 1)\n",
    "            \n",
    "            T = log_mel.shape[1]\n",
    "            \n",
    "            # Create label matrix (same structure as training)\n",
    "            label_matrix = np.zeros((T, 3), dtype=np.float32)\n",
    "            file_labels = labels_df[labels_df['filename'] == filename]\n",
    "            \n",
    "            for _, row in file_labels.iterrows():\n",
    "                start_sec, end_sec = float(row['start_time']), float(row['end_time'])\n",
    "                ntype = row['noise_type']\n",
    "\n",
    "                if ntype not in noise_to_idx:\n",
    "                    continue\n",
    "\n",
    "                start_idx = librosa.time_to_frames(start_sec, sr=SR, hop_length=HOP_LENGTH)\n",
    "                end_idx = librosa.time_to_frames(end_sec, sr=SR, hop_length=HOP_LENGTH)\n",
    "                start_idx = max(0, min(start_idx, T-1))\n",
    "                end_idx = max(start_idx+1, min(end_idx, T))\n",
    "\n",
    "                if start_idx < end_idx:\n",
    "                    label_matrix[start_idx:end_idx, noise_to_idx[ntype]] = 1.0\n",
    "\n",
    "            # Save with compression (same format as training)\n",
    "            np.save(x_path, log_mel.astype(np.float32))\n",
    "            np.save(y_path, label_matrix)\n",
    "            \n",
    "            successful += 1\n",
    "            \n",
    "            # Memory cleanup every 10 files (more frequent for test)\n",
    "            if successful % 10 == 0:\n",
    "                del y_audio, mel, log_mel, label_matrix\n",
    "                gc.collect()\n",
    "                \n",
    "        except Exception as e:\n",
    "            errors.append(f\"{filename}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Final summary\n",
    "    print(f\"\\nğŸ‰ Test Processing Complete!\")\n",
    "    print(f\"   âœ… Successfully processed: {successful}\")\n",
    "    print(f\"   â­ï¸ Skipped (already done): {skipped}\")\n",
    "    print(f\"   âŒ Errors: {len(errors)}\")\n",
    "    print(f\"   ğŸ“ Output directory: {os.path.abspath(OUTPUT_DIR)}\")\n",
    "    \n",
    "    if errors:\n",
    "        print(f\"\\nâš ï¸ Error details:\")\n",
    "        for error in errors[:5]:  # Show first 5 errors\n",
    "            print(f\"   {error}\")\n",
    "        if len(errors) > 5:\n",
    "            print(f\"   ... and {len(errors)-5} more errors\")\n",
    "\n",
    "# Force cleanup\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nâœ… Test data ready for model evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Evaluating model on NEW test data...\n",
      "ğŸ“Š Found 11 test files to evaluate\n",
      "ğŸ”„ Processing test file 1/11: AimeeMullins_2009P_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 2/11: BillGates_2010_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 2/11: BillGates_2010_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 3/11: DanBarber_2010_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 3/11: DanBarber_2010_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 4/11: DanielKahneman_2010_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 4/11: DanielKahneman_2010_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 5/11: EricMead_2009P_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 5/11: EricMead_2009P_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 6/11: GaryFlake_2010_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 6/11: GaryFlake_2010_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 7/11: JamesCameron_2010_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 7/11: JamesCameron_2010_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 8/11: JaneMcGonigal_2010_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 8/11: JaneMcGonigal_2010_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 9/11: MichaelSpecter_2010_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 9/11: MichaelSpecter_2010_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 10/11: RobertGupta_2010U_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 10/11: RobertGupta_2010U_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 11/11: TomWujec_2010U_with_noises_X.npy\n",
      "ğŸ”„ Processing test file 11/11: TomWujec_2010U_with_noises_X.npy\n",
      "\n",
      "ğŸ¯ TEST RESULTS SUMMARY:\n",
      "==================================================\n",
      "ğŸ“Š Total frames analyzed: 8,800\n",
      "ğŸ”¸ Clean frames: 7,602 (86.4%)\n",
      "ğŸ”¶ Frames with noise: 1,198 (13.6%)\n",
      "\n",
      "ğŸ¯ DETECTION PERFORMANCE:\n",
      "âœ… True Positives: 1,120\n",
      "âœ… True Negatives: 7,601\n",
      "âŒ False Positives: 1\n",
      "âŒ False Negatives: 78\n",
      "\n",
      "ğŸ“ˆ METRICS:\n",
      "ğŸ¯ Accuracy: 0.9910 (99.10%)\n",
      "ğŸ¯ Precision: 0.9991 (99.91%)\n",
      "ğŸ¯ Recall: 0.9349 (93.49%)\n",
      "ğŸ¯ F1-Score: 0.9659\n",
      "âš ï¸ False Positive Rate: 0.013%\n",
      "\n",
      "ğŸ” PER-NOISE TYPE PERFORMANCE:\n",
      "==================================================\n",
      "ğŸ¯ signal_loss:\n",
      "   Detected: 0/0 instances\n",
      "   Precision: 0.000, Recall: 0.000, F1: 0.000\n",
      "ğŸ¯ volume_drop:\n",
      "   Detected: 511/845 instances\n",
      "   Precision: 1.000, Recall: 0.605, F1: 0.754\n",
      "ğŸ¯ compression_artifact:\n",
      "   Detected: 353/353 instances\n",
      "   Precision: 0.692, Recall: 1.000, F1: 0.818\n",
      "\n",
      "ğŸ† OVERALL PERFORMANCE:\n",
      "ğŸ¯ Overall Recall: 0.721 (72.1%)\n",
      "âš ï¸ False Positive Rate: 0.013%\n",
      "\n",
      "ğŸ“‹ PERFORMANCE SUMMARY:\n",
      "==================================================\n",
      "âœ… VERY GOOD: Low FP rate (0.013%) and good recall (93.5%)\n",
      "âœ… Model evaluation completed on 11 test files\n",
      "\n",
      "ğŸ¯ TEST RESULTS SUMMARY:\n",
      "==================================================\n",
      "ğŸ“Š Total frames analyzed: 8,800\n",
      "ğŸ”¸ Clean frames: 7,602 (86.4%)\n",
      "ğŸ”¶ Frames with noise: 1,198 (13.6%)\n",
      "\n",
      "ğŸ¯ DETECTION PERFORMANCE:\n",
      "âœ… True Positives: 1,120\n",
      "âœ… True Negatives: 7,601\n",
      "âŒ False Positives: 1\n",
      "âŒ False Negatives: 78\n",
      "\n",
      "ğŸ“ˆ METRICS:\n",
      "ğŸ¯ Accuracy: 0.9910 (99.10%)\n",
      "ğŸ¯ Precision: 0.9991 (99.91%)\n",
      "ğŸ¯ Recall: 0.9349 (93.49%)\n",
      "ğŸ¯ F1-Score: 0.9659\n",
      "âš ï¸ False Positive Rate: 0.013%\n",
      "\n",
      "ğŸ” PER-NOISE TYPE PERFORMANCE:\n",
      "==================================================\n",
      "ğŸ¯ signal_loss:\n",
      "   Detected: 0/0 instances\n",
      "   Precision: 0.000, Recall: 0.000, F1: 0.000\n",
      "ğŸ¯ volume_drop:\n",
      "   Detected: 511/845 instances\n",
      "   Precision: 1.000, Recall: 0.605, F1: 0.754\n",
      "ğŸ¯ compression_artifact:\n",
      "   Detected: 353/353 instances\n",
      "   Precision: 0.692, Recall: 1.000, F1: 0.818\n",
      "\n",
      "ğŸ† OVERALL PERFORMANCE:\n",
      "ğŸ¯ Overall Recall: 0.721 (72.1%)\n",
      "âš ï¸ False Positive Rate: 0.013%\n",
      "\n",
      "ğŸ“‹ PERFORMANCE SUMMARY:\n",
      "==================================================\n",
      "âœ… VERY GOOD: Low FP rate (0.013%) and good recall (93.5%)\n",
      "âœ… Model evaluation completed on 11 test files\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“Š MODEL TEST EVALUATION ON NEW TEST DATA\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"ğŸ§ª Evaluating model on NEW test data...\")\n",
    "\n",
    "# Setup NEW test data (NOT from training set)\n",
    "TEST_DATA_DIR = \"preprocessed_test\"  # ×§×‘×¦×™ ×”×˜×¡×˜ ×”×—×“×©×™× ×©×œ× ×•\n",
    "X_test_files = sorted([f for f in os.listdir(TEST_DATA_DIR) if f.endswith(\"_X.npy\")])\n",
    "y_test_files = sorted([f for f in os.listdir(TEST_DATA_DIR) if f.endswith(\"_y.npy\")])\n",
    "\n",
    "print(f\"ğŸ“Š Found {len(X_test_files)} test files to evaluate\")\n",
    "\n",
    "def load_test_xy(i):\n",
    "    \"\"\"×˜×•×¢×Ÿ ×§×•×‘×¥ ×˜×¡×˜ ×¢× ××•×ª×” ×©×™×˜×” ×›××• ×‘××™××•×Ÿ\"\"\"\n",
    "    X = np.load(os.path.join(TEST_DATA_DIR, X_test_files[i])).astype(np.float32)\n",
    "    y = np.load(os.path.join(TEST_DATA_DIR, y_test_files[i])).astype(np.float32)\n",
    "    \n",
    "    # ×•×“× ×©×”×¦×•×¨×” × ×›×•× ×” (T, 3)\n",
    "    if y.shape[0] == 3 and y.shape[1] != 3: \n",
    "        y = y.T\n",
    "    \n",
    "    MAX_T = 800  # ××•×ª×• ××’×‘×œ×ª ×–××Ÿ ×›××• ×‘××™××•×Ÿ\n",
    "    actual_T = min(X.shape[1], y.shape[0], MAX_T)\n",
    "    X = X[:, :actual_T]\n",
    "    y = y[:actual_T]\n",
    "    \n",
    "    return X[..., None], y\n",
    "\n",
    "# ×¨×©×™××•×ª ×œ××™×¡×•×£ ×”×ª×•×¦××•×ª\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "file_results = []\n",
    "\n",
    "# ×¢×‘×•×¨ ×¢×œ ×›×œ ×§×‘×¦×™ ×”×˜×¡×˜ ×”×—×“×©×™×\n",
    "for i, test_file in enumerate(X_test_files):\n",
    "    print(f\"ğŸ”„ Processing test file {i+1}/{len(X_test_files)}: {test_file}\")\n",
    "    \n",
    "    try:\n",
    "        X, y_true = load_test_xy(i)\n",
    "        X_input = X[np.newaxis, :]  # ×”×•×¡×£ batch dimension\n",
    "        \n",
    "        # ×—×™×–×•×™ ×¢× ×”××•×“×œ ×”×××•××Ÿ\n",
    "        y_pred = model.predict(X_input, verbose=0)[0]\n",
    "        \n",
    "        # ×™×™×©×•×¨ ×”××•×¨×›×™× ×‘××§×¨×” ×©×œ ×”×‘×“×œ×™× ×§×˜× ×™×\n",
    "        min_length = min(y_true.shape[0], y_pred.shape[0])\n",
    "        y_true = y_true[:min_length]\n",
    "        y_pred = y_pred[:min_length]\n",
    "        \n",
    "        all_predictions.append(y_pred)\n",
    "        all_true_labels.append(y_true)\n",
    "        \n",
    "        # ×¡×˜×˜×™×¡×˜×™×§×•×ª ×œ×§×•×‘×¥ ×‘×•×“×“\n",
    "        file_frames = len(y_true)\n",
    "        file_noise_frames = np.sum(np.any(y_true > 0.5, axis=1))\n",
    "        file_results.append({\n",
    "            'filename': test_file,\n",
    "            'total_frames': file_frames,\n",
    "            'noise_frames': file_noise_frames,\n",
    "            'noise_percentage': (file_noise_frames / file_frames) * 100\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {test_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "# × ×™×ª×•×— ×ª×•×¦××•×ª ×›×œ×œ×™\n",
    "if all_predictions:\n",
    "    all_pred_concat = np.vstack(all_predictions)\n",
    "    all_true_concat = np.vstack(all_true_labels)\n",
    "    \n",
    "    # ×¨×£ ×”×—×œ×˜×” - 0.8 (×¨×£ ×’×‘×•×” ×œ×“×™×•×§ ×’×‘×•×” ×›××• ×‘××™××•×Ÿ)\n",
    "    THRESHOLD = 0.8\n",
    "    predictions_binary = (all_pred_concat > THRESHOLD).astype(int)\n",
    "    true_labels_binary = (all_true_concat > 0.5).astype(int)\n",
    "    \n",
    "    # ×¡×˜×˜×™×¡×˜×™×§×•×ª ×›×œ×œ×™×•×ª\n",
    "    total_frames = len(all_true_concat)\n",
    "    frames_clean = np.sum(~np.any(true_labels_binary, axis=1))\n",
    "    frames_with_noise = np.sum(np.any(true_labels_binary, axis=1))\n",
    "    \n",
    "    # ×©×’×™××•×ª\n",
    "    false_positives = np.sum(np.any(predictions_binary, axis=1) & ~np.any(true_labels_binary, axis=1))\n",
    "    false_negatives = np.sum(np.any(true_labels_binary, axis=1) & ~np.any(predictions_binary, axis=1))\n",
    "    true_positives = np.sum(np.any(predictions_binary, axis=1) & np.any(true_labels_binary, axis=1))\n",
    "    true_negatives = np.sum(~np.any(predictions_binary, axis=1) & ~np.any(true_labels_binary, axis=1))\n",
    "    \n",
    "    # ×—×™×©×•×‘ ××“×“×™×\n",
    "    fp_rate = (false_positives / frames_clean * 100) if frames_clean > 0 else 0\n",
    "    precision = (true_positives / (true_positives + false_positives)) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = (true_positives / (true_positives + false_negatives)) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1_score = (2 * precision * recall / (precision + recall)) if (precision + recall) > 0 else 0\n",
    "    accuracy = (true_positives + true_negatives) / total_frames\n",
    "    \n",
    "    print(f\"\\nğŸ¯ TEST RESULTS SUMMARY:\")\n",
    "    print(f\"=\" * 50)\n",
    "    print(f\"ğŸ“Š Total frames analyzed: {total_frames:,}\")\n",
    "    print(f\"ğŸ”¸ Clean frames: {frames_clean:,} ({(frames_clean/total_frames)*100:.1f}%)\")\n",
    "    print(f\"ğŸ”¶ Frames with noise: {frames_with_noise:,} ({(frames_with_noise/total_frames)*100:.1f}%)\")\n",
    "    print(f\"\\nğŸ¯ DETECTION PERFORMANCE:\")\n",
    "    print(f\"âœ… True Positives: {true_positives:,}\")\n",
    "    print(f\"âœ… True Negatives: {true_negatives:,}\")\n",
    "    print(f\"âŒ False Positives: {false_positives:,}\")\n",
    "    print(f\"âŒ False Negatives: {false_negatives:,}\")\n",
    "    print(f\"\\nğŸ“ˆ METRICS:\")\n",
    "    print(f\"ğŸ¯ Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"ğŸ¯ Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "    print(f\"ğŸ¯ Recall: {recall:.4f} ({recall*100:.2f}%)\")\n",
    "    print(f\"ğŸ¯ F1-Score: {f1_score:.4f}\")\n",
    "    print(f\"âš ï¸ False Positive Rate: {fp_rate:.3f}%\")\n",
    "    \n",
    "    # ×‘×™×¦×•×¢×™× ×œ×¤×™ ×¡×•×’ ×¨×¢×©\n",
    "    noise_names = ['signal_loss', 'volume_drop', 'compression_artifact']\n",
    "    print(f\"\\nğŸ” PER-NOISE TYPE PERFORMANCE:\")\n",
    "    print(f\"=\" * 50)\n",
    "    \n",
    "    total_detected = 0\n",
    "    total_true = 0\n",
    "    \n",
    "    for i, noise_name in enumerate(noise_names):\n",
    "        true_noise = true_labels_binary[:, i]\n",
    "        pred_noise = predictions_binary[:, i]\n",
    "        \n",
    "        tp_noise = np.sum((true_noise == 1) & (pred_noise == 1))\n",
    "        fp_noise = np.sum((true_noise == 0) & (pred_noise == 1))\n",
    "        fn_noise = np.sum((true_noise == 1) & (pred_noise == 0))\n",
    "        true_count = np.sum(true_noise)\n",
    "        \n",
    "        total_detected += tp_noise\n",
    "        total_true += true_count\n",
    "        \n",
    "        noise_precision = tp_noise / (tp_noise + fp_noise) if (tp_noise + fp_noise) > 0 else 0\n",
    "        noise_recall = tp_noise / (tp_noise + fn_noise) if (tp_noise + fn_noise) > 0 else 0\n",
    "        noise_f1 = 2 * noise_precision * noise_recall / (noise_precision + noise_recall) if (noise_precision + noise_recall) > 0 else 0\n",
    "        \n",
    "        print(f\"ğŸ¯ {noise_name}:\")\n",
    "        print(f\"   Detected: {tp_noise}/{true_count} instances\")\n",
    "        print(f\"   Precision: {noise_precision:.3f}, Recall: {noise_recall:.3f}, F1: {noise_f1:.3f}\")\n",
    "    \n",
    "    overall_recall = total_detected / total_true if total_true > 0 else 0\n",
    "    print(f\"\\nğŸ† OVERALL PERFORMANCE:\")\n",
    "    print(f\"ğŸ¯ Overall Recall: {overall_recall:.3f} ({overall_recall*100:.1f}%)\")\n",
    "    print(f\"âš ï¸ False Positive Rate: {fp_rate:.3f}%\")\n",
    "    \n",
    "    # ×¡×™×›×•× ×‘×™×¦×•×¢×™×\n",
    "    print(f\"\\nğŸ“‹ PERFORMANCE SUMMARY:\")\n",
    "    print(f\"=\" * 50)\n",
    "    if fp_rate < 0.1 and recall > 0.95:\n",
    "        print(f\"ğŸ† EXCELLENT: Very low FP rate ({fp_rate:.3f}%) and high recall ({recall*100:.1f}%)\")\n",
    "    elif fp_rate < 0.5 and recall > 0.9:\n",
    "        print(f\"âœ… VERY GOOD: Low FP rate ({fp_rate:.3f}%) and good recall ({recall*100:.1f}%)\")\n",
    "    elif fp_rate < 1.0 and recall > 0.8:\n",
    "        print(f\"ğŸ‘ GOOD: Acceptable FP rate ({fp_rate:.3f}%) and recall ({recall*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ NEEDS IMPROVEMENT: FP rate {fp_rate:.3f}%, recall {recall*100:.1f}%\")\n",
    "    \n",
    "    print(f\"âœ… Model evaluation completed on {len(X_test_files)} test files\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No test files processed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda activate tf215\n",
    "cd F:\\DEPP\\data2\\data3\\test\n",
    "python test_terminal.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ FULL TEST: 11 files | CPU threadsâ‰ˆ11\n",
      "Params: CHUNK=512, BATCH=16, TH=[0.800000011920929, 0.800000011920929, 0.800000011920929]\n",
      "âœ… CORRECTED FP: Only when predicting noise where GT has NO noise, â‰¥3.0s\n",
      "Files: ['AimeeMullins_2009P_with_noises', 'BillGates_2010_with_noises', 'DanBarber_2010_with_noises', 'DanielKahneman_2010_with_noises', 'EricMead_2009P_with_noises', 'GaryFlake_2010_with_noises', 'JamesCameron_2010_with_noises', 'JaneMcGonigal_2010_with_noises', 'MichaelSpecter_2010_with_noises', 'RobertGupta_2010U_with_noises', 'TomWujec_2010U_with_noises']\n",
      "\n",
      "â–¶ [1/3] AimeeMullins_2009P_with_noises\n",
      "   â€¢ Frames: 131822 (~21:58)\n",
      "   âœ“ GT events: 15 | Recall: 79.6% | TRUE FPâ‰¥3.0s: 0\n",
      "   â€¢ Inference: 28.9s\n",
      "\n",
      "â–¶ [2/3] BillGates_2010_with_noises\n",
      "   â€¢ Frames: 177203 (~29:32)\n",
      "   âœ“ GT events: 15 | Recall: 79.6% | TRUE FPâ‰¥3.0s: 0\n",
      "   â€¢ Inference: 28.9s\n",
      "\n",
      "â–¶ [2/3] BillGates_2010_with_noises\n",
      "   â€¢ Frames: 177203 (~29:32)\n",
      "   âœ“ GT events: 13 | Recall: 79.4% | TRUE FPâ‰¥3.0s: 2\n",
      "   â€¢ Inference: 28.8s\n",
      "\n",
      "â–¶ [3/3] DanBarber_2010_with_noises\n",
      "   â€¢ Frames: 117004 (~19:30)\n",
      "   âœ“ GT events: 13 | Recall: 79.4% | TRUE FPâ‰¥3.0s: 2\n",
      "   â€¢ Inference: 28.8s\n",
      "\n",
      "â–¶ [3/3] DanBarber_2010_with_noises\n",
      "   â€¢ Frames: 117004 (~19:30)\n",
      "   âœ“ GT events: 10 | Recall: 83.4% | TRUE FPâ‰¥3.0s: 7\n",
      "   â€¢ Inference: 20.2s\n",
      "\n",
      "â–¶ [4/3] DanielKahneman_2010_with_noises\n",
      "   â€¢ Frames: 123670 (~20:36)\n",
      "   âœ“ GT events: 10 | Recall: 83.4% | TRUE FPâ‰¥3.0s: 7\n",
      "   â€¢ Inference: 20.2s\n",
      "\n",
      "â–¶ [4/3] DanielKahneman_2010_with_noises\n",
      "   â€¢ Frames: 123670 (~20:36)\n",
      "   âœ“ GT events: 12 | Recall: 78.3% | TRUE FPâ‰¥3.0s: 0\n",
      "   â€¢ Inference: 20.1s\n",
      "\n",
      "â–¶ [5/3] EricMead_2009P_with_noises\n",
      "   â€¢ Frames: 54579 (~09:05)\n",
      "   âœ“ GT events: 12 | Recall: 78.3% | TRUE FPâ‰¥3.0s: 0\n",
      "   â€¢ Inference: 20.1s\n",
      "\n",
      "â–¶ [5/3] EricMead_2009P_with_noises\n",
      "   â€¢ Frames: 54579 (~09:05)\n",
      "   âœ“ GT events: 11 | Recall: 89.4% | TRUE FPâ‰¥3.0s: 0\n",
      "   â€¢ Inference: 11.6s\n",
      "\n",
      "â–¶ [6/3] GaryFlake_2010_with_noises\n",
      "   â€¢ Frames: 41339 (~06:53)\n",
      "   âœ“ GT events: 11 | Recall: 89.4% | TRUE FPâ‰¥3.0s: 0\n",
      "   â€¢ Inference: 11.6s\n",
      "\n",
      "â–¶ [6/3] GaryFlake_2010_with_noises\n",
      "   â€¢ Frames: 41339 (~06:53)\n",
      "   âœ“ GT events: 14 | Recall: 74.3% | TRUE FPâ‰¥3.0s: 1\n",
      "   â€¢ Inference: 7.4s\n",
      "\n",
      "â–¶ [7/3] JamesCameron_2010_with_noises\n",
      "   â€¢ Frames: 105577 (~17:35)\n",
      "   âœ“ GT events: 14 | Recall: 74.3% | TRUE FPâ‰¥3.0s: 1\n",
      "   â€¢ Inference: 7.4s\n",
      "\n",
      "â–¶ [7/3] JamesCameron_2010_with_noises\n",
      "   â€¢ Frames: 105577 (~17:35)\n",
      "   âœ“ GT events: 13 | Recall: 86.6% | TRUE FPâ‰¥3.0s: 1\n",
      "   â€¢ Inference: 18.7s\n",
      "\n",
      "â–¶ [8/3] JaneMcGonigal_2010_with_noises\n",
      "   â€¢ Frames: 123152 (~20:31)\n",
      "   âœ“ GT events: 13 | Recall: 86.6% | TRUE FPâ‰¥3.0s: 1\n",
      "   â€¢ Inference: 18.7s\n",
      "\n",
      "â–¶ [8/3] JaneMcGonigal_2010_with_noises\n",
      "   â€¢ Frames: 123152 (~20:31)\n",
      "   âœ“ GT events: 14 | Recall: 79.4% | TRUE FPâ‰¥3.0s: 2\n",
      "   â€¢ Inference: 20.5s\n",
      "\n",
      "â–¶ [9/3] MichaelSpecter_2010_with_noises\n",
      "   â€¢ Frames: 114117 (~19:01)\n",
      "   âœ“ GT events: 14 | Recall: 79.4% | TRUE FPâ‰¥3.0s: 2\n",
      "   â€¢ Inference: 20.5s\n",
      "\n",
      "â–¶ [9/3] MichaelSpecter_2010_with_noises\n",
      "   â€¢ Frames: 114117 (~19:01)\n",
      "   âœ“ GT events: 11 | Recall: 76.2% | TRUE FPâ‰¥3.0s: 1\n",
      "   â€¢ Inference: 23.2s\n",
      "\n",
      "â–¶ [10/3] RobertGupta_2010U_with_noises\n",
      "   â€¢ Frames: 71852 (~11:58)\n",
      "   âœ“ GT events: 11 | Recall: 76.2% | TRUE FPâ‰¥3.0s: 1\n",
      "   â€¢ Inference: 23.2s\n",
      "\n",
      "â–¶ [10/3] RobertGupta_2010U_with_noises\n",
      "   â€¢ Frames: 71852 (~11:58)\n",
      "   âœ“ GT events: 14 | Recall: 80.7% | TRUE FPâ‰¥3.0s: 0\n",
      "   â€¢ Inference: 13.7s\n",
      "\n",
      "â–¶ [11/3] TomWujec_2010U_with_noises\n",
      "   â€¢ Frames: 44248 (~07:22)\n",
      "   âœ“ GT events: 14 | Recall: 80.7% | TRUE FPâ‰¥3.0s: 0\n",
      "   â€¢ Inference: 13.7s\n",
      "\n",
      "â–¶ [11/3] TomWujec_2010U_with_noises\n",
      "   â€¢ Frames: 44248 (~07:22)\n",
      "   âœ“ GT events: 14 | Recall: 86.5% | TRUE FPâ‰¥3.0s: 0\n",
      "   â€¢ Inference: 9.6s\n",
      "\n",
      "ğŸ¯ SUMMARY: Total TRUE FPâ‰¥3.0s: 14\n",
      "âš¡ Done in 202.8s total\n",
      "âœ… Super-fast test completed!\n",
      "   âœ“ GT events: 14 | Recall: 86.5% | TRUE FPâ‰¥3.0s: 0\n",
      "   â€¢ Inference: 9.6s\n",
      "\n",
      "ğŸ¯ SUMMARY: Total TRUE FPâ‰¥3.0s: 14\n",
      "âš¡ Done in 202.8s total\n",
      "âœ… Super-fast test completed!\n"
     ]
    }
   ],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# âš¡ SUPER-FAST CPU INFERENCE (3 files only, vectorized batching)\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import os, time, numpy as np, tensorflow as tf\n",
    "\n",
    "# â”€â”€ CPU threading optimization\n",
    "try:\n",
    "    n_threads = max(1, (os.cpu_count() or 4) - 1)\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = str(n_threads)\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = str(n_threads)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(n_threads)\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(n_threads)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# â”€â”€ Constants\n",
    "DATA_DIR   = \"preprocessed_test\"\n",
    "LABELS     = [\"signal_loss\", \"volume_drop\", \"compression_artifact\"]\n",
    "THRESHOLDS = np.array([0.8, 0.8, 0.8], dtype=np.float32)\n",
    "SR, HOP = 16000, 160\n",
    "FRAME_TIME = HOP / SR\n",
    "MIN_FP_SEC = 3.0  # âœ… Changed to 3.0 seconds as requested\n",
    "MIN_FP_FRM = int(round(MIN_FP_SEC / FRAME_TIME))\n",
    "\n",
    "def mmss(sec):\n",
    "    m, s = divmod(int(sec), 60)\n",
    "    return f\"{m:02d}:{s:02d}\"\n",
    "\n",
    "def find_events(bin_arr):\n",
    "    x = bin_arr.astype(np.int8)\n",
    "    edges = np.flatnonzero(np.diff(np.r_[0, x, 0]))\n",
    "    return list(zip(edges[::2], edges[1::2]))\n",
    "\n",
    "# â”€â”€ Fast compiled forward function (without JIT for compatibility)\n",
    "@tf.function\n",
    "def forward_call(batch_64_T1):\n",
    "    return model(batch_64_T1, training=False)\n",
    "\n",
    "def infer_cpu_vectorized(X_64_T, max_chunk=512, batch_chunks=16):\n",
    "    \"\"\"\n",
    "    Ultra-fast CPU inference:\n",
    "    - Pads temporal axis to multiple of max_chunk\n",
    "    - Vectorized reshape+transpose to create chunk batches without loops\n",
    "    - Runs in bursts of batch_chunks to save memory\n",
    "    \"\"\"\n",
    "    T = int(X_64_T.shape[1])\n",
    "    if T == 0:\n",
    "        return np.zeros((0, 3), dtype=np.float32)\n",
    "\n",
    "    # Pad temporal axis to multiple of max_chunk\n",
    "    num_chunks = (T + max_chunk - 1) // max_chunk\n",
    "    pad_T = num_chunks * max_chunk\n",
    "    if pad_T != T:\n",
    "        X_pad = np.pad(X_64_T, ((0, 0), (0, pad_T - T)), mode=\"constant\")\n",
    "    else:\n",
    "        X_pad = X_64_T\n",
    "\n",
    "    # Vectorized reshape: (64, pad_T) -> (num_chunks, 64, max_chunk, 1)\n",
    "    X_blocks = X_pad.reshape(64, num_chunks, max_chunk)\n",
    "    X_batches_all = np.transpose(X_blocks, (1, 0, 2))[:, :, :, None]\n",
    "\n",
    "    preds_out = np.empty((pad_T, 3), dtype=np.float32)\n",
    "\n",
    "    # One-time warm-up (cached by tf.function)\n",
    "    _ = forward_call(tf.zeros((1, 64, max_chunk, 1), dtype=tf.float32))\n",
    "\n",
    "    # Process in large but manageable bursts for CPU\n",
    "    for i in range(0, num_chunks, batch_chunks):\n",
    "        j = min(i + batch_chunks, num_chunks)\n",
    "        batch = tf.convert_to_tensor(X_batches_all[i:j], dtype=tf.float32)\n",
    "        yb = forward_call(batch).numpy()\n",
    "        preds_out[i*max_chunk : j*max_chunk] = yb.reshape(-1, 3)\n",
    "\n",
    "    return preds_out[:T]\n",
    "\n",
    "def analyze_file(base, y_true, probs):\n",
    "    \"\"\"\n",
    "    âœ… CORRECTED FP LOGIC: Only count as FP when model predicts noise where GT has NO noise\n",
    "    AND only if duration â‰¥ 2.5 seconds\n",
    "    \"\"\"\n",
    "    y_pred = (probs > THRESHOLDS[None, :]).astype(np.uint8)\n",
    "    \n",
    "    # âœ… Key correction: FP only when model says \"any noise\" but GT says \"no noise at all\"\n",
    "    gt_has_any_noise = (np.any(y_true == 1, axis=1)).astype(np.uint8)\n",
    "    pred_has_any_noise = (np.any(y_pred == 1, axis=1)).astype(np.uint8)\n",
    "\n",
    "    # GT events and recall calculation\n",
    "    gt_events = find_events(gt_has_any_noise)\n",
    "    total_gt_sec = sum((e - s) * FRAME_TIME for s, e in gt_events)\n",
    "    overlap_sec = np.sum(gt_has_any_noise & pred_has_any_noise) * FRAME_TIME\n",
    "    recall = (overlap_sec / total_gt_sec) if total_gt_sec > 1e-9 else 0.0\n",
    "\n",
    "    # âœ… TRUE False Positives: model predicts \"any noise\" where GT has \"no noise at all\"\n",
    "    true_fp_mask = (pred_has_any_noise == 1) & (gt_has_any_noise == 0)\n",
    "    fp_events = find_events(true_fp_mask)\n",
    "    fp_count = sum(1 for s, e in fp_events if (e - s) >= MIN_FP_FRM)\n",
    "\n",
    "    print(f\"   âœ“ GT events: {len(gt_events)} | Recall: {recall:.1%} | TRUE FPâ‰¥{MIN_FP_SEC:.1f}s: {fp_count}\")\n",
    "    return fp_count\n",
    "\n",
    "# â”€â”€ Safety check\n",
    "if 'model' not in globals():\n",
    "    raise RuntimeError(\"âš ï¸ model not loaded - run model loading cell first\")\n",
    "\n",
    "# â”€â”€ Process ALL files in directory\n",
    "label_files = sorted(f for f in os.listdir(DATA_DIR) if f.endswith(\"_y.npy\"))  # ALL FILES!\n",
    "print(f\"ğŸš€ FULL TEST: {len(label_files)} files | CPU threadsâ‰ˆ{n_threads}\")\n",
    "print(f\"Params: CHUNK=512, BATCH=16, TH={THRESHOLDS.tolist()}\")\n",
    "print(f\"âœ… CORRECTED FP: Only when predicting noise where GT has NO noise, â‰¥{MIN_FP_SEC:.1f}s\")\n",
    "print(f\"Files: {[f[:-6] for f in label_files]}\")\n",
    "\n",
    "t_all = time.time()\n",
    "global_fp_total = 0\n",
    "\n",
    "for idx, y_file in enumerate(label_files, 1):\n",
    "    base = y_file[:-6]\n",
    "    x_file = base + \"_X.npy\"\n",
    "    print(f\"\\nâ–¶ [{idx}/3] {base}\")\n",
    "\n",
    "    try:\n",
    "        y_true = np.load(os.path.join(DATA_DIR, y_file), mmap_mode='r')\n",
    "        X = np.load(os.path.join(DATA_DIR, x_file), mmap_mode='r')\n",
    "        T = int(X.shape[1])\n",
    "        print(f\"   â€¢ Frames: {T} (~{mmss(T*FRAME_TIME)})\")\n",
    "\n",
    "        t0 = time.time()\n",
    "        probs = infer_cpu_vectorized(X, max_chunk=512, batch_chunks=16)\n",
    "        dt = time.time() - t0\n",
    "\n",
    "        fp_count = analyze_file(base, y_true, probs)\n",
    "        global_fp_total += fp_count\n",
    "        print(f\"   â€¢ Inference: {dt:.1f}s\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âœ— Error: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ SUMMARY: Total TRUE FPâ‰¥{MIN_FP_SEC:.1f}s: {global_fp_total}\")\n",
    "print(f\"âš¡ Done in {time.time() - t_all:.1f}s total\")\n",
    "print(\"âœ… Super-fast test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Starting transcription of missing text from original files...\n",
      "ğŸ“‹ Loading existing test labels...\n",
      "   Found 141 noise events in 11 files\n",
      "ğŸ”— Mapping to original WAV files...\n",
      "   Mapped to 11 original files\n",
      "\n",
      "ğŸ™ï¸ Starting transcription of 141 segments...\n",
      "\n",
      "ğŸ“ Processing: AimeeMullins_2009P.wav (15 segments)\n",
      "   Duration: 1318.2s\n",
      "   ğŸ”„ Segment 1/15 (1/141): compression_artifact 57.13s-60.40s\n",
      "      âœ… Transcribed: 'Down, worn out, weakened.'\n",
      "   ğŸ”„ Segment 2/15 (2/141): volume_drop 134.79s-137.93s\n",
      "      âœ… Transcribed: 'I mean, from this entry, it would.'\n",
      "   ğŸ”„ Segment 3/15 (3/141): compression_artifact 252.83s-256.19s\n",
      "      âœ… Transcribed: 'An Italian American whose name apparently was.'\n",
      "   ğŸ”„ Segment 4/15 (4/141): volume_drop 305.98s-309.07s\n",
      "      âœ… Transcribed: 'He came in to my session.'\n",
      "   ğŸ”„ Segment 5/15 (5/141): compression_artifact 365.35s-368.77s\n",
      "      âœ… Transcribed: 'And athletic person well into the future. This is ...'\n",
      "   ğŸ”„ Segment 6/15 (6/141): compression_artifact 472.00s-475.38s\n",
      "      âœ… Transcribed: 'I think I'm starting to figure out why.'\n",
      "   ğŸ”„ Segment 7/15 (7/141): compression_artifact 590.62s-594.04s\n",
      "      âœ… Transcribed: 'And consistent disability I've had to confront is.'\n",
      "   ğŸ”„ Segment 8/15 (8/141): compression_artifact 776.31s-779.85s\n",
      "      âœ… Transcribed: 'A sense of self, a sense of our own power.'\n",
      "   ğŸ”„ Segment 9/15 (9/141): signal_loss 826.62s-829.91s\n",
      "      âœ… Transcribed: 'To be even a little bit more dangerous, we can rel...'\n",
      "   ğŸ”„ Segment 10/15 (10/141): volume_drop 941.32s-944.88s\n",
      "      âœ… Transcribed: 'Toes in that. He had to be the bearer, the strange...'\n",
      "   ğŸ”„ Segment 11/15 (11/141): compression_artifact 975.22s-978.33s\n",
      "      âœ… Transcribed: 'Whether winning a second grade spelling bee.'\n",
      "   ğŸ”„ Segment 12/15 (12/141): compression_artifact 997.34s-1001.21s\n",
      "      âœ… Transcribed: 'Called this part of the course the X factor, and i...'\n",
      "   ğŸ”„ Segment 13/15 (13/141): signal_loss 1016.24s-1019.90s\n",
      "      âœ… Transcribed: 'In my experience, unless rep.'\n",
      "   ğŸ”„ Segment 14/15 (14/141): compression_artifact 1138.88s-1142.73s\n",
      "      âœ… Transcribed: 'When they were moving from grammar schools to comp...'\n",
      "   ğŸ”„ Segment 15/15 (15/141): compression_artifact 1212.91s-1216.03s\n",
      "      âœ… Transcribed: 'Is a crushed spirit.'\n",
      "\n",
      "ğŸ“ Processing: BillGates_2010.wav (13 segments)\n",
      "   Duration: 1772.0s\n",
      "   ğŸ”„ Segment 1/13 (16/141): compression_artifact 56.78s-60.01s\n",
      "      âœ… Transcribed: 'Environment simply can't support and that.'\n",
      "   ğŸ”„ Segment 2/13 (17/141): compression_artifact 288.94s-292.67s\n",
      "      âœ… Transcribed: 'But there we see an increase of about.'\n",
      "   ğŸ”„ Segment 3/13 (18/141): signal_loss 373.18s-376.45s\n",
      "      âœ… Transcribed: 'Fort, where the rooms for improvement are far, far...'\n",
      "   ğŸ”„ Segment 4/13 (19/141): volume_drop 436.23s-439.49s\n",
      "      âœ… Transcribed: 'The microprocessor is a miracle. The personal comp...'\n",
      "   ğŸ”„ Segment 5/13 (20/141): signal_loss 472.24s-475.45s\n",
      "      âœ… Transcribed: 'That would grab people's imagination here.'\n",
      "   ğŸ”„ Segment 6/13 (21/141): volume_drop 556.40s-560.28s\n",
      "      âœ… Transcribed: 'Let's look first at the burning fossil fuels. Eith...'\n",
      "   ğŸ”„ Segment 7/13 (22/141): compression_artifact 645.17s-648.80s\n",
      "      âœ… Transcribed: 'These are what people often refer to as the renewa...'\n",
      "   ğŸ”„ Segment 8/13 (23/141): compression_artifact 900.86s-904.86s\n",
      "      âœ… Transcribed: 'Process, you'd have enough fuel for the entire lif...'\n",
      "   ğŸ”„ Segment 9/13 (24/141): signal_loss 1034.00s-1037.26s\n",
      "      âœ… Transcribed: 'There's a lot that has to come together. So this i...'\n",
      "   ğŸ”„ Segment 10/13 (25/141): compression_artifact 1077.18s-1080.83s\n",
      "      âœ… Transcribed: 'To you to step forward and drive.'\n",
      "   ğŸ”„ Segment 11/13 (26/141): volume_drop 1131.55s-1135.54s\n",
      "      âœ… Transcribed: 'Thank you. Thank you.'\n",
      "   ğŸ”„ Segment 12/13 (27/141): volume_drop 1490.45s-1494.14s\n",
      "      âœ… Transcribed: 'Well, unfortunately, the skeptics come in differen...'\n",
      "   ğŸ”„ Segment 13/13 (28/141): compression_artifact 1617.50s-1620.90s\n",
      "      âœ… Transcribed: 'Rich can afford that. I mean, all of us here could...'\n",
      "\n",
      "ğŸ“ Processing: DanBarber_2010.wav (10 segments)\n",
      "   Duration: 1170.0s\n",
      "   ğŸ”„ Segment 1/10 (29/141): volume_drop 3.79s-6.95s\n",
      "      âœ… Transcribed: 'Ra.'\n",
      "   ğŸ”„ Segment 2/10 (30/141): volume_drop 124.13s-127.64s\n",
      "      âœ… Transcribed: 'A farm tuna. Not very sustainable.'\n",
      "   ğŸ”„ Segment 3/10 (31/141): compression_artifact 178.24s-182.10s\n",
      "      âœ… Transcribed: 'Great. I said, got off the phone.'\n",
      "   ğŸ”„ Segment 4/10 (32/141): compression_artifact 396.73s-400.50s\n",
      "      âœ… Transcribed: 'Biologically, it was a disaster. Killed like 90% o...'\n",
      "   ğŸ”„ Segment 5/10 (33/141): compression_artifact 545.95s-549.54s\n",
      "      âœ… Transcribed: 'He goes on to tell me it's.'\n",
      "   ğŸ”„ Segment 6/10 (34/141): compression_artifact 592.03s-595.87s\n",
      "      âœ… Transcribed: 'Change, and we rounded the corner and saw the most...'\n",
      "   ğŸ”„ Segment 7/10 (35/141): compression_artifact 695.62s-699.30s\n",
      "      âœ… Transcribed: 'Better for building nests every morning.'\n",
      "   ğŸ”„ Segment 8/10 (36/141): volume_drop 1032.47s-1035.59s\n",
      "      âœ… Transcribed: 'So let's start by asking, how are we going to feed...'\n",
      "   ğŸ”„ Segment 9/10 (37/141): volume_drop 1099.32s-1102.88s\n",
      "      âœ… Transcribed: 'Because they're the ones that are experts in flavo...'\n",
      "   ğŸ”„ Segment 10/10 (38/141): volume_drop 1133.52s-1137.24s\n",
      "      âœ… Transcribed: ''\n",
      "\n",
      "ğŸ“ Processing: DanielKahneman_2010.wav (12 segments)\n",
      "   Duration: 1236.7s\n",
      "   ğŸ”„ Segment 1/12 (39/141): compression_artifact 0.70s-4.24s\n",
      "      âœ… Transcribed: ''\n",
      "   ğŸ”„ Segment 2/12 (40/141): volume_drop 85.35s-88.84s\n",
      "      âœ… Transcribed: 'A more complicated view of what well being is.'\n",
      "   ğŸ”„ Segment 3/12 (41/141): compression_artifact 158.30s-162.06s\n",
      "      âœ… Transcribed: 'Of glorious music. They counted for nothing becaus...'\n",
      "   ğŸ”„ Segment 4/12 (42/141): volume_drop 261.20s-264.63s\n",
      "      âœ… Transcribed: 'Go into detail. It's no longer painful these days,...'\n",
      "   ğŸ”„ Segment 5/12 (43/141): signal_loss 326.85s-330.40s\n",
      "      âœ… Transcribed: 'Where pain was at its peak at the very end.'\n",
      "   ğŸ”„ Segment 6/12 (44/141): compression_artifact 379.12s-382.95s\n",
      "      âœ… Transcribed: 'That for a couple of minutes you have made the exp...'\n",
      "   ğŸ”„ Segment 7/12 (45/141): volume_drop 417.02s-420.24s\n",
      "      âœ… Transcribed: 'Dominated. Now the experiencing.'\n",
      "   ğŸ”„ Segment 8/12 (46/141): compression_artifact 638.30s-641.74s\n",
      "      âœ… Transcribed: 'If I had ever opened the folder with the 600 pictu...'\n",
      "   ğŸ”„ Segment 9/12 (47/141): volume_drop 665.02s-668.78s\n",
      "      âœ… Transcribed: 'Relative to the weight that we put on experiences.'\n",
      "   ğŸ”„ Segment 10/12 (48/141): signal_loss 1146.21s-1149.23s\n",
      "      âœ… Transcribed: 'Happening. People are recognizing that they ought ...'\n",
      "   ğŸ”„ Segment 11/12 (49/141): compression_artifact 1167.41s-1171.29s\n",
      "      âœ… Transcribed: 'Goes very different ways, depending on how you thi...'\n",
      "   ğŸ”„ Segment 12/12 (50/141): volume_drop 1227.40s-1230.71s\n",
      "      âœ… Transcribed: 'Sharing. That's.'\n",
      "\n",
      "ğŸ“ Processing: EricMead_2009P.wav (11 segments)\n",
      "   Duration: 545.8s\n",
      "   ğŸ”„ Segment 1/11 (51/141): volume_drop 3.90s-7.49s\n",
      "      âœ… Transcribed: 'Ra.'\n",
      "   ğŸ”„ Segment 2/11 (52/141): compression_artifact 36.58s-39.64s\n",
      "      âœ… Transcribed: 'Words. Sugar pills have a measurable effect.'\n",
      "   ğŸ”„ Segment 3/11 (53/141): compression_artifact 99.57s-102.71s\n",
      "      âœ… Transcribed: 'That way. You can see that at no time can anything...'\n",
      "   ğŸ”„ Segment 4/11 (54/141): compression_artifact 256.61s-259.85s\n",
      "      âœ… Transcribed: 'Pills. But a white pill is not as good as a blue p...'\n",
      "   ğŸ”„ Segment 5/11 (55/141): compression_artifact 278.91s-282.24s\n",
      "      âœ… Transcribed: 'One pill twice a day is not as good as three pill.'\n",
      "   ğŸ”„ Segment 6/11 (56/141): compression_artifact 357.62s-360.72s\n",
      "      âœ… Transcribed: 'Sterilize it a tiny bit, okay?'\n",
      "   ğŸ”„ Segment 7/11 (57/141): volume_drop 377.90s-381.19s\n",
      "      âœ… Transcribed: 'If you faint easily. I was doing this for some fri...'\n",
      "   ğŸ”„ Segment 8/11 (58/141): compression_artifact 408.95s-412.05s\n",
      "      âœ… Transcribed: 'And out the other side like this.'\n",
      "   ğŸ”„ Segment 9/11 (59/141): compression_artifact 433.97s-437.69s\n",
      "      âœ… Transcribed: 'I know what people think when they see this. They ...'\n",
      "   ğŸ”„ Segment 10/11 (60/141): volume_drop 478.31s-482.03s\n",
      "      âœ… Transcribed: 'See? There's a hole there and a hole there. If it ...'\n",
      "   ğŸ”„ Segment 11/11 (61/141): volume_drop 502.54s-505.93s\n",
      "      âœ… Transcribed: ''\n",
      "\n",
      "ğŸ“ Processing: GaryFlake_2010.wav (14 segments)\n",
      "   Duration: 413.4s\n",
      "   ğŸ”„ Segment 1/14 (62/141): volume_drop 23.99s-27.21s\n",
      "      âœ… Transcribed: 'And instead of thinking about information overload...'\n",
      "   ğŸ”„ Segment 2/14 (63/141): volume_drop 40.98s-44.54s\n",
      "      âœ… Transcribed: 'Tool that I'm using here is a little experiment. I...'\n",
      "   ğŸ”„ Segment 3/14 (64/141): compression_artifact 63.68s-67.42s\n",
      "      âœ… Transcribed: 'Circulatory diseases and cancers are the usual sus...'\n",
      "   ğŸ”„ Segment 4/14 (65/141): volume_drop 106.93s-110.25s\n",
      "      âœ… Transcribed: 'After my talk with Pivot, you can drill into it.'\n",
      "   ğŸ”„ Segment 5/14 (66/141): compression_artifact 128.68s-131.74s\n",
      "      âœ… Transcribed: 'Now if I.'\n",
      "   ğŸ”„ Segment 6/14 (67/141): volume_drop 151.51s-154.54s\n",
      "      âœ… Transcribed: 'That's actually a little bit different. It's in be...'\n",
      "   ğŸ”„ Segment 7/14 (68/141): volume_drop 181.25s-184.41s\n",
      "      âœ… Transcribed: 'We can do a lot of things right away. We get a sen...'\n",
      "   ğŸ”„ Segment 8/14 (69/141): compression_artifact 199.40s-203.06s\n",
      "      âœ… Transcribed: 'So this is really important because this is an ins...'\n",
      "   ğŸ”„ Segment 9/14 (70/141): volume_drop 233.25s-237.19s\n",
      "      âœ… Transcribed: 'There's my boss and.'\n",
      "   ğŸ”„ Segment 10/14 (71/141): compression_artifact 264.82s-267.95s\n",
      "      âœ… Transcribed: 'Pivot this application. I don't want to call it a ...'\n",
      "   ğŸ”„ Segment 11/14 (72/141): compression_artifact 282.93s-286.88s\n",
      "      âœ… Transcribed: 'Because by virtue of just viewing web pages in thi...'\n",
      "   ğŸ”„ Segment 12/14 (73/141): compression_artifact 353.62s-356.69s\n",
      "      âœ… Transcribed: 'Trapped and data we might actually extract.'\n",
      "   ğŸ”„ Segment 13/14 (74/141): volume_drop 376.86s-380.34s\n",
      "      âœ… Transcribed: ''\n",
      "   ğŸ”„ Segment 14/14 (75/141): volume_drop 403.46s-406.76s\n",
      "      âœ… Transcribed: ''\n",
      "\n",
      "ğŸ“ Processing: JamesCameron_2010.wav (13 segments)\n",
      "   Duration: 1055.8s\n",
      "   ğŸ”„ Segment 1/13 (76/141): volume_drop 26.07s-29.95s\n",
      "      âœ… Transcribed: 'I was always absorbed in a book, science fiction b...'\n",
      "   ğŸ”„ Segment 2/13 (77/141): signal_loss 113.71s-117.50s\n",
      "      âœ… Transcribed: 'We all did as kids, having to read a book and thro...'\n",
      "   ğŸ”„ Segment 3/13 (78/141): signal_loss 162.61s-166.23s\n",
      "      âœ… Transcribed: 'Exotic as anything that I had imagined from readin...'\n",
      "   ğŸ”„ Segment 4/13 (79/141): compression_artifact 203.32s-206.34s\n",
      "      âœ… Transcribed: 'Intervening 40 years.'\n",
      "   ğŸ”„ Segment 5/13 (80/141): volume_drop 233.98s-237.84s\n",
      "      âœ… Transcribed: 'Day stand in absolute awe of what I see when I mak...'\n",
      "   ğŸ”„ Segment 6/13 (81/141): compression_artifact 262.64s-265.85s\n",
      "      âœ… Transcribed: 'Put pictures and stories together, and that made s...'\n",
      "   ğŸ”„ Segment 7/13 (82/141): signal_loss 324.48s-327.61s\n",
      "      âœ… Transcribed: 'Advanced technology as indistinguishable from magi...'\n",
      "   ğŸ”„ Segment 8/13 (83/141): compression_artifact 675.15s-678.43s\n",
      "      âœ… Transcribed: 'Out as we start to have cyborg bond.'\n",
      "   ğŸ”„ Segment 9/13 (84/141): compression_artifact 852.83s-856.69s\n",
      "      âœ… Transcribed: 'At a time, sometimes at sea for two, three months.'\n",
      "   ğŸ”„ Segment 10/13 (85/141): signal_loss 905.43s-909.23s\n",
      "      âœ… Transcribed: 'With a small team and in uncharted territory.'\n",
      "   ğŸ”„ Segment 11/13 (86/141): compression_artifact 930.10s-933.88s\n",
      "      âœ… Transcribed: 'Fundamental way of doing business. The process its...'\n",
      "   ğŸ”„ Segment 12/13 (87/141): volume_drop 979.62s-982.95s\n",
      "      âœ… Transcribed: 'NASA has this phrase that they like.'\n",
      "   ğŸ”„ Segment 13/13 (88/141): volume_drop 1026.87s-1030.74s\n",
      "      âœ… Transcribed: ''\n",
      "\n",
      "ğŸ“ Processing: JaneMcGonigal_2010.wav (14 segments)\n",
      "   Duration: 1231.5s\n",
      "   ğŸ”„ Segment 1/14 (89/141): signal_loss 33.90s-37.23s\n",
      "      âœ… Transcribed: 'And it entails convincing more people, including.'\n",
      "   ğŸ”„ Segment 2/14 (90/141): signal_loss 114.67s-118.29s\n",
      "      âœ… Transcribed: 'The emotion of gaming. So we set up a camera in fr...'\n",
      "   ğŸ”„ Segment 3/14 (91/141): signal_loss 535.77s-539.56s\n",
      "      âœ… Transcribed: 'Billion gamers. So I've started to think about wha...'\n",
      "   ğŸ”„ Segment 4/14 (92/141): volume_drop 622.55s-626.45s\n",
      "      âœ… Transcribed: 'To awe inspiring missions to human.'\n",
      "   ğŸ”„ Segment 5/14 (93/141): signal_loss 713.11s-716.37s\n",
      "      âœ… Transcribed: 'Than they can have in real life. They get better f...'\n",
      "   ğŸ”„ Segment 6/14 (94/141): compression_artifact 732.88s-735.91s\n",
      "      âœ… Transcribed: 'Walk more like a game. So I take my inspiration.'\n",
      "   ğŸ”„ Segment 7/14 (95/141): compression_artifact 814.57s-818.19s\n",
      "      âœ… Transcribed: 'This is exactly, I think, how we're using games to...'\n",
      "   ğŸ”„ Segment 8/14 (96/141): volume_drop 856.30s-859.63s\n",
      "      âœ… Transcribed: 'Just enough people to survive on the resources tha...'\n",
      "   ğŸ”„ Segment 9/14 (97/141): compression_artifact 904.77s-908.71s\n",
      "      âœ… Transcribed: 'Since 1994. That was the first real time strategy ...'\n",
      "   ğŸ”„ Segment 10/14 (98/141): volume_drop 965.15s-968.36s\n",
      "      âœ… Transcribed: 'Briefly show you three games that I've made that a...'\n",
      "   ğŸ”„ Segment 11/14 (99/141): volume_drop 990.39s-993.91s\n",
      "      âœ… Transcribed: 'You sign up, you tell us where you live, and then ...'\n",
      "   ğŸ”„ Segment 12/14 (100/141): compression_artifact 1023.91s-1027.31s\n",
      "      âœ… Transcribed: 'It's good for the world or because we're supposed ...'\n",
      "   ğŸ”„ Segment 13/14 (101/141): compression_artifact 1104.95s-1108.07s\n",
      "      âœ… Transcribed: 'Innovator, class of 2010, working with universitie...'\n",
      "   ğŸ”„ Segment 14/14 (102/141): signal_loss 1165.30s-1168.73s\n",
      "      âœ… Transcribed: 'I really hope that we can come together to play.'\n",
      "\n",
      "ğŸ“ Processing: MichaelSpecter_2010.wav (11 segments)\n",
      "   Duration: 1141.2s\n",
      "   ğŸ”„ Segment 1/11 (103/141): volume_drop 6.31s-9.96s\n",
      "      âœ… Transcribed: ''\n",
      "   ğŸ”„ Segment 2/11 (104/141): compression_artifact 82.83s-86.68s\n",
      "      âœ… Transcribed: 'Death number. But it's not even about people like ...'\n",
      "   ğŸ”„ Segment 3/11 (105/141): compression_artifact 121.23s-125.00s\n",
      "      âœ… Transcribed: 'Those things are vaccines. My.'\n",
      "   ğŸ”„ Segment 4/11 (106/141): volume_drop 221.18s-224.81s\n",
      "      âœ… Transcribed: 'People wrap themselves in their beliefs, and they ...'\n",
      "   ğŸ”„ Segment 5/11 (107/141): compression_artifact 255.53s-259.20s\n",
      "      âœ… Transcribed: 'A story, and I moved on. And soon after that,'\n",
      "   ğŸ”„ Segment 6/11 (108/141): compression_artifact 278.67s-281.69s\n",
      "      âœ… Transcribed: 'Ground, but I do what I do, I wr.'\n",
      "   ğŸ”„ Segment 7/11 (109/141): volume_drop 519.14s-522.99s\n",
      "      âœ… Transcribed: 'But it's called it home because people like to tel...'\n",
      "   ğŸ”„ Segment 8/11 (110/141): volume_drop 574.16s-577.88s\n",
      "      âœ… Transcribed: 'And he's going to attend one of these fabulous TED...'\n",
      "   ğŸ”„ Segment 9/11 (111/141): volume_drop 1013.75s-1017.70s\n",
      "      âœ… Transcribed: 'J.'\n",
      "   ğŸ”„ Segment 10/11 (112/141): volume_drop 1090.16s-1093.33s\n",
      "      âœ… Transcribed: 'Before. To find this oil, we need to use.'\n",
      "   ğŸ”„ Segment 11/11 (113/141): volume_drop 1123.73s-1127.40s\n",
      "      âœ… Transcribed: 'In the past. We have to move to more sustainable f...'\n",
      "\n",
      "ğŸ“ Processing: RobertGupta_2010U.wav (14 segments)\n",
      "   Duration: 718.5s\n",
      "   ğŸ”„ Segment 1/14 (114/141): signal_loss 13.96s-17.90s\n",
      "      âœ… Transcribed: 'One day, los angeles.'\n",
      "   ğŸ”„ Segment 2/14 (115/141): volume_drop 44.52s-47.99s\n",
      "      âœ… Transcribed: 'Robert Downey Jr. Acting as Steve lopez and jamie ...'\n",
      "   ğŸ”„ Segment 3/14 (116/141): signal_loss 113.81s-117.25s\n",
      "      âœ… Transcribed: 'Violin lesson with me Now I should mention.'\n",
      "   ğŸ”„ Segment 4/14 (117/141): signal_loss 240.23s-243.46s\n",
      "      âœ… Transcribed: 'To Esopeca Salina. And I understood that he not on...'\n",
      "   ğŸ”„ Segment 5/14 (118/141): signal_loss 278.93s-282.23s\n",
      "      âœ… Transcribed: 'Changes us. And for Nathaniel, music is set.'\n",
      "   ğŸ”„ Segment 6/14 (119/141): compression_artifact 296.76s-299.97s\n",
      "      âœ… Transcribed: 'Understood that this was the very essence of art, ...'\n",
      "   ğŸ”„ Segment 7/14 (120/141): volume_drop 314.63s-317.87s\n",
      "      âœ… Transcribed: 'And the reality of that expression reaches all of ...'\n",
      "   ğŸ”„ Segment 8/14 (121/141): signal_loss 341.01s-344.59s\n",
      "      âœ… Transcribed: 'Make music with Nathaniel, whether we're at Walt D...'\n",
      "   ğŸ”„ Segment 9/14 (122/141): volume_drop 384.66s-388.49s\n",
      "      âœ… Transcribed: 'Stole from cellists, so please forgive me.'\n",
      "   ğŸ”„ Segment 10/14 (123/141): volume_drop 478.33s-481.72s\n",
      "      âœ… Transcribed: ''\n",
      "   ğŸ”„ Segment 11/14 (124/141): volume_drop 537.57s-541.02s\n",
      "      âœ… Transcribed: ''\n",
      "   ğŸ”„ Segment 12/14 (125/141): compression_artifact 556.23s-559.50s\n",
      "      âœ… Transcribed: ''\n",
      "   ğŸ”„ Segment 13/14 (126/141): signal_loss 600.79s-604.51s\n",
      "      âœ… Transcribed: 'Price on taking your car into the central parts of...'\n",
      "   ğŸ”„ Segment 14/14 (127/141): compression_artifact 641.68s-645.48s\n",
      "      âœ… Transcribed: 'Organization and the R and D centers and find a ve...'\n",
      "\n",
      "ğŸ“ Processing: TomWujec_2010U.wav (14 segments)\n",
      "   Duration: 442.5s\n",
      "   ğŸ”„ Segment 1/14 (128/141): compression_artifact 17.65s-21.61s\n",
      "      âœ… Transcribed: 'Peter Skillman introduced a design challenge calle...'\n",
      "   ğŸ”„ Segment 2/14 (129/141): compression_artifact 36.84s-40.50s\n",
      "      âœ… Transcribed: 'Pretty hard because it forces people to collaborat...'\n",
      "   ğŸ”„ Segment 3/14 (130/141): compression_artifact 79.71s-83.58s\n",
      "      âœ… Transcribed: 'They lay out spaghetti, they spend the majority of...'\n",
      "   ğŸ”„ Segment 4/14 (131/141): compression_artifact 98.33s-102.28s\n",
      "      âœ… Transcribed: 'Their work. But what really happens most of the ti...'\n",
      "   ğŸ”„ Segment 5/14 (132/141): signal_loss 122.04s-125.92s\n",
      "      âœ… Transcribed: 'And they produce really lame structures. And of co...'\n",
      "   ğŸ”„ Segment 6/14 (133/141): volume_drop 162.03s-165.28s\n",
      "      âœ… Transcribed: 'And then they execute on it. And then what happens...'\n",
      "   ğŸ”„ Segment 7/14 (134/141): compression_artifact 199.68s-203.01s\n",
      "      âœ… Transcribed: 'But let's look at how different teams perform. So ...'\n",
      "   ğŸ”„ Segment 8/14 (135/141): volume_drop 234.11s-237.15s\n",
      "      âœ… Transcribed: 'Structures, so CEOs a little bit better than that.'\n",
      "   ğŸ”„ Segment 9/14 (136/141): compression_artifact 284.54s-287.61s\n",
      "      âœ… Transcribed: 'These design students, what was the result?'\n",
      "   ğŸ”„ Segment 10/14 (137/141): volume_drop 315.01s-318.97s\n",
      "      âœ… Transcribed: 'To being among the very best. They produce the tal...'\n",
      "   ğŸ”„ Segment 11/14 (138/141): volume_drop 349.28s-353.09s\n",
      "      âœ… Transcribed: 'The challenge provides a shared experience, a comm...'\n",
      "   ğŸ”„ Segment 12/14 (139/141): compression_artifact 366.57s-370.00s\n",
      "      âœ… Transcribed: 'Step by step instructions on this. There are crazy...'\n",
      "   ğŸ”„ Segment 13/14 (140/141): volume_drop 398.09s-401.63s\n",
      "      âœ… Transcribed: 'Moment, and that can make a big difference. Thank ...'\n",
      "   ğŸ”„ Segment 14/14 (141/141): compression_artifact 413.40s-416.78s\n",
      "      âœ… Transcribed: 'Broadband High speed Internet can help small busin...'\n",
      "\n",
      "ğŸ’¾ Saving results...\n",
      "\n",
      "ğŸ‰ Transcription Complete!\n",
      "============================================================\n",
      "ğŸ“Š Total segments processed: 141\n",
      "âœ… Successful transcriptions: 141\n",
      "âŒ Failed transcriptions: 0\n",
      "ğŸ“ Total characters transcribed: 6,989\n",
      "ğŸ“ Output directory: F:\\DEPP\\data2\\thebest\\test\\transcription_dataset\n",
      "ğŸ“„ CSV file: F:\\DEPP\\data2\\thebest\\test\\transcription_dataset\\missing_text_transcriptions.csv\n",
      "ğŸ“„ JSON file: F:\\DEPP\\data2\\thebest\\test\\transcription_dataset\\missing_text_transcriptions.json\n",
      "ğŸ“Š Average characters per segment: 49.6\n",
      "\n",
      "ğŸ“Š Breakdown by noise type:\n",
      "   compression_artifact: 64 segments, 51.3 avg chars\n",
      "   volume_drop: 54 segments, 45.0 avg chars\n",
      "   signal_loss: 23 segments, 55.3 avg chars\n",
      "\n",
      "âœ… Ready for prompt generation and text prediction!\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ™ï¸ TRANSCRIBE MISSING TEXT FROM ORIGINAL FILES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import os, time, requests, json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "print(\"ğŸ¯ Starting transcription of missing text from original files...\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ AssemblyAI Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "API_KEY = \"dc11de72508f4103a483dd74c7506cb2\"  # Your API key\n",
    "HDR_UP  = {\"authorization\": API_KEY}\n",
    "HDR_TR  = {\"authorization\": API_KEY, \"content-type\": \"application/json\"}\n",
    "UPL     = \"https://api.assemblyai.com/v2/upload\"\n",
    "TRN     = \"https://api.assemblyai.com/v2/transcript\"\n",
    "\n",
    "def transcribe_clean_segment(audio_segment: AudioSegment, tag: str) -> str:\n",
    "    \"\"\"×ª××œ×•×œ ×§×˜×¢ ××•×“×™×• × ×§×™ ×‘×××¦×¢×•×ª AssemblyAI\"\"\"\n",
    "    tmp_file = f\"tmp_{tag}_{int(time.time())}.wav\"\n",
    "    try:\n",
    "        # Export temporary file\n",
    "        audio_segment.export(tmp_file, format=\"wav\")\n",
    "        \n",
    "        # Upload to AssemblyAI\n",
    "        with open(tmp_file, \"rb\") as f:\n",
    "            response = requests.post(UPL, headers=HDR_UP, data=f)\n",
    "            upload_url = response.json()[\"upload_url\"]\n",
    "        \n",
    "        # Request transcription\n",
    "        transcript_request = {\n",
    "            \"audio_url\": upload_url,\n",
    "            \"punctuate\": True,\n",
    "            \"format_text\": True\n",
    "        }\n",
    "        response = requests.post(TRN, json=transcript_request, headers=HDR_TR)\n",
    "        transcript_id = response.json()[\"id\"]\n",
    "        \n",
    "        # Poll for completion\n",
    "        while True:\n",
    "            response = requests.get(f\"{TRN}/{transcript_id}\", headers=HDR_UP)\n",
    "            result = response.json()\n",
    "            \n",
    "            if result[\"status\"] == \"completed\":\n",
    "                if result.get(\"words\"):\n",
    "                    return \" \".join(word[\"text\"] for word in result[\"words\"]).strip()\n",
    "                else:\n",
    "                    return result.get(\"text\", \"\").strip()\n",
    "            elif result[\"status\"] == \"error\":\n",
    "                raise RuntimeError(f\"AssemblyAI error: {result.get('error', 'Unknown error')}\")\n",
    "            \n",
    "            time.sleep(3)  # Wait before next poll\n",
    "            \n",
    "    finally:\n",
    "        # Clean up temporary file\n",
    "        if os.path.exists(tmp_file):\n",
    "            os.remove(tmp_file)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Paths Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ORIGINAL_WAV_DIR = Path(r\"F:\\DEPP\\data2\\thebest\\test\\wav\")  # ×§×‘×¦×™× ××§×•×¨×™×™×\n",
    "TEST_LABELS_PATH = \"test_dataset/labels.csv\"                # ×œ×™×™×‘×œ×™× ×§×™×™××™×\n",
    "OUTPUT_DIR = Path(\"transcription_dataset\")                  # ×ª×™×§×™×” ×—×“×©×”\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Load Existing Labels â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ğŸ“‹ Loading existing test labels...\")\n",
    "if not os.path.exists(TEST_LABELS_PATH):\n",
    "    raise FileNotFoundError(f\"Labels file not found: {TEST_LABELS_PATH}\")\n",
    "\n",
    "labels_df = pd.read_csv(TEST_LABELS_PATH)\n",
    "print(f\"   Found {len(labels_df)} noise events in {labels_df['filename'].nunique()} files\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Map to Original Files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ğŸ”— Mapping to original WAV files...\")\n",
    "original_files = {}\n",
    "for _, row in labels_df.iterrows():\n",
    "    noisy_filename = row['filename']\n",
    "    # Remove \"_with_noises.wav\" to get original name\n",
    "    original_name = noisy_filename.replace(\"_with_noises.wav\", \".wav\")\n",
    "    original_path = ORIGINAL_WAV_DIR / original_name\n",
    "    \n",
    "    if original_path.exists():\n",
    "        if original_name not in original_files:\n",
    "            original_files[original_name] = []\n",
    "        original_files[original_name].append(row)\n",
    "    else:\n",
    "        print(f\"   âš ï¸ Original file not found: {original_path}\")\n",
    "\n",
    "print(f\"   Mapped to {len(original_files)} original files\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Noise Type Descriptions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "NOISE_DESCRIPTIONS = {\n",
    "    \"signal_loss\": \"Complete silence â€“ signal lost\",\n",
    "    \"volume_drop\": \"Volume significantly reduced with fade effects\", \n",
    "    \"compression_artifact\": \"Strong codec artifacts â€“ heavily distorted audio\"\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Process Each Original File â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "transcription_results = []\n",
    "total_segments = sum(len(events) for events in original_files.values())\n",
    "processed_segments = 0\n",
    "\n",
    "print(f\"\\nğŸ™ï¸ Starting transcription of {total_segments} segments...\")\n",
    "\n",
    "for original_filename, noise_events in original_files.items():\n",
    "    original_path = ORIGINAL_WAV_DIR / original_filename\n",
    "    print(f\"\\nğŸ“ Processing: {original_filename} ({len(noise_events)} segments)\")\n",
    "    \n",
    "    try:\n",
    "        # Load original audio\n",
    "        original_audio = AudioSegment.from_file(original_path)\n",
    "        duration_sec = len(original_audio) / 1000.0\n",
    "        print(f\"   Duration: {duration_sec:.1f}s\")\n",
    "        \n",
    "        # Process each noise event\n",
    "        for idx, event in enumerate(noise_events):\n",
    "            processed_segments += 1\n",
    "            start_time = float(event['start_time'])\n",
    "            end_time = float(event['end_time'])\n",
    "            noise_type = event['noise_type']\n",
    "            \n",
    "            print(f\"   ğŸ”„ Segment {idx+1}/{len(noise_events)} ({processed_segments}/{total_segments}): \"\n",
    "                  f\"{noise_type} {start_time:.2f}s-{end_time:.2f}s\")\n",
    "            \n",
    "            try:\n",
    "                # Extract clean segment from original file\n",
    "                start_ms = int(start_time * 1000)\n",
    "                end_ms = int(end_time * 1000)\n",
    "                clean_segment = original_audio[start_ms:end_ms]\n",
    "                \n",
    "                # Transcribe the clean segment\n",
    "                tag = f\"{original_filename.replace('.wav', '')}_{idx}\"\n",
    "                missing_text = transcribe_clean_segment(clean_segment, tag)\n",
    "                \n",
    "                # Store result\n",
    "                transcription_results.append({\n",
    "                    \"original_filename\": original_filename,\n",
    "                    \"noisy_filename\": event['filename'],\n",
    "                    \"noise_type\": noise_type,\n",
    "                    \"description\": NOISE_DESCRIPTIONS.get(noise_type, \"Unknown noise type\"),\n",
    "                    \"start_time\": start_time,\n",
    "                    \"end_time\": end_time,\n",
    "                    \"duration\": float(event['duration']),\n",
    "                    \"start_time_mmss\": event.get('start_time_mmss', f\"{int(start_time//60):02d}:{int(start_time%60):02d}\"),\n",
    "                    \"end_time_mmss\": event.get('end_time_mmss', f\"{int(end_time//60):02d}:{int(end_time%60):02d}\"),\n",
    "                    \"missing_text\": missing_text,\n",
    "                    \"segment_length_chars\": len(missing_text),\n",
    "                    \"segment_id\": f\"{original_filename.replace('.wav', '')}_{start_time:.1f}s\"\n",
    "                })\n",
    "                \n",
    "                print(f\"      âœ… Transcribed: '{missing_text[:50]}{'...' if len(missing_text) > 50 else ''}'\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      âŒ Error transcribing segment: {e}\")\n",
    "                # Add error entry\n",
    "                transcription_results.append({\n",
    "                    \"original_filename\": original_filename,\n",
    "                    \"noisy_filename\": event['filename'],\n",
    "                    \"noise_type\": noise_type,\n",
    "                    \"description\": NOISE_DESCRIPTIONS.get(noise_type, \"Unknown noise type\"),\n",
    "                    \"start_time\": start_time,\n",
    "                    \"end_time\": end_time,\n",
    "                    \"duration\": float(event['duration']),\n",
    "                    \"start_time_mmss\": event.get('start_time_mmss', f\"{int(start_time//60):02d}:{int(start_time%60):02d}\"),\n",
    "                    \"end_time_mmss\": event.get('end_time_mmss', f\"{int(end_time//60):02d}:{int(end_time%60):02d}\"),\n",
    "                    \"missing_text\": \"[TRANSCRIPTION_ERROR]\",\n",
    "                    \"segment_length_chars\": 0,\n",
    "                    \"segment_id\": f\"{original_filename.replace('.wav', '')}_{start_time:.1f}s\",\n",
    "                    \"error\": str(e)\n",
    "                })\n",
    "                continue\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error processing file {original_filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Save Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\nğŸ’¾ Saving results...\")\n",
    "\n",
    "# Save as CSV\n",
    "csv_path = OUTPUT_DIR / \"missing_text_transcriptions.csv\"\n",
    "results_df = pd.DataFrame(transcription_results)\n",
    "results_df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Save as JSON for easy reading\n",
    "json_path = OUTPUT_DIR / \"missing_text_transcriptions.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(transcription_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "successful_transcriptions = len([r for r in transcription_results if r[\"missing_text\"] != \"[TRANSCRIPTION_ERROR]\"])\n",
    "total_chars = sum(r[\"segment_length_chars\"] for r in transcription_results if r[\"missing_text\"] != \"[TRANSCRIPTION_ERROR]\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Transcription Complete!\")\n",
    "print(f\"=\" * 60)\n",
    "print(f\"ğŸ“Š Total segments processed: {len(transcription_results)}\")\n",
    "print(f\"âœ… Successful transcriptions: {successful_transcriptions}\")\n",
    "print(f\"âŒ Failed transcriptions: {len(transcription_results) - successful_transcriptions}\")\n",
    "print(f\"ğŸ“ Total characters transcribed: {total_chars:,}\")\n",
    "print(f\"ğŸ“ Output directory: {OUTPUT_DIR.resolve()}\")\n",
    "print(f\"ğŸ“„ CSV file: {csv_path.resolve()}\")\n",
    "print(f\"ğŸ“„ JSON file: {json_path.resolve()}\")\n",
    "\n",
    "if successful_transcriptions > 0:\n",
    "    avg_chars = total_chars / successful_transcriptions\n",
    "    print(f\"ğŸ“Š Average characters per segment: {avg_chars:.1f}\")\n",
    "    \n",
    "    # Show breakdown by noise type\n",
    "    noise_stats = {}\n",
    "    for result in transcription_results:\n",
    "        if result[\"missing_text\"] != \"[TRANSCRIPTION_ERROR]\":\n",
    "            noise_type = result[\"noise_type\"]\n",
    "            if noise_type not in noise_stats:\n",
    "                noise_stats[noise_type] = {\"count\": 0, \"chars\": 0}\n",
    "            noise_stats[noise_type][\"count\"] += 1\n",
    "            noise_stats[noise_type][\"chars\"] += result[\"segment_length_chars\"]\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Breakdown by noise type:\")\n",
    "    for noise_type, stats in noise_stats.items():\n",
    "        avg_chars_type = stats[\"chars\"] / stats[\"count\"] if stats[\"count\"] > 0 else 0\n",
    "        print(f\"   {noise_type}: {stats['count']} segments, {avg_chars_type:.1f} avg chars\")\n",
    "\n",
    "print(f\"\\nâœ… Ready for prompt generation and text prediction!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Detecting noise segments and transcribing with context...\n",
      "ğŸ“‹ Processing only FIRST file for testing\n",
      "ğŸ“ Processing file: AimeeMullins_2009P_with_noises.wav\n",
      "\n",
      "ğŸ“ Processing file: AimeeMullins_2009P_with_noises.wav\n",
      "   Duration: 1318.2s\n",
      "   ğŸ” Analyzing 131822 frames for noise...\n",
      "      ğŸ“Š signal_loss: max=0.985, mean=0.244, >0.5=2965, >0.8=1768\n",
      "      ğŸ“Š volume_drop: max=0.957, mean=0.305, >0.5=8585, >0.8=709\n",
      "      ğŸ“Š compression_artifact: max=0.992, mean=0.550, >0.5=63963, >0.8=44848\n",
      "        ğŸ” Found signal_loss segment: 12.9s-16.0s (duration: 3.1s)\n",
      "        ğŸ” Found signal_loss segment: 826.6s-829.8s (duration: 3.1s)\n",
      "        ğŸ” Found signal_loss segment: 1016.2s-1019.8s (duration: 3.6s)\n",
      "        ğŸ” Found compression_artifact segment: 590.6s-594.1s (duration: 3.4s)\n",
      "   âœ… Found 4 noise segments â‰¥3.0s\n",
      "   ğŸ”„ Segment 1/4: signal_loss 12.9s-16.0s (duration: 3.1s)\n",
      "      ğŸ“ Context range: 0.0s - 46.0s\n",
      "      ğŸ™ï¸ Transcribing BEFORE (12.9s)...\n",
      "   ğŸ” Analyzing 131822 frames for noise...\n",
      "      ğŸ“Š signal_loss: max=0.985, mean=0.244, >0.5=2965, >0.8=1768\n",
      "      ğŸ“Š volume_drop: max=0.957, mean=0.305, >0.5=8585, >0.8=709\n",
      "      ğŸ“Š compression_artifact: max=0.992, mean=0.550, >0.5=63963, >0.8=44848\n",
      "        ğŸ” Found signal_loss segment: 12.9s-16.0s (duration: 3.1s)\n",
      "        ğŸ” Found signal_loss segment: 826.6s-829.8s (duration: 3.1s)\n",
      "        ğŸ” Found signal_loss segment: 1016.2s-1019.8s (duration: 3.6s)\n",
      "        ğŸ” Found compression_artifact segment: 590.6s-594.1s (duration: 3.4s)\n",
      "   âœ… Found 4 noise segments â‰¥3.0s\n",
      "   ğŸ”„ Segment 1/4: signal_loss 12.9s-16.0s (duration: 3.1s)\n",
      "      ğŸ“ Context range: 0.0s - 46.0s\n",
      "      ğŸ™ï¸ Transcribing BEFORE (12.9s)...\n",
      "      ğŸ™ï¸ Transcribing DURING noise (3.1s)...\n",
      "      ğŸ™ï¸ Transcribing DURING noise (3.1s)...\n",
      "      ğŸ™ï¸ Transcribing AFTER (30.0s)...\n",
      "      ğŸ™ï¸ Transcribing AFTER (30.0s)...\n",
      "      âœ… Results:\n",
      "         BEFORE: 0 words - ''\n",
      "         DURING: 0 words - ''\n",
      "         AFTER:  70 words - 'I'd like to share with you a discovery that I made...'\n",
      "   ğŸ”„ Segment 2/4: signal_loss 826.6s-829.8s (duration: 3.1s)\n",
      "      ğŸ“ Context range: 806.6s - 859.8s\n",
      "      ğŸ™ï¸ Transcribing BEFORE (20.0s)...\n",
      "      âœ… Results:\n",
      "         BEFORE: 0 words - ''\n",
      "         DURING: 0 words - ''\n",
      "         AFTER:  70 words - 'I'd like to share with you a discovery that I made...'\n",
      "   ğŸ”„ Segment 2/4: signal_loss 826.6s-829.8s (duration: 3.1s)\n",
      "      ğŸ“ Context range: 806.6s - 859.8s\n",
      "      ğŸ™ï¸ Transcribing BEFORE (20.0s)...\n",
      "      ğŸ™ï¸ Transcribing DURING noise (3.1s)...\n",
      "      ğŸ™ï¸ Transcribing DURING noise (3.1s)...\n",
      "      ğŸ™ï¸ Transcribing AFTER (30.0s)...\n",
      "      ğŸ™ï¸ Transcribing AFTER (30.0s)...\n",
      "      âœ… Results:\n",
      "         BEFORE: 44 words - 'There's no normal, there's common, there's typical...'\n",
      "         DURING: 0 words - ''\n",
      "         AFTER:  63 words - 'The power of so many more children and invite them...'\n",
      "   ğŸ”„ Segment 3/4: signal_loss 1016.2s-1019.8s (duration: 3.6s)\n",
      "      ğŸ“ Context range: 996.2s - 1049.8s\n",
      "      ğŸ™ï¸ Transcribing BEFORE (20.0s)...\n",
      "      âœ… Results:\n",
      "         BEFORE: 44 words - 'There's no normal, there's common, there's typical...'\n",
      "         DURING: 0 words - ''\n",
      "         AFTER:  63 words - 'The power of so many more children and invite them...'\n",
      "   ğŸ”„ Segment 3/4: signal_loss 1016.2s-1019.8s (duration: 3.6s)\n",
      "      ğŸ“ Context range: 996.2s - 1049.8s\n",
      "      ğŸ™ï¸ Transcribing BEFORE (20.0s)...\n",
      "      ğŸ™ï¸ Transcribing DURING noise (3.6s)...\n",
      "      ğŸ™ï¸ Transcribing DURING noise (3.6s)...\n",
      "      ğŸ™ï¸ Transcribing AFTER (30.0s)...\n",
      "      ğŸ™ï¸ Transcribing AFTER (30.0s)...\n",
      "      âœ… Results:\n",
      "         BEFORE: 48 words - 'School. And he called this part of the course the ...'\n",
      "         DURING: 0 words - ''\n",
      "         AFTER:  68 words - 'Repeatedly told otherwise. And even if given a mod...'\n",
      "   ğŸ”„ Segment 4/4: compression_artifact 590.6s-594.1s (duration: 3.4s)\n",
      "      ğŸ“ Context range: 570.6s - 624.1s\n",
      "      ğŸ™ï¸ Transcribing BEFORE (20.0s)...\n",
      "      âœ… Results:\n",
      "         BEFORE: 48 words - 'School. And he called this part of the course the ...'\n",
      "         DURING: 0 words - ''\n",
      "         AFTER:  68 words - 'Repeatedly told otherwise. And even if given a mod...'\n",
      "   ğŸ”„ Segment 4/4: compression_artifact 590.6s-594.1s (duration: 3.4s)\n",
      "      ğŸ“ Context range: 570.6s - 624.1s\n",
      "      ğŸ™ï¸ Transcribing BEFORE (20.0s)...\n",
      "      ğŸ™ï¸ Transcribing DURING noise (3.4s)...\n",
      "      ğŸ™ï¸ Transcribing DURING noise (3.4s)...\n",
      "      ğŸ™ï¸ Transcribing AFTER (30.0s)...\n",
      "      ğŸ™ï¸ Transcribing AFTER (30.0s)...\n",
      "      âœ… Results:\n",
      "         BEFORE: 35 words - 'Equipped to adapt. There's an important difference...'\n",
      "         DURING: 8 words - 'And consistent disability. I'm having some fun. It...'\n",
      "         AFTER:  73 words - 'The world ever thinking that I could be described ...'\n",
      "\n",
      "ğŸ’¾ Saving results...\n",
      "\n",
      "ğŸ‰ Context Transcription Complete!\n",
      "============================================================\n",
      "ğŸ“Š Total segments â‰¥3.0s processed: 4\n",
      "ğŸ“ Output directory: F:\\DEPP\\data2\\thebest\\test\\context_transcription\n",
      "ğŸ“„ JSON file: F:\\DEPP\\data2\\thebest\\test\\context_transcription\\context_transcription_results.json\n",
      "ğŸ“„ CSV file: F:\\DEPP\\data2\\thebest\\test\\context_transcription\\context_transcription_results.csv\n",
      "ğŸµ Audio clips: F:\\DEPP\\data2\\thebest\\test\\context_transcription\\clips\n",
      "\n",
      "ğŸ“Š Transcription Statistics (â‰¥3.0s segments only):\n",
      "   Words BEFORE noise: 127\n",
      "   Words DURING noise: 8\n",
      "   Words AFTER noise: 274\n",
      "   Total context words: 401\n",
      "   Segments blocked by noise: 3/4\n",
      "   Average words before per segment: 31.8\n",
      "   Average words after per segment: 68.5\n",
      "   Noise blocking rate: 75.0%\n",
      "\n",
      "ğŸ“Š Duration Statistics:\n",
      "   Average duration: 3.3s\n",
      "   Minimum duration: 3.1s\n",
      "   Maximum duration: 3.6s\n",
      "\n",
      "ğŸ“Š Noise type breakdown (â‰¥3.0s only):\n",
      "   signal_loss: 3 segments (avg: 3.3s)\n",
      "   compression_artifact: 1 segments (avg: 3.4s)\n",
      "\n",
      "ğŸ“„ Detailed results preview:\n",
      "\n",
      "--- Segment #1 ---\n",
      "File: AimeeMullins_2009P_with_noises.wav\n",
      "Noise: signal_loss (12.9s-16.0s, 3.1s)\n",
      "BEFORE (0 words): ''\n",
      "DURING (0 words): ''\n",
      "AFTER  (70 words): 'I'd like to share with you a discovery that I made a few months ago while writin...'\n",
      "Blocked: True\n",
      "\n",
      "--- Segment #2 ---\n",
      "File: AimeeMullins_2009P_with_noises.wav\n",
      "Noise: signal_loss (826.6s-829.8s, 3.1s)\n",
      "BEFORE (44 words): 'There's no normal, there's common, there's typical, there's no normal. And would...'\n",
      "DURING (0 words): ''\n",
      "AFTER  (63 words): 'The power of so many more children and invite them to engage their rare and valu...'\n",
      "Blocked: True\n",
      "\n",
      "--- Segment #3 ---\n",
      "File: AimeeMullins_2009P_with_noises.wav\n",
      "Noise: signal_loss (1016.2s-1019.8s, 3.6s)\n",
      "BEFORE (48 words): 'School. And he called this part of the course the X factor, the principle of the...'\n",
      "DURING (0 words): ''\n",
      "AFTER  (68 words): 'Repeatedly told otherwise. And even if given a modicum of support, if left to th...'\n",
      "Blocked: True\n",
      "\n",
      "âœ… Ready for LLM text prediction with separated context (â‰¥3.0s segments only)!\n",
      "      âœ… Results:\n",
      "         BEFORE: 35 words - 'Equipped to adapt. There's an important difference...'\n",
      "         DURING: 8 words - 'And consistent disability. I'm having some fun. It...'\n",
      "         AFTER:  73 words - 'The world ever thinking that I could be described ...'\n",
      "\n",
      "ğŸ’¾ Saving results...\n",
      "\n",
      "ğŸ‰ Context Transcription Complete!\n",
      "============================================================\n",
      "ğŸ“Š Total segments â‰¥3.0s processed: 4\n",
      "ğŸ“ Output directory: F:\\DEPP\\data2\\thebest\\test\\context_transcription\n",
      "ğŸ“„ JSON file: F:\\DEPP\\data2\\thebest\\test\\context_transcription\\context_transcription_results.json\n",
      "ğŸ“„ CSV file: F:\\DEPP\\data2\\thebest\\test\\context_transcription\\context_transcription_results.csv\n",
      "ğŸµ Audio clips: F:\\DEPP\\data2\\thebest\\test\\context_transcription\\clips\n",
      "\n",
      "ğŸ“Š Transcription Statistics (â‰¥3.0s segments only):\n",
      "   Words BEFORE noise: 127\n",
      "   Words DURING noise: 8\n",
      "   Words AFTER noise: 274\n",
      "   Total context words: 401\n",
      "   Segments blocked by noise: 3/4\n",
      "   Average words before per segment: 31.8\n",
      "   Average words after per segment: 68.5\n",
      "   Noise blocking rate: 75.0%\n",
      "\n",
      "ğŸ“Š Duration Statistics:\n",
      "   Average duration: 3.3s\n",
      "   Minimum duration: 3.1s\n",
      "   Maximum duration: 3.6s\n",
      "\n",
      "ğŸ“Š Noise type breakdown (â‰¥3.0s only):\n",
      "   signal_loss: 3 segments (avg: 3.3s)\n",
      "   compression_artifact: 1 segments (avg: 3.4s)\n",
      "\n",
      "ğŸ“„ Detailed results preview:\n",
      "\n",
      "--- Segment #1 ---\n",
      "File: AimeeMullins_2009P_with_noises.wav\n",
      "Noise: signal_loss (12.9s-16.0s, 3.1s)\n",
      "BEFORE (0 words): ''\n",
      "DURING (0 words): ''\n",
      "AFTER  (70 words): 'I'd like to share with you a discovery that I made a few months ago while writin...'\n",
      "Blocked: True\n",
      "\n",
      "--- Segment #2 ---\n",
      "File: AimeeMullins_2009P_with_noises.wav\n",
      "Noise: signal_loss (826.6s-829.8s, 3.1s)\n",
      "BEFORE (44 words): 'There's no normal, there's common, there's typical, there's no normal. And would...'\n",
      "DURING (0 words): ''\n",
      "AFTER  (63 words): 'The power of so many more children and invite them to engage their rare and valu...'\n",
      "Blocked: True\n",
      "\n",
      "--- Segment #3 ---\n",
      "File: AimeeMullins_2009P_with_noises.wav\n",
      "Noise: signal_loss (1016.2s-1019.8s, 3.6s)\n",
      "BEFORE (48 words): 'School. And he called this part of the course the X factor, the principle of the...'\n",
      "DURING (0 words): ''\n",
      "AFTER  (68 words): 'Repeatedly told otherwise. And even if given a modicum of support, if left to th...'\n",
      "Blocked: True\n",
      "\n",
      "âœ… Ready for LLM text prediction with separated context (â‰¥3.0s segments only)!\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¯ DETECT & TRANSCRIBE WITH CONTEXT (FIRST FILE ONLY)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import os, time, json, requests, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "print(\"ğŸ¯ Detecting noise segments and transcribing with context...\")\n",
    "print(\"ğŸ“‹ Processing only FIRST file for testing\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Paths & Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "NOISY_AUDIO_DIR = Path(\"test_dataset/data\")        # ×§×‘×¦×™× ×¢× ×¨×¢×©×™× \n",
    "PREPROCESSED_DIR = \"preprocessed_test\"              # × ×ª×•× ×™× ××¢×•×‘×“×™×\n",
    "CONTEXT_OUTPUT_DIR = Path(\"context_transcription\")  # ×ª×™×§×™×” ×—×“×©×” ×œ×ª×•×¦××•×ª\n",
    "CLIPS_DIR = CONTEXT_OUTPUT_DIR / \"clips\"\n",
    "\n",
    "# Create output directories\n",
    "CONTEXT_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "CLIPS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Model & Detection Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Use EXACT same parameters as fast inference cell!\n",
    "SR, HOP = 16000, 160\n",
    "FRAME_TIME = HOP / SR  # Same as fast inference: 0.01\n",
    "THRESHOLDS = np.array([0.8, 0.8, 0.8], dtype=np.float32)  # Same as fast inference\n",
    "MIN_SEGMENT_SEC = 3.0  # Only process segments â‰¥ 3.0 seconds\n",
    "MIN_FRAMES = int(round(MIN_SEGMENT_SEC / FRAME_TIME))\n",
    "MAX_FRAMES = int(round(30.0 / FRAME_TIME))  # Max 30 seconds to avoid very long segments\n",
    "\n",
    "NOISE_CLASSES = [\"signal_loss\", \"volume_drop\", \"compression_artifact\"]\n",
    "NOISE_CLASS_IDX = {name: i for i, name in enumerate(NOISE_CLASSES)}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ AssemblyAI Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "API_KEY = \"dc11de72508f4103a483dd74c7506cb2\"\n",
    "HDR_UP = {\"authorization\": API_KEY}\n",
    "HDR_TR = {\"authorization\": API_KEY, \"content-type\": \"application/json\"}\n",
    "UPL_EP = \"https://api.assemblyai.com/v2/upload\"\n",
    "TRN_EP = \"https://api.assemblyai.com/v2/transcript\"\n",
    "\n",
    "def transcribe_with_assemblyai(audio_path: str) -> list:\n",
    "    \"\"\"×ª××œ×•×œ ×¢× AssemblyAI - ××—×–×™×¨ ××™×œ×™× ×¢× timestamps\"\"\"\n",
    "    try:\n",
    "        # Upload file\n",
    "        with open(audio_path, \"rb\") as f:\n",
    "            upload_response = requests.post(UPL_EP, headers=HDR_UP, data=f)\n",
    "            upload_url = upload_response.json()[\"upload_url\"]\n",
    "        \n",
    "        # Request transcription with word-level timestamps\n",
    "        transcript_request = {\n",
    "            \"audio_url\": upload_url,\n",
    "            \"punctuate\": True,\n",
    "            \"format_text\": True\n",
    "        }\n",
    "        response = requests.post(TRN_EP, json=transcript_request, headers=HDR_TR)\n",
    "        transcript_id = response.json()[\"id\"]\n",
    "        \n",
    "        # Poll for completion\n",
    "        while True:\n",
    "            response = requests.get(f\"{TRN_EP}/{transcript_id}\", headers=HDR_UP)\n",
    "            result = response.json()\n",
    "            \n",
    "            if result[\"status\"] == \"completed\":\n",
    "                return result.get(\"words\", [])\n",
    "            elif result[\"status\"] == \"error\":\n",
    "                raise RuntimeError(f\"AssemblyAI error: {result.get('error', 'Unknown error')}\")\n",
    "            \n",
    "            time.sleep(3)\n",
    "    except Exception as e:\n",
    "        print(f\"      âŒ Transcription error: {e}\")\n",
    "        return []\n",
    "\n",
    "def predict_noise_for_file(wav_filename: str) -> np.ndarray:\n",
    "    \"\"\"×—×™×–×•×™ ×¨×¢×©×™× ×œ×§×•×‘×¥ ×‘×××¦×¢×•×ª ×”××•×“×œ\"\"\"\n",
    "    npy_file = wav_filename.replace(\".wav\", \"_X.npy\")\n",
    "    npy_path = os.path.join(PREPROCESSED_DIR, npy_file)\n",
    "    \n",
    "    if not os.path.exists(npy_path):\n",
    "        print(f\"      âš ï¸ No preprocessed file found: {npy_path}\")\n",
    "        return np.array([])\n",
    "    \n",
    "    # Load spectrogram data\n",
    "    X = np.load(npy_path)[None, ..., None]  # Add batch and channel dims\n",
    "    \n",
    "    # Predict in chunks to handle memory\n",
    "    predictions = []\n",
    "    chunk_size = 1000\n",
    "    for start in range(0, X.shape[2], chunk_size):\n",
    "        end = min(start + chunk_size, X.shape[2])\n",
    "        chunk_pred = model.predict(X[:, :, start:end, :], verbose=0)[0]\n",
    "        predictions.append(chunk_pred)\n",
    "    \n",
    "    return np.concatenate(predictions, axis=0)\n",
    "\n",
    "def find_noise_runs(binary_vector: np.ndarray) -> list:\n",
    "    \"\"\"××¦×™××ª ×¨×¦×¤×™× ×¨×¦×™×¤×™× ×©×œ ×¨×¢×©\"\"\"\n",
    "    runs = []\n",
    "    in_run = False\n",
    "    start_idx = 0\n",
    "    \n",
    "    for i, val in enumerate(binary_vector):\n",
    "        if val and not in_run:\n",
    "            start_idx = i\n",
    "            in_run = True\n",
    "        elif (not val or i == len(binary_vector) - 1) and in_run:\n",
    "            end_idx = i if not val else i + 1\n",
    "            run_length = end_idx - start_idx\n",
    "            \n",
    "            # Filter by duration\n",
    "            if MIN_FRAMES <= run_length <= MAX_FRAMES:\n",
    "                runs.append((start_idx, end_idx))\n",
    "            in_run = False\n",
    "    \n",
    "    return runs\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Process First File Only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "audio_files = sorted([f for f in NOISY_AUDIO_DIR.glob(\"*.wav\")])[:1]  # ×¨×§ ×§×•×‘×¥ ×¨××©×•×Ÿ!\n",
    "\n",
    "if not audio_files:\n",
    "    raise RuntimeError(\"No audio files found in test_dataset/data\")\n",
    "\n",
    "print(f\"ğŸ“ Processing file: {audio_files[0].name}\")\n",
    "\n",
    "# Safety check for model\n",
    "if 'model' not in globals():\n",
    "    raise RuntimeError(\"âš ï¸ Model not loaded - run model loading cell first\")\n",
    "\n",
    "all_results = []\n",
    "PRE_CONTEXT_SEC = 20   # 20 seconds before noise\n",
    "POST_CONTEXT_SEC = 30  # 30 seconds after noise (increased!)\n",
    "MIN_AFTER_AUDIO = 10   # Minimum audio needed after noise for good context\n",
    "\n",
    "for file_idx, audio_file in enumerate(audio_files):\n",
    "    print(f\"\\nğŸ“ Processing file: {audio_file.name}\")\n",
    "    \n",
    "    try:\n",
    "        # Load noisy audio (WITH noise)\n",
    "        noisy_audio = AudioSegment.from_file(audio_file)\n",
    "        total_duration_sec = len(noisy_audio) / 1000.0\n",
    "        print(f\"   Duration: {total_duration_sec:.1f}s\")\n",
    "        \n",
    "        # Get noise predictions from model\n",
    "        predictions = predict_noise_for_file(audio_file.name)\n",
    "        if len(predictions) == 0:\n",
    "            print(f\"   âš ï¸ No predictions available, skipping file\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"   ğŸ” Analyzing {len(predictions)} frames for noise...\")\n",
    "        \n",
    "        # Debug: Check prediction stats\n",
    "        for class_idx, class_name in enumerate(NOISE_CLASSES):\n",
    "            class_probs = predictions[:, class_idx]\n",
    "            max_prob = np.max(class_probs)\n",
    "            mean_prob = np.mean(class_probs)\n",
    "            above_05 = np.sum(class_probs > 0.5)\n",
    "            above_08 = np.sum(class_probs > 0.8)\n",
    "            print(f\"      ğŸ“Š {class_name}: max={max_prob:.3f}, mean={mean_prob:.3f}, >0.5={above_05}, >0.8={above_08}\")\n",
    "        \n",
    "        # Detect noise segments for each class\n",
    "        detected_segments = []\n",
    "        for noise_class in NOISE_CLASSES:\n",
    "            class_idx = NOISE_CLASS_IDX[noise_class]\n",
    "            \n",
    "            # Binary detection with same thresholds as fast inference\n",
    "            binary_pred = (predictions[:, class_idx] >= THRESHOLDS[class_idx]).astype(int)\n",
    "            noise_runs = find_noise_runs(binary_pred)\n",
    "            \n",
    "            for start_frame, end_frame in noise_runs:\n",
    "                start_sec = start_frame * FRAME_TIME\n",
    "                end_sec = end_frame * FRAME_TIME\n",
    "                segment_duration = end_sec - start_sec\n",
    "                \n",
    "                print(f\"        ğŸ” Found {noise_class} segment: {start_sec:.1f}s-{end_sec:.1f}s (duration: {segment_duration:.1f}s)\")\n",
    "                \n",
    "                # âœ… ONLY process segments â‰¥ 3.0 seconds with enough context after!\n",
    "                if segment_duration < MIN_SEGMENT_SEC:\n",
    "                    print(f\"        âŒ Skipped: duration {segment_duration:.1f}s < {MIN_SEGMENT_SEC:.1f}s\")\n",
    "                    continue\n",
    "                \n",
    "                # Check if there's enough audio after the noise for good context\n",
    "                remaining_after = total_duration_sec - end_sec  # total_duration_sec is total file duration\n",
    "                if remaining_after < MIN_AFTER_AUDIO:\n",
    "                    print(f\"        âŒ Skipped: only {remaining_after:.1f}s left after noise (need â‰¥{MIN_AFTER_AUDIO}s)\")\n",
    "                    continue\n",
    "                \n",
    "                # âœ… NO MORE BOUNDARY CHECKS - ALWAYS PROCESS WITH AVAILABLE CONTEXT\n",
    "                detected_segments.append({\n",
    "                    \"filename\": audio_file.name,\n",
    "                    \"start_time\": start_sec,\n",
    "                    \"end_time\": end_sec,\n",
    "                    \"duration\": segment_duration,\n",
    "                    \"noise_type\": noise_class,\n",
    "                    \"confidence\": float(np.mean(predictions[start_frame:end_frame, class_idx]))\n",
    "                })\n",
    "        \n",
    "        print(f\"   âœ… Found {len(detected_segments)} noise segments â‰¥{MIN_SEGMENT_SEC:.1f}s\")\n",
    "        \n",
    "        # Process each detected segment\n",
    "        for seg_idx, segment in enumerate(detected_segments):\n",
    "            print(f\"   ğŸ”„ Segment {seg_idx + 1}/{len(detected_segments)}: \"\n",
    "                  f\"{segment['noise_type']} {segment['start_time']:.1f}s-{segment['end_time']:.1f}s \"\n",
    "                  f\"(duration: {segment['duration']:.1f}s)\")\n",
    "            \n",
    "            try:\n",
    "                # Define time ranges for context\n",
    "                context_start = max(0, segment['start_time'] - PRE_CONTEXT_SEC)\n",
    "                context_end = min(total_duration_sec, segment['end_time'] + POST_CONTEXT_SEC)\n",
    "                \n",
    "                print(f\"      ğŸ“ Context range: {context_start:.1f}s - {context_end:.1f}s\")\n",
    "                \n",
    "                # Extract 3 separate clips from the NOISY audio:\n",
    "                # 1. Before noise (clean context)\n",
    "                before_start_ms = int(context_start * 1000)\n",
    "                before_end_ms = int(segment['start_time'] * 1000)\n",
    "                \n",
    "                # 2. During noise (noisy segment)\n",
    "                during_start_ms = int(segment['start_time'] * 1000)\n",
    "                during_end_ms = int(segment['end_time'] * 1000)\n",
    "                \n",
    "                # 3. After noise (clean context)\n",
    "                after_start_ms = int(segment['end_time'] * 1000)\n",
    "                after_end_ms = int(context_end * 1000)\n",
    "                \n",
    "                # Create clips\n",
    "                clip_before = noisy_audio[before_start_ms:before_end_ms] if before_end_ms > before_start_ms else None\n",
    "                clip_during = noisy_audio[during_start_ms:during_end_ms]\n",
    "                clip_after = noisy_audio[after_start_ms:after_end_ms] if after_end_ms > after_start_ms else None\n",
    "                \n",
    "                # Save clips and transcribe each\n",
    "                results_parts = {}\n",
    "                \n",
    "                # Transcribe BEFORE noise\n",
    "                if clip_before and len(clip_before) > 1000:  # At least 1 second\n",
    "                    before_path = CLIPS_DIR / f\"before_{file_idx}_{seg_idx}.wav\"\n",
    "                    clip_before.export(before_path, format=\"wav\")\n",
    "                    print(f\"      ğŸ™ï¸ Transcribing BEFORE ({len(clip_before)/1000:.1f}s)...\")\n",
    "                    words_before = transcribe_with_assemblyai(str(before_path))\n",
    "                    results_parts['before'] = {\n",
    "                        'clip_path': str(before_path),\n",
    "                        'duration': len(clip_before)/1000,\n",
    "                        'words': words_before,\n",
    "                        'text': \" \".join([w.get('text', '') for w in words_before])\n",
    "                    }\n",
    "                else:\n",
    "                    results_parts['before'] = {'words': [], 'text': '', 'duration': 0}\n",
    "                \n",
    "                # Transcribe DURING noise\n",
    "                during_path = CLIPS_DIR / f\"during_{file_idx}_{seg_idx}.wav\"\n",
    "                clip_during.export(during_path, format=\"wav\")\n",
    "                print(f\"      ğŸ™ï¸ Transcribing DURING noise ({len(clip_during)/1000:.1f}s)...\")\n",
    "                words_during = transcribe_with_assemblyai(str(during_path))\n",
    "                results_parts['during'] = {\n",
    "                    'clip_path': str(during_path),\n",
    "                    'duration': len(clip_during)/1000,\n",
    "                    'words': words_during,\n",
    "                    'text': \" \".join([w.get('text', '') for w in words_during])\n",
    "                }\n",
    "                \n",
    "                # Transcribe AFTER noise\n",
    "                if clip_after and len(clip_after) > 1000:  # At least 1 second\n",
    "                    after_path = CLIPS_DIR / f\"after_{file_idx}_{seg_idx}.wav\"\n",
    "                    clip_after.export(after_path, format=\"wav\")\n",
    "                    print(f\"      ğŸ™ï¸ Transcribing AFTER ({len(clip_after)/1000:.1f}s)...\")\n",
    "                    words_after = transcribe_with_assemblyai(str(after_path))\n",
    "                    results_parts['after'] = {\n",
    "                        'clip_path': str(after_path),\n",
    "                        'duration': len(clip_after)/1000,\n",
    "                        'words': words_after,\n",
    "                        'text': \" \".join([w.get('text', '') for w in words_after])\n",
    "                    }\n",
    "                else:\n",
    "                    results_parts['after'] = {'words': [], 'text': '', 'duration': 0}\n",
    "                \n",
    "                # Store comprehensive result\n",
    "                result = {\n",
    "                    \"file_index\": file_idx,\n",
    "                    \"segment_index\": seg_idx,\n",
    "                    \"filename\": audio_file.name,\n",
    "                    \"noise_type\": segment['noise_type'],\n",
    "                    \"confidence\": segment['confidence'],\n",
    "                    \"start_time\": round(segment['start_time'], 3),\n",
    "                    \"end_time\": round(segment['end_time'], 3),\n",
    "                    \"duration\": round(segment['duration'], 3),\n",
    "                    \n",
    "                    # Context information\n",
    "                    \"context_start_time\": round(context_start, 3),\n",
    "                    \"context_end_time\": round(context_end, 3),\n",
    "                    \n",
    "                    # Before noise results\n",
    "                    \"before_text\": results_parts['before']['text'],\n",
    "                    \"before_word_count\": len(results_parts['before']['words']),\n",
    "                    \"before_duration\": round(results_parts['before']['duration'], 3),\n",
    "                    \n",
    "                    # During noise results\n",
    "                    \"during_text\": results_parts['during']['text'],\n",
    "                    \"during_word_count\": len(results_parts['during']['words']),\n",
    "                    \"during_duration\": round(results_parts['during']['duration'], 3),\n",
    "                    \n",
    "                    # After noise results\n",
    "                    \"after_text\": results_parts['after']['text'],\n",
    "                    \"after_word_count\": len(results_parts['after']['words']),\n",
    "                    \"after_duration\": round(results_parts['after']['duration'], 3),\n",
    "                    \n",
    "                    # Summary\n",
    "                    \"total_context_words\": len(results_parts['before']['words']) + len(results_parts['after']['words']),\n",
    "                    \"noise_blocked_transcription\": len(results_parts['during']['words']) == 0,\n",
    "                    \"full_results\": results_parts\n",
    "                }\n",
    "                \n",
    "                all_results.append(result)\n",
    "                \n",
    "                print(f\"      âœ… Results:\")\n",
    "                print(f\"         BEFORE: {len(results_parts['before']['words'])} words - '{results_parts['before']['text'][:50]}{'...' if len(results_parts['before']['text']) > 50 else ''}'\")\n",
    "                print(f\"         DURING: {len(results_parts['during']['words'])} words - '{results_parts['during']['text'][:50]}{'...' if len(results_parts['during']['text']) > 50 else ''}'\")\n",
    "                print(f\"         AFTER:  {len(results_parts['after']['words'])} words - '{results_parts['after']['text'][:50]}{'...' if len(results_parts['after']['text']) > 50 else ''}'\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      âŒ Error processing segment: {e}\")\n",
    "                continue\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error processing file {audio_file.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Save Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\nğŸ’¾ Saving results...\")\n",
    "\n",
    "json_path = CONTEXT_OUTPUT_DIR / \"context_transcription_results.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "csv_path = CONTEXT_OUTPUT_DIR / \"context_transcription_results.csv\"\n",
    "if all_results:\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    results_df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"\\nğŸ‰ Context Transcription Complete!\")\n",
    "print(f\"=\" * 60)\n",
    "print(f\"ğŸ“Š Total segments â‰¥{MIN_SEGMENT_SEC:.1f}s processed: {len(all_results)}\")\n",
    "print(f\"ğŸ“ Output directory: {CONTEXT_OUTPUT_DIR.resolve()}\")\n",
    "print(f\"ğŸ“„ JSON file: {json_path.resolve()}\")\n",
    "print(f\"ğŸ“„ CSV file: {csv_path.resolve()}\")\n",
    "print(f\"ğŸµ Audio clips: {CLIPS_DIR.resolve()}\")\n",
    "\n",
    "if all_results:\n",
    "    # Statistics\n",
    "    total_before = sum(r[\"before_word_count\"] for r in all_results)\n",
    "    total_during = sum(r[\"during_word_count\"] for r in all_results) \n",
    "    total_after = sum(r[\"after_word_count\"] for r in all_results)\n",
    "    total_context = sum(r[\"total_context_words\"] for r in all_results)\n",
    "    blocked_segments = sum(1 for r in all_results if r[\"noise_blocked_transcription\"])\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Transcription Statistics (â‰¥{MIN_SEGMENT_SEC:.1f}s segments only):\")\n",
    "    print(f\"   Words BEFORE noise: {total_before:,}\")\n",
    "    print(f\"   Words DURING noise: {total_during:,}\")\n",
    "    print(f\"   Words AFTER noise: {total_after:,}\")\n",
    "    print(f\"   Total context words: {total_context:,}\")\n",
    "    print(f\"   Segments blocked by noise: {blocked_segments}/{len(all_results)}\")\n",
    "    \n",
    "    if len(all_results) > 0:\n",
    "        print(f\"   Average words before per segment: {total_before / len(all_results):.1f}\")\n",
    "        print(f\"   Average words after per segment: {total_after / len(all_results):.1f}\")\n",
    "        print(f\"   Noise blocking rate: {blocked_segments / len(all_results) * 100:.1f}%\")\n",
    "    \n",
    "    # Duration statistics\n",
    "    durations = [r[\"duration\"] for r in all_results]\n",
    "    avg_duration = sum(durations) / len(durations)\n",
    "    min_duration = min(durations)\n",
    "    max_duration = max(durations)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Duration Statistics:\")\n",
    "    print(f\"   Average duration: {avg_duration:.1f}s\")\n",
    "    print(f\"   Minimum duration: {min_duration:.1f}s\")\n",
    "    print(f\"   Maximum duration: {max_duration:.1f}s\")\n",
    "    \n",
    "    # Noise type breakdown\n",
    "    noise_stats = {}\n",
    "    for result in all_results:\n",
    "        noise_type = result[\"noise_type\"]\n",
    "        if noise_type not in noise_stats:\n",
    "            noise_stats[noise_type] = {\"count\": 0, \"total_duration\": 0}\n",
    "        noise_stats[noise_type][\"count\"] += 1\n",
    "        noise_stats[noise_type][\"total_duration\"] += result[\"duration\"]\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Noise type breakdown (â‰¥{MIN_SEGMENT_SEC:.1f}s only):\")\n",
    "    for noise_type, stats in noise_stats.items():\n",
    "        avg_dur = stats[\"total_duration\"] / stats[\"count\"]\n",
    "        print(f\"   {noise_type}: {stats['count']} segments (avg: {avg_dur:.1f}s)\")\n",
    "    \n",
    "    print(f\"\\nğŸ“„ Detailed results preview:\")\n",
    "    for i, result in enumerate(all_results[:3]):\n",
    "        print(f\"\\n--- Segment #{i+1} ---\")\n",
    "        print(f\"File: {result['filename']}\")\n",
    "        print(f\"Noise: {result['noise_type']} ({result['start_time']:.1f}s-{result['end_time']:.1f}s, {result['duration']:.1f}s)\")\n",
    "        print(f\"BEFORE ({result['before_word_count']} words): '{result['before_text'][:80]}{'...' if len(result['before_text']) > 80 else ''}'\")\n",
    "        print(f\"DURING ({result['during_word_count']} words): '{result['during_text'][:80]}{'...' if len(result['during_text']) > 80 else ''}'\")\n",
    "        print(f\"AFTER  ({result['after_word_count']} words): '{result['after_text'][:80]}{'...' if len(result['after_text']) > 80 else ''}'\")\n",
    "        print(f\"Blocked: {result['noise_blocked_transcription']}\")\n",
    "\n",
    "print(f\"\\nâœ… Ready for LLM text prediction with separated context (â‰¥{MIN_SEGMENT_SEC:.1f}s segments only)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yonatan\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Starting Gemini text prediction...\n",
      "ğŸ“‹ Loaded 4 clips and 141 real missing texts\n",
      "\n",
      "ğŸ”„ Clip 1/4: signal_loss at 12.9s\n",
      "   âœ… Real: '[not found]'\n",
      "   ğŸ¤– Predicted: 'So, I did.  And'\n",
      "\n",
      "ğŸ”„ Clip 2/4: signal_loss at 826.6s\n",
      "   âœ… Real: '[not found]'\n",
      "   ğŸ¤– Predicted: 'So, I did.  And'\n",
      "\n",
      "ğŸ”„ Clip 2/4: signal_loss at 826.6s\n",
      "   âœ… Real: 'To be even a little bit more dangerous, we can release.'\n",
      "   ğŸ¤– Predicted: 'then we can unleash'\n",
      "\n",
      "ğŸ”„ Clip 3/4: signal_loss at 1016.2s\n",
      "   âœ… Real: 'To be even a little bit more dangerous, we can release.'\n",
      "   ğŸ¤– Predicted: 'then we can unleash'\n",
      "\n",
      "ğŸ”„ Clip 3/4: signal_loss at 1016.2s\n",
      "   âœ… Real: 'In my experience, unless rep.'\n",
      "   ğŸ¤– Predicted: '\"he had been repeatedly\"'\n",
      "\n",
      "ğŸ”„ Clip 4/4: compression_artifact at 590.6s\n",
      "   âœ… Real: 'In my experience, unless rep.'\n",
      "   ğŸ¤– Predicted: '\"he had been repeatedly\"'\n",
      "\n",
      "ğŸ”„ Clip 4/4: compression_artifact at 590.6s\n",
      "   âœ… Real: 'And consistent disability I've had to confront is.'\n",
      "   ğŸ¤– Predicted: 'difference is between medical fact'\n",
      "\n",
      "ğŸ‰ Done! Processed 4 clips\n",
      "ğŸ“„ Results saved to: gemini_final_results.csv\n",
      "ğŸ“Š Real text found: 3/4\n",
      "ğŸ“Š Successful predictions: 4/4\n",
      "\n",
      "ğŸ“‹ Results:\n",
      "   1: signal_loss | Real: '[not found]...' | Predicted: 'So, I did.  And...'\n",
      "   2: signal_loss | Real: 'To be even a little bit more d...' | Predicted: 'then we can unleash...'\n",
      "   3: signal_loss | Real: 'In my experience, unless rep....' | Predicted: '\"he had been repeatedly\"...'\n",
      "   4: compression_artifact | Real: 'And consistent disability I've...' | Predicted: 'difference is between medical ...'\n",
      "   âœ… Real: 'And consistent disability I've had to confront is.'\n",
      "   ğŸ¤– Predicted: 'difference is between medical fact'\n",
      "\n",
      "ğŸ‰ Done! Processed 4 clips\n",
      "ğŸ“„ Results saved to: gemini_final_results.csv\n",
      "ğŸ“Š Real text found: 3/4\n",
      "ğŸ“Š Successful predictions: 4/4\n",
      "\n",
      "ğŸ“‹ Results:\n",
      "   1: signal_loss | Real: '[not found]...' | Predicted: 'So, I did.  And...'\n",
      "   2: signal_loss | Real: 'To be even a little bit more d...' | Predicted: 'then we can unleash...'\n",
      "   3: signal_loss | Real: 'In my experience, unless rep....' | Predicted: '\"he had been repeatedly\"...'\n",
      "   4: compression_artifact | Real: 'And consistent disability I've...' | Predicted: 'difference is between medical ...'\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¤– GEMINI TEXT PREDICTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os, json\n",
    "import pandas as pd\n",
    "\n",
    "print(\"ğŸ¤– Starting Gemini text prediction...\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Load Data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Load context clips\n",
    "with open(\"context_transcription/context_transcription_results.json\", 'r', encoding='utf-8') as f:\n",
    "    context_clips = json.load(f)\n",
    "\n",
    "# Load real missing text\n",
    "with open(\"transcription_dataset/missing_text_transcriptions.json\", 'r', encoding='utf-8') as f:\n",
    "    real_missing_data = json.load(f)\n",
    "\n",
    "# Create lookup for real missing text\n",
    "real_missing_lookup = {}\n",
    "for entry in real_missing_data:\n",
    "    filename = entry['noisy_filename']\n",
    "    start_time = float(entry['start_time'])\n",
    "    key = f\"{filename}_{start_time:.1f}s\"\n",
    "    real_missing_lookup[key] = entry['missing_text']\n",
    "\n",
    "print(f\"ğŸ“‹ Loaded {len(context_clips)} clips and {len(real_missing_data)} real missing texts\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Gemini Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "genai.configure(api_key=\"AIzaSyAzdmFfGrN0-ljCd2AMrI9wz9ETQqUt4ek\")\n",
    "gem = genai.GenerativeModel(\"gemini-1.5-flash-latest\")\n",
    "\n",
    "def predict_missing_text(before: str, during: str, after: str, duration: float) -> str:\n",
    "    \"\"\"×—×™×–×•×™ ×˜×§×¡×˜ ×—×¡×¨ ×¢× Gemini\"\"\"\n",
    "    words_expected = max(1, int(duration * 2.5))\n",
    "    \n",
    "    prompt = f\"\"\"You need to predict missing text from audio transcription.\n",
    "\n",
    "BEFORE the gap ({len(before.split())} words):\n",
    "{before}\n",
    "\n",
    "DURING the gap: [{duration:.1f} seconds of corrupted audio]\n",
    "{during}\n",
    "\n",
    "AFTER the gap ({len(after.split())} words):\n",
    "{after}\n",
    "\n",
    "Predict approximately {words_expected} words that naturally connect BEFORE and AFTER.\n",
    "Return only the predicted text, no explanations.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = gem.generate_content(prompt)\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"[ERROR: {str(e)}]\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Process All Clips â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "results = []\n",
    "\n",
    "for i, clip in enumerate(context_clips):\n",
    "    print(f\"\\nğŸ”„ Clip {i+1}/{len(context_clips)}: {clip['noise_type']} at {clip['start_time']:.1f}s\")\n",
    "    \n",
    "    # Get context\n",
    "    before_text = clip.get('before_text', '')\n",
    "    during_text = clip.get('during_text', '')\n",
    "    after_text = clip.get('after_text', '')\n",
    "    duration = float(clip['end_time']) - float(clip['start_time'])\n",
    "    \n",
    "    # Get real missing text\n",
    "    key = f\"{clip['filename']}_{clip['start_time']:.1f}s\"\n",
    "    real_text = real_missing_lookup.get(key, '[not found]')\n",
    "    \n",
    "    # Predict with Gemini\n",
    "    predicted_text = predict_missing_text(before_text, during_text, after_text, duration)\n",
    "    \n",
    "    print(f\"   âœ… Real: '{real_text}'\")\n",
    "    print(f\"   ğŸ¤– Predicted: '{predicted_text}'\")\n",
    "    \n",
    "    # Store result\n",
    "    results.append({\n",
    "        \"clip\": i+1,\n",
    "        \"filename\": clip['filename'],\n",
    "        \"noise_type\": clip['noise_type'],\n",
    "        \"timing\": f\"{clip['start_time']:.1f}s-{clip['end_time']:.1f}s\",\n",
    "        \"duration\": round(duration, 1),\n",
    "        \"before_words\": len(before_text.split()),\n",
    "        \"after_words\": len(after_text.split()),\n",
    "        \"real_missing\": real_text,\n",
    "        \"gemini_prediction\": predicted_text\n",
    "    })\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Save Results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"context_transcription/gemini_final_results.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nğŸ‰ Done! Processed {len(results)} clips\")\n",
    "print(f\"ğŸ“„ Results saved to: gemini_final_results.csv\")\n",
    "\n",
    "# Show summary\n",
    "found_real = sum(1 for r in results if r['real_missing'] != '[not found]')\n",
    "successful_pred = sum(1 for r in results if not r['gemini_prediction'].startswith('[ERROR'))\n",
    "\n",
    "print(f\"ğŸ“Š Real text found: {found_real}/{len(results)}\")\n",
    "print(f\"ğŸ“Š Successful predictions: {successful_pred}/{len(results)}\")\n",
    "print(\"\\nğŸ“‹ Results:\")\n",
    "for r in results:\n",
    "    print(f\"   {r['clip']}: {r['noise_type']} | Real: '{r['real_missing'][:30]}...' | Predicted: '{r['gemini_prediction'][:30]}...'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
